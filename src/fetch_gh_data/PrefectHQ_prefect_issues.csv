number,title,state,state_reason,created_at,updated_at,closed_at,comments,labels,user,assignee,author_association,body,closed_by,reactions,timeline_url,sub_issues_total,sub_issues_completed,sub_issues_percent_completed,url
18049,missing flow run events,open,,2025-05-14T16:14:57Z,2025-05-14T16:15:34Z,,0,['bug'],zzstoatzz,,COLLABORATOR,"its not totally clear if this issue is limited to `flow-run` events

### Bug summary

not sure if this is an MRE yet, but it should generally repro

```python
from prefect import flow, serve
from prefect.events import DeploymentCompoundTrigger, DeploymentEventTrigger


@flow
def upstream_flow():
    print(""upstream flow"")


@flow
def other_upstream_flow():
    print(""other upstream flow"")


@flow
def downstream_flow():
    print(""downstream flow"")


if __name__ == ""__main__"":
    upstream_deployment = upstream_flow.to_deployment(name=""upstream_deployment_a"")
    other_upstream_deployment = other_upstream_flow.to_deployment(
        name=""upstream_deployment_b""
    )
    downstream_deployment = downstream_flow.to_deployment(
        name=""downstream_deployment"",
        triggers=[
            DeploymentCompoundTrigger(
                require=""all"",
                triggers=[
                    DeploymentEventTrigger(
                        expect={""prefect.flow-run.Completed""},
                        match_related={
                            ""prefect.resource.name"": ""upstream_deployment_a"",
                        },
                    ),
                    DeploymentEventTrigger(
                        expect={""prefect.flow-run.Completed""},
                        match_related={
                            ""prefect.resource.name"": ""upstream_deployment_b"",
                        },
                    ),
                ],
            )
        ],
    )

    serve(upstream_deployment, other_upstream_deployment, downstream_deployment)
```

sometimes completed events are missing, sometimes other flow run events are missing

### Version info

```Text
Version:             3.4.2.dev3+1.g27cccbf654
API version:         0.8.4
Python version:      3.12.8
Git commit:          27cccbf6
Built:               Wed, May 14, 2025 04:10 PM
OS/Arch:             darwin/arm64
Profile:             bleeding
Server type:         server
Pydantic version:    2.11.3
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/18049/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/18049
18047,too many values to unpack (expected 2),open,,2025-05-14T15:03:30Z,2025-05-14T15:11:47Z,,1,['bug'],mizell-lipseys,,NONE,"### Bug summary

This is the same issue as the one outlined here:
https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Flinen.prefect.io%2Ft%2F16009724%2Fhi-i-ve-been-trying-out-the-new-flow-deploy-function-for-dep&data=05%7C02%7Cphillips%40lipseys.com%7C447a7ba502ea426dc6e108dd92f7635a%7Cfd78ae5f2bcd4db2b08eff7920601431%7C0%7C0%7C638828313443064442%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=rYVfCtHtWEFebhnuHAaNUlIXI5hy8PzQXsKyT6Sm0mY%3D&reserved=0

### Version info

```Text
Version:             2.10.2
API version:         0.8.4
Python version:      3.10.9
Git commit:          16747be2
Built:               Fri, Apr 7, 2023 10:19 AM
OS/Arch:             win32/AMD64
Profile:             default
Server type:         cloud
```

### Additional context

Can't update out of fear for existing company processes",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/18047/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/18047
18045,Cancel flow run in automation errors with 403 response,open,,2025-05-14T13:04:10Z,2025-05-14T14:10:22Z,,3,['bug'],mvdb-enspi,,NONE,"### Bug summary

Cancelling a flow run via automations is not working and returns a 403 error.

To reproduce, start a Prefect server and run the following flow file:

```python
from prefect import flow, task
from time import sleep


@task
def sleep_task(seconds: int) -> None:
    print(f""Sleeping for {seconds} seconds..."")
    sleep(seconds)
    print(""Done sleeping!"")


@flow(flow_run_name=""sleep-for-{seconds}"", log_prints=True)
def sleepy_flow(seconds: int = 300):
    sleep_task(seconds)


if __name__ == ""__main__"":
    sleepy_flow.serve()
```

This job will just sleep for 5 minutes.

I created an automation via the GUI that looks as follows:

![Image](https://github.com/user-attachments/assets/363a7861-90b0-4e57-a2a7-b5aed09e87b9).

When creating a flow run, this automation is triggered and successfully sends a notification but the flow run is not cancelled. In the event feed, there's a failed automation action with the following raw return:

![Image](https://github.com/user-attachments/assets/50d0ced1-f8a2-4c52-a7fd-2934b6613057)

I tried changing the cancel action to suspend but this gave the same 403 error.

### Version info

```Text
Version:             3.4.1
API version:         0.8.4
Python version:      3.13.1
Git commit:          b47ad8e1
Built:               Thu, May 08, 2025 08:42 PM
OS/Arch:             linux/x86_64
Profile:             local
Server type:         server
Pydantic version:    2.11.4

The server is also running on 3.4.1.
```

### Additional context

The JSON representation of the automation trigger:

```json
{
  ""type"": ""event"",
  ""match"": {
    ""prefect.resource.id"": ""prefect.flow-run.*""
  },
  ""match_related"": {
    ""prefect.resource.id"": [
      ""prefect.flow.e2e27dee-bd6a-4e0f-9772-1e853d2586ad""
    ],
    ""prefect.resource.role"": ""flow""
  },
  ""after"": [
    ""prefect.flow-run.Running""
  ],
  ""expect"": [
    ""prefect.flow-run.*""
  ],
  ""for_each"": [
    ""prefect.resource.id""
  ],
  ""posture"": ""Proactive"",
  ""threshold"": 1,
  ""within"": 30
}
```",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/18045/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/18045
18035,ModuleNotFoundError: No module named 'referencing',closed,completed,2025-05-13T17:52:08Z,2025-05-13T20:55:31Z,2025-05-13T20:54:59Z,4,['bug'],Daveography,,NONE,"### Bug summary

In the process of upgrading a project from Prefect V2 to V3. On running `prefect server database upgrade` I get the following:

```
Traceback (most recent call last):
  File ""<redacted>\.pyenv\pyenv-win\versions\3.10.11\lib\runpy.py"", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File ""<redacted>\.pyenv\pyenv-win\versions\3.10.11\lib\runpy.py"", line 86, in _run_code
    exec(code, run_globals)
  File ""<redacted>\.venv\Scripts\prefect.exe\__main__.py"", line 4, in <module>
    from prefect.cli import app
  File ""<redacted>\.venv\lib\site-packages\prefect\cli\__init__.py"", line 24, in <module>
    import prefect.cli.server
  File ""<redacted>\.venv\lib\site-packages\prefect\cli\server.py"", line 32, in <module>
    from prefect.server.services.base import Service
  File ""<redacted>\.venv\lib\site-packages\prefect\server\__init__.py"", line 1, in <module>
    from . import models, orchestration, schemas, services
  File ""<redacted>\.venv\lib\site-packages\prefect\server\models\__init__.py"", line 1, in <module>
    from . import (
  File ""<redacted>\.venv\lib\site-packages\prefect\server\models\artifacts.py"", line 9, in <module>
    from prefect.server.database import PrefectDBInterface, db_injector, orm_models
  File ""<redacted>\.venv\lib\site-packages\prefect\server\database\__init__.py"", line 6, in <module>
    from prefect.server.database.interface import PrefectDBInterface
  File ""<redacted>\.venv\lib\site-packages\prefect\server\database\interface.py"", line 9, in <module>
    from prefect.server.database import orm_models
  File ""<redacted>\.venv\lib\site-packages\prefect\server\database\orm_models.py"", line 26, in <module>
    from prefect.server.events.actions import ServerActionTypes
  File ""<redacted>\.venv\lib\site-packages\prefect\server\events\actions.py"", line 86, in <module>
    from prefect.utilities.schema_tools.hydration import (
  File ""<redacted>\.venv\lib\site-packages\prefect\utilities\schema_tools\__init__.py"", line 2, in <module>
    from .validation import (
  File ""<redacted>\.venv\lib\site-packages\prefect\utilities\schema_tools\validation.py"", line 9, in <module>
    from referencing.jsonschema import ObjectSchema, Schema
ModuleNotFoundError: No module named 'referencing'
```

Appears to be related to https://github.com/PrefectHQ/prefect/pull/16298, where a dependency on the `referencing` package was added, however it does not appear to be included in the Prefect dependencies.

Adding the dependency to my own project resolves the issue as a workaround.

### Version info

```Text
Version:             3.4.1
API version:         0.8.4
Python version:      3.10.11
Git commit:          b47ad8e1
Built:               Thu, May 08, 2025 08:42 PM
OS/Arch:             win32/AMD64
Profile:             local
Server type:         ephemeral
Pydantic version:    2.11.4
Server:
  Database:          sqlite
  SQLite version:    3.40.1
Integrations:
  prefect-snowflake: 0.28.4
```

### Additional context

_No response_",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/18035/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/18035
18026,dbt-prefect path handling for DbtCoreOperation can not handle spaces nor escaping in paths,open,,2025-05-12T12:41:45Z,2025-05-12T12:41:45Z,,0,['bug'],dumkydewilde,,NONE,"### Bug summary

The [`_append_dirs_to_commands` function](https://github.com/PrefectHQ/prefect/blob/7f25bbdf45fc81cca6dc23fb6a7377d436b70c83/src/integrations/prefect-dbt/prefect_dbt/cli/commands.py#L369) does not add the paths in quotes, meaning that if a path contains a space the generated shell script will fail. Unfortunately escaping with a `\` also fails since `relative_path_to_current_platform()` replaces all backslashes.

Minimal example:
```
result = DbtCoreOperation(
        commands=[
            ""dbt debug""
            ],
        project_dir=os.getenv(""DBT_PROJECT_DIR"", ""/local user name with spaces/my_dbt_project"")
    ).run()
```

### Version info

```Text
3.4.0
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/18026/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/18026
18025,"UI should connect to server using relative URLs by default, not absolute URLs",open,,2025-05-12T02:29:36Z,2025-05-12T02:30:28Z,,0,['bug'],Hueburtsonly,,NONE,"### Bug summary

TL;DR: Please default PREFECT_UI_API_URL to ""/api"", not ""http://_host_:_port_/api"".

At the moment, the value of PREFECT_UI_API_URL defaults to something like this:

""http://127.0.0.1:4000/api""

The first thing I do on any deployment of prefect is set an env var to set PREFECT_UI_API_URL to this:

""/api""

My only question is, why does Prefect use the full absolute path as a default? This can only possibly serve to break things, because if any kind of tunneling/proxying/cloudflaring is done, the end user will be connecting to http://something.else/ , but that website will try to connect to 127.0.0.1. Much better to just use relative paths, which will ALWAYS* work.

Inappropriate use of absolute URLs where relative URLs would be perfectly fine is a common mistake in web design, and it's being made here in the Prefect UI.

'* And if they don't work for some weird reason, we still have the env var available. 

### Version info

```Text
>prefect version
Version:             3.4.1
API version:         0.8.4
Python version:      3.13.2
Git commit:          b47ad8e1
Built:               Thu, May 08, 2025 08:42 PM
OS/Arch:             win32/AMD64
Profile:             local
Server type:         server
Pydantic version:    2.11.4
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/18025/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/18025
18019,Deploy a deployment without overriding values that were declared in the UI,open,,2025-05-11T12:11:38Z,2025-05-11T12:11:38Z,,0,['enhancement'],ChrisPaul33,,NONE,"### Describe the current behavior

When updating a deployment, the parameters and schedules declared in the `prefect.yaml` are all overriding the current values.
For most cases it's fine.
But I have a case when there is an operation team that make changes in the UI only!
Once in a while, I need to update the image of the deployment, but I don't want to override any (or most) of the UI parameters, schedules and more. 

### Describe the proposed behavior

There are a few ideas I can think of.

1. Add an extra flag named `--no-override-ui` (or similar) that overrides the data only if it is explicitly declared. It will keep the current behavior and only add that specific use case.
2. Add a special key in the yaml itself that enables the same behavior.
3. In the prefect.yaml, if the keys of `parameters`, `schedules`, etc. are not declared, it will keep the values declared in the UI. Then, if I don't want schedules at all, I explicitly declare it as an empty value (`{}` or `none`) in the yaml. I believe this is the best approach.

### Example Use

How option 3 would look like:
```
deployments:
  - name: deployment-1
    # Because ""schedules"" key is missing, it will keep the current values.
    entrypoint: flows/hello.py:my_flow
   # Overrides the parameters ""number"", ""message""  and ""need_to_override"" from the UI. If there are other parameters, they keep the same value that was declared in the UI.
    parameters: 
        number: 42,
        message: Don't panic!
        need_to_override: none
    work_pool:
        name: my-process-work-pool
        work_queue_name: primary-queue
```

### Additional context

_No response_",,2,https://api.github.com/repos/PrefectHQ/prefect/issues/18019/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/18019
18017,RedisLockManager breaks Ray and Dask flows,closed,completed,2025-05-10T03:12:35Z,2025-05-12T19:38:04Z,2025-05-12T13:45:54Z,4,['bug'],bogdibota,,NONE,"### Bug summary

Hello! I tried to use cached tasks with `IsolationLevel.SERIALIZABLE` in a flow with `RayTaskRunner` (or `DaskTaskRunner`), but it errors before starting. From my understanding, something related to `RedisLockManager` seems to error when being serialized.


Here is the minimal example
```python
# /// script
# dependencies = [""prefect"", ""prefect[redis]"", ""prefect[dask]"", ""prefect[ray]""]
# ///

import prefect
from prefect.cache_policies import TASK_SOURCE, INPUTS
from prefect.transactions import IsolationLevel
from prefect_dask.task_runners import DaskTaskRunner
from prefect_redis import RedisLockManager
from prefect_ray import RayTaskRunner

@prefect.task(
    cache_policy=(TASK_SOURCE + INPUTS).configure(
        isolation_level=IsolationLevel.SERIALIZABLE,
        lock_manager=RedisLockManager(host=""localhost"", port=6379),
    )
)
def cached_task(input: int):
    logger = prefect.get_run_logger()
    logger.info(f""executed task for {input}"")
    return input + 1

def simple_flow():
    logger = prefect.get_run_logger()
    results = cached_task.map([1, 2, 2, 3, 3, 3]).result()
    logger.info(f""results: {results}"")

if __name__ == ""__main__"":
    ray_flow = prefect.flow(task_runner=RayTaskRunner)(simple_flow)
    dask_flow = prefect.flow(task_runner=DaskTaskRunner)(simple_flow)
    concurrent_flow = prefect.flow()(simple_flow)

    ray_flow() # fails
    dask_flow() # fails
    concurrent_flow() # works as expected
```

`concurrent_flow` work as expected, but both `ray_flow` and `dask_flow` flow. I did comment/uncomment to run only one at a time.

disclaimer: i'm new to both python and prefect, maybe i'm missing something here ðŸ˜… 

### Version info

```Text
Version:             3.4.1
API version:         0.8.4
Python version:      3.13.2
Git commit:          b47ad8e1
Built:               Thu, May 08, 2025 08:42 PM
OS/Arch:             linux/x86_64
Profile:             prefect-cloud
Server type:         cloud
Pydantic version:    2.11.4
```

### Additional context

The regular flow works as expected:
```
05:49:16.413 | INFO    | Task run 'cached_task-ed2' - executed task for 3
05:49:16.414 | INFO    | Task run 'cached_task-6cb' - executed task for 1
05:49:16.414 | INFO    | Task run 'cached_task-642' - executed task for 2
05:49:16.421 | INFO    | Task run 'cached_task-ed2' - Finished in state Completed()
05:49:16.423 | INFO    | Task run 'cached_task-642' - Finished in state Completed()
05:49:16.423 | INFO    | Task run 'cached_task-6cb' - Finished in state Completed()
05:49:16.517 | INFO    | Task run 'cached_task-bc0' - Finished in state Cached(type=COMPLETED)
05:49:16.519 | INFO    | Task run 'cached_task-a90' - Finished in state Cached(type=COMPLETED)
05:49:16.616 | INFO    | Task run 'cached_task-cec' - Finished in state Cached(type=COMPLETED)
05:49:16.618 | INFO    | Flow run 'mustard-cat' - results: [2, 3, 3, 4, 4, 4]
05:49:16.803 | INFO    | Flow run 'mustard-cat' - Finished in state Completed()
```

Ray errors with:
```
TypeError: Could not serialize the argument <prefect.tasks.Task object at 0x7f203c529950> for a task or actor prefect_ray.task_runners.RayTaskRunner._run_prefect_task:
=========================================================================
Checking Serializability of <prefect.tasks.Task object at 0x7f203c529950>
=========================================================================
!!! FAIL serialization: cannot pickle '_thread.lock' object
    Serializing '__wrapped__' <function cached_task at 0x7f2040f2b1a0>...
    Serializing 'fn' <function cached_task at 0x7f2040f2b1a0>...
    Serializing 'apply_async' <bound method Task.apply_async of <prefect.tasks.Task object at 0x7f203c529950>>...
    !!! FAIL serialization: cannot pickle '_thread.lock' object
        Serializing '__func__' <function Task.apply_async at 0x7f203d4620c0>...
    WARNING: Did not find non-serializable object in <bound method Task.apply_async of <prefect.tasks.Task object at 0x7f203c529950>>. This may be an oversight.
=========================================================================
Variable:

        FailTuple(apply_async [obj=<bound method Task.apply_async of <prefect.tasks.Task object at 0x7f203c529950>>, parent=<prefect.tasks.Task object at 0x7f203c529950>])

was found to be non-serializable. There may be multiple other undetected variables that were non-serializable.
Consider either removing the instantiation/imports of these variables or moving the instantiation into the scope of the function/class.
=========================================================================
Check https://docs.ray.io/en/master/ray-core/objects/serialization.html#troubleshooting for more information.
If you have any suggestions on how to improve this error message, please reach out to the Ray developers on github.com/ray-project/ray/issues/
=========================================================================
```

Dask errors with:
```
Traceback (most recent call last):
  File ""/home/bogdi/projects/reactive/varyn/varyn-core/flows/redis_lock_bug.py"", line 34, in <module>
    dask_flow()
    ~~~~~~~~~^^
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/prefect/flows.py"", line 1691, in __call__
    return run_flow(
        flow=self,
    ...<2 lines>...
        return_type=return_type,
    )
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/prefect/flow_engine.py"", line 1527, in run_flow
    ret_val = run_flow_sync(**kwargs)
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/prefect/flow_engine.py"", line 1372, in run_flow_sync
    return engine.state if return_type == ""state"" else engine.result()
                                                       ~~~~~~~~~~~~~^^
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/prefect/flow_engine.py"", line 350, in result
    raise self._raised
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/prefect/flow_engine.py"", line 763, in run_context
    yield self
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/prefect/flow_engine.py"", line 1370, in run_flow_sync
    engine.call_flow_fn()
    ~~~~~~~~~~~~~~~~~~~^^
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/prefect/flow_engine.py"", line 783, in call_flow_fn
    result = call_with_parameters(self.flow.fn, self.parameters)
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/prefect/utilities/callables.py"", line 210, in call_with_parameters
    return fn(*args, **kwargs)
  File ""/home/bogdi/projects/reactive/varyn/varyn-core/flows/redis_lock_bug.py"", line 25, in simple_flow
    results = cached_task.map([1, 2, 2, 3, 3, 3]).result()
              ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/prefect/tasks.py"", line 1438, in map
    futures = task_runner.map(self, parameters, wait_for)
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/prefect_dask/task_runners.py"", line 481, in map
    return super().map(task, parameters, wait_for)
           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/prefect/task_runners.py"", line 208, in map
    self.submit(
    ~~~~~~~~~~~^
        task=task,
        ^^^^^^^^^^
    ...<2 lines>...
        dependencies=task_inputs,
        ^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/prefect_dask/task_runners.py"", line 448, in submit
    future = self.client.submit(
        task,
    ...<3 lines>...
        return_type=""state"",
    )
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/prefect_dask/client.py"", line 64, in submit
    future = super().submit(
        wrapper_func,
    ...<10 lines>...
        **run_task_kwargs,
    )
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/distributed/client.py"", line 2141, in submit
    expr = LLGExpr(
        {
    ...<6 lines>...
        }
    )
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/_expr.py"", line 72, in __new__
    inst._name
  File ""/usr/lib64/python3.13/functools.py"", line 1042, in __get__
    val = self.func(instance)
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/_expr.py"", line 522, in _name
    return self._funcname + ""-"" + self.deterministic_token
                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/_expr.py"", line 517, in deterministic_token
    self._determ_token = self.__dask_tokenize__()
                         ~~~~~~~~~~~~~~~~~~~~~~^^
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/_expr.py"", line 147, in __dask_tokenize__
    self._determ_token = _tokenize_deterministic(type(self), *self.operands)
                         ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/tokenize.py"", line 457, in _tokenize_deterministic
    return tokenize(*args, ensure_deterministic=True, **kwargs)
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/tokenize.py"", line 76, in tokenize
    return _tokenize(*args, **kwargs)
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/tokenize.py"", line 34, in _tokenize
    token: object = _normalize_seq_func(args)
                    ~~~~~~~~~~~~~~~~~~~^^^^^^
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/tokenize.py"", line 154, in _normalize_seq_func
    return tuple(map(_inner_normalize_token, seq))
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/tokenize.py"", line 147, in _inner_normalize_token
    return normalize_token(item)
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/utils.py"", line 772, in __call__
    return meth(arg, *args, **kwargs)
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/tokenize.py"", line 122, in normalize_dict
    return ""dict"", _normalize_seq_func(
                   ~~~~~~~~~~~~~~~~~~~^
        sorted(d.items(), key=lambda kv: str(kv[0]))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/tokenize.py"", line 154, in _normalize_seq_func
    return tuple(map(_inner_normalize_token, seq))
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/tokenize.py"", line 147, in _inner_normalize_token
    return normalize_token(item)
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/utils.py"", line 772, in __call__
    return meth(arg, *args, **kwargs)
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/tokenize.py"", line 161, in normalize_seq
    return type(seq).__name__, _normalize_seq_func(seq)
                               ~~~~~~~~~~~~~~~~~~~^^^^^
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/tokenize.py"", line 154, in _normalize_seq_func
    return tuple(map(_inner_normalize_token, seq))
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/tokenize.py"", line 147, in _inner_normalize_token
    return normalize_token(item)
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/utils.py"", line 772, in __call__
    return meth(arg, *args, **kwargs)
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/tokenize.py"", line 198, in normalize_object
    return method()
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/_task_spec.py"", line 707, in __dask_tokenize__
    return self._get_token()
           ~~~~~~~~~~~~~~~^^
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/_task_spec.py"", line 696, in _get_token
    self._token = tokenize(
                  ~~~~~~~~^
        (
        ^
    ...<4 lines>...
        )
        ^
    )
    ^
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/tokenize.py"", line 76, in tokenize
    return _tokenize(*args, **kwargs)
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/tokenize.py"", line 34, in _tokenize
    token: object = _normalize_seq_func(args)
                    ~~~~~~~~~~~~~~~~~~~^^^^^^
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/tokenize.py"", line 154, in _normalize_seq_func
    return tuple(map(_inner_normalize_token, seq))
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/tokenize.py"", line 147, in _inner_normalize_token
    return normalize_token(item)
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/utils.py"", line 772, in __call__
    return meth(arg, *args, **kwargs)
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/tokenize.py"", line 161, in normalize_seq
    return type(seq).__name__, _normalize_seq_func(seq)
                               ~~~~~~~~~~~~~~~~~~~^^^^^
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/tokenize.py"", line 154, in _normalize_seq_func
    return tuple(map(_inner_normalize_token, seq))
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/tokenize.py"", line 147, in _inner_normalize_token
    return normalize_token(item)
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/utils.py"", line 772, in __call__
    return meth(arg, *args, **kwargs)
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/tokenize.py"", line 212, in normalize_object
    _maybe_raise_nondeterministic(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        f""Object {o!r} cannot be deterministically hashed. This likely ""
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        ""indicates that the object cannot be serialized deterministically.""
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File ""/home/bogdi/.cache/uv/environments-v2/redis-lock-bug-63ce28e9b3b3ffe7/lib64/python3.13/site-packages/dask/tokenize.py"", line 89, in _maybe_raise_nondeterministic
    raise TokenizationError(msg)
dask.tokenize.TokenizationError: Object <function cached_task at 0x7f8addd1f9c0> cannot be deterministically hashed. This likely indicates that the object cannot be serialized deterministically.
```",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/18017/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/18017
18015,Ability to store the prefect database to a custom PostgreSQL schema,open,,2025-05-09T17:44:13Z,2025-05-09T17:44:13Z,,0,['enhancement'],francbartoli,,NONE,"### Describe the current behavior

At the moment there is no way to set a custom `search_path` in the connection string of the database. This is an hard constraint in certain circumstances and environments where databases are not allowed to be containerized and the database is unique and shared across different applications. 

### Describe the proposed behavior

I'd like to have a setting in the [database settings](https://docs-3.prefect.io/v3/manage/server/index#database-settings) `PREFECT_API_DATABASE_SCHEMA='foo'`

### Example Use

_No response_

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/18015/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/18015
18006,Logs missing when using result_serializer with a GCS Block,open,,2025-05-08T10:36:02Z,2025-05-11T11:07:47Z,,2,['bug'],essamik,,NONE,"### Bug summary

When providing a GCS Block to my flow decorator `result_storage`, logs don't appear neither on my local IDE when running a deployment locally from the python main, neither on my self hosted prefect server when running a deployment on k8s directly.

Removing that `result_storage` parameter line fix the problems and logs are again visible.

```python

@flow(
    name=""flow-name"",
    result_serializer=""json"",
    result_storage=""gcs-bucket/gcs-prefect-block"", # Removing this line and logs show up again
    persist_result=True
)
def my_flow(day_delta: int = 30) -> None:
```

It's weird that setting a result_storage creates a side effects on the logging, seems like a bug to me.

See image, there should be a lot more logs at task level.
![Image](https://github.com/user-attachments/assets/1e061a51-0fc5-49c1-b8fb-3266ef2fdd65)

### Version info

```Text
Version:             3.4.0
API version:         0.8.4
Python version:      3.12.3
Git commit:          c80e4442
Built:               Fri, May 02, 2025 08:02 PM
OS/Arch:             darwin/arm64
Profile:             dev
Server type:         server
Pydantic version:    2.10.6
Integrations:
  prefect-gcp:       0.6.2
  prefect-docker:    0.6.3
  prefect-kubernetes: 0.5.9
```

### Additional context

I checked the log table in the prefect DB and they also do not appear there.
I'm using the `get_run_logger` helper to log in my tasks.
Log level is correctly set to default value.",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/18006/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/18006
18005,CancellationCleanup service stuck permanently at 100% CPU usage,open,,2025-05-07T21:47:58Z,2025-05-07T22:14:47Z,,3,['bug'],gabr1elt,,NONE,"### Bug summary

CancellationCleanup constantly keeps the CPU at 90+% (the service still works tough, and with no delays)

Stopping the service as described in [settings ref](https://docs.prefect.io/v3/api-ref/settings-ref#enabled-4) frees up the cpu (so I assume its that).

### logs

The server only ever showed a warning once:

`19:21:17.691 | WARNING | prefect.server.services.cancellationcleanup - `stop(block=True)` was called on CancellationCleanup but more than one loop interval (20.0 seconds) has passed. This usually means something is wrong. If `stop()` was called from inside the loop service, use `stop(block=False)` instead.`

then it never mentioned it again

### how to stop it

Resetting the DB is the only way I found to fix it (but obviously not ideal)

### Maybe related

My infra crashed a few times and had to do some manual cleanup

also found this

https://github.com/PrefectHQ/prefect/issues/15231


### Version info

```Text
Prefect Server: docker.io/prefecthq/prefect:3.4.0-python3.10
Postgres: docker.io/postgres:17.4
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/18005/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/18005
18001,Mismatch between frontend and backend API Default Limit Settings,open,,2025-05-07T17:51:16Z,2025-05-07T18:43:08Z,,1,"['bug', 'ui']",eric-martial,,NONE,"### Bug summary

## Summary
After migrating from Prefect v3.3.4 to v3.4.0, there's a discrepancy in the API default limit values between frontend and backend. The frontend consistently sends a limit of 200 when making requests, but the backend seems to be expecting 100, resulting in 422 Unprocessable Entity errors when viewing flow run logs.
The issue specifically impacts log retrieval. 
Setting the environment variable doesn't override the frontend request parameter.

## Environment
- Prefect Version: 3.4.0
- Environment Setup: Using the environment variable `PREFECT_SERVER_API_DEFAULT_LIMIT` to attempt to modify the default limit

## Steps to Reproduce
1. Set up Prefect 3.4.0 server
2. Create a simple flow using the Prefect Python SDK:
   ```python
   from prefect import flow, task
   
   @task(name=""test-task"", log_prints=True)
   def my_task():
       for i in range(250):
           print(f""Log line {i}"")
       return ""done""
   
   @flow(name=""test-flow"")
   def my_flow():
       return my_task()
   
   if __name__ == ""__main__"":
       my_flow()
   ```
3. Run the flow from the command line: `python some_flow.py`
4. Open the Prefect UI and navigate to the Runs page
5. Click on the flow run to view details
6. Open browser developer tools (F12) and go to the Network tab
7. Click on the ""Logs"" tab in the UI
8. Observe the 422 errors in the browser console for requests to `api/logs/filter` endpoint

## Actual Behavior
The browser makes POST requests to `api/logs/filter` with a limit value of 200, resulting in a 422 Unprocessable Entity error with message 'Invalid limit: must be less than or equal to 100.'. 
Setting the `PREFECT_SERVER_API_DEFAULT_LIMIT` environment variable to 100 does not change this behavior - frontend requests continue to use 200.

The logs are actually being generated correctly (confirmed by checking the database `log` table which contains entries), but they cannot be retrieved through the UI due to this API validation error. 

Additionally, the UI displays a misleading message ""This run didn't generate logs"" when in fact logs exist but cannot be retrieved due to the API limit mismatch. This misleading message further obscures the actual problem.

## Console Error (Partial)
```
{
  ""message"": ""Request failed with status code 422"",
  ""name"": ""AxiosError"",
  ""stack"": <removed>
  ""config"": {
    ""transitional"": {
      ""silentJSONParsing"": true,
      ""forcedJSONParsing"": true,
      ""clarifyTimeoutError"": false
    },
    ""adapter"": [
      ""xhr"",
      ""http"",
      ""fetch""
    ],
    ""transformRequest"": [
      null
    ],
    ""transformResponse"": [
      null
    ],
    ""timeout"": 0,
    ""xsrfCookieName"": ""XSRF-TOKEN"",
    ""xsrfHeaderName"": ""X-XSRF-TOKEN"",
    ""maxContentLength"": -1,
    ""maxBodyLength"": -1,
    ""env"": {},
    ""headers"": {
      ""Accept"": ""application/json, text/plain, */*"",
      ""Content-Type"": ""application/json"",
      ""X-PREFECT-UI"": ""true""
    },
    ""baseURL"": ""http://<api_host>/api"",
    ""method"": ""post"",
    ""url"": ""/logs/filter"",
    ""data"": ""{\""logs\"":{\""level\"":{\""ge_\"":0},\""flow_run_id\"":{\""any_\"":[\""<flow_run_id>\""]}},\""sort\"":\""TIMESTAMP_ASC\"",\""offset\"":0,\""limit\"":200}"",
    ""allowAbsoluteUrls"": true
  },
  ""code"": ""ERR_BAD_REQUEST"",
  ""status"": 422
}
```

## Possible Causes
1. **Configuration Loading Issue**: The default limit value is not being properly loaded or propagated from backend to frontend.

2. **Environment Variable Inconsistency**: There appear to be two different environment variables in the codebase:
   - `PREFECT_API_DEFAULT_LIMIT` (found in multiple files)
   - `PREFECT_SERVER_API_DEFAULT_LIMIT` (shown in the documentation)

3. **Frontend/Backend Synchronization**: The frontend JavaScript code might have a hardcoded default limit of 200, while the backend API validates against a different value (potentially 100).

4. **Settings Propagation Failure**: The configured limit value isn't being properly sent to the client-side code when the UI is loaded, causing a mismatch in expectations.

5. **Inaccurate Error Handling**: When log retrieval fails due to API validation errors, the UI incorrectly displays ""This run didn't generate logs"" instead of indicating that logs exist but could not be retrieved.


### Version info

```Text
Version:             3.4.0
API version:         0.8.4
Python version:      3.13.3
Git commit:          c80e4442
Built:               Fri, May 02, 2025 08:02 PM
OS/Arch:             linux/x86_64
Profile:             
Server type:         server
Pydantic version:    2.11.4
Integrations:
  prefect-github:    0.3.1
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/18001/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/18001
17996,fetch_all() returns zero rows with SQLAlchemy â‰¥ 2.0.0 using mssql+pymssql,open,,2025-05-07T07:49:42Z,2025-05-07T07:49:42Z,,0,['bug'],DSauterIntersport,,NONE,"### Bug summary

Weâ€™re experiencing an issue when querying tables from a Microsoft SQL Server using _prefect_sqlalchemy_ and the _mssql+pymssql_ driver. The problem occurs only with SQLAlchemy versions 2.0.0 and above.

### Minimal Example:

```
@flow
async def f_some_import() -> None:
    connection = await SqlAlchemyConnector.load(INSERT_BLOCK_NAME_HERE)
    query = f""SELECT * FROM dbo.{table}""
    with connection as conn:
        result = conn.fetch_all(operation=query)
```
With SQLAlchemy < 2.0.0, this returns results as expected.
With SQLAlchemy â‰¥ 2.0.0, `fetch_all()` always returns an **empty result set**.

### Findings:
The issue appears to be due to a `commit()` call inside the `_async_sync_execute()` method. If lines 504â€“505 (where `commit()` is invoked) are commented out, the `SELECT` query works properly and returns results.
 
![Image](https://github.com/user-attachments/assets/4ed5bc50-7d34-489a-bc4e-24c879b3c1e5)

According to the [SQLAlchemy 2.0 documentation](https://docs.sqlalchemy.org/en/20/orm/session_basics.html#opening-and-closing-a-session), `commit()` is not required â€” and should not be used â€” for pure `SELECT` operations.

### Environment:

- Database: Microsoft SQL Server
- Driver: mssql+pymssql
- SQLAlchemy version: 2.0.0 and above

### Version info

```Text
Version:             2.20.15
API version:         0.8.4
Python version:      3.10.17
Git commit:          b21233f3
Built:               Wed, Nov 27, 2024 10:45 AM
OS/Arch:             linux/x86_64
Profile:             postgres
Server type:         server
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17996/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17996
17989,"Extra inputs are not permitted: loc': ['body', 'version_info']",closed,not_planned,2025-05-06T02:32:32Z,2025-05-06T03:19:11Z,2025-05-06T03:19:10Z,3,[],Gunnar-Stunnar,,NONE,"### Bug summary

today I started experience this deployment error in my CICD pipeline

current deployment code:
```python
git_repo = GitRepository(
        url=""..."",
        credentials=GitHubCredentials.load(""el-document-code"")
    )

    flow.from_source(
            source=git_repo,
            entrypoint=""src/flows/<flow entrypoint>"",
        ).deploy(
        name=""inference"",
        image=docker image,
        work_pool_name=""..."",
        work_queue_name=""..."",
        push=False
    )
``` 

Current stack trace:
```
Traceback (most recent call last):
  File ""/runner/_work/.../.../deployFlow.py"", line 97, in <module>
    main()
  File ""/runner/_work/.../.../deployFlow.py"", line 94, in main
    deploy_flows(worker_pools)
  File ""/runner/_work/.../.../deployFlow.py"", line 65, in deploy_flows
    flow.from_source(
  File ""/opt/hostedtoolcache/Python/3.10.4/x64/lib/python3.10/site-packages/prefect/utilities/asyncutils.py"", line [351](https://github.com/Stunn-Inc/AzureFR-validator/actions/runs/14849701852/job/41692531275#step:6:352), in coroutine_wrapper
    return run_coro_as_sync(ctx_call())
  File ""/opt/hostedtoolcache/Python/3.10.4/x64/lib/python3.10/site-packages/prefect/utilities/asyncutils.py"", line 207, in run_coro_as_sync
    return call.result()
  File ""/opt/hostedtoolcache/Python/3.10.4/x64/lib/python3.10/site-packages/prefect/_internal/concurrency/calls.py"", line 329, in result
    return self.future.result(timeout=timeout)
  File ""/opt/hostedtoolcache/Python/3.10.4/x64/lib/python3.10/site-packages/prefect/_internal/concurrency/calls.py"", line 192, in result
    return self.__get_result()
  File ""/opt/hostedtoolcache/Python/3.10.4/x64/lib/python3.10/concurrent/futures/_base.py"", line 391, in __get_result
    raise self._exception
  File ""/opt/hostedtoolcache/Python/3.10.4/x64/lib/python3.10/site-packages/prefect/_internal/concurrency/calls.py"", line 405, in _run_async
    result = await coro
  File ""/opt/hostedtoolcache/Python/3.10.4/x64/lib/python3.10/site-packages/prefect/utilities/asyncutils.py"", line 188, in coroutine_wrapper
    return await task
  File ""/opt/hostedtoolcache/Python/3.10.4/x64/lib/python3.10/site-packages/prefect/utilities/asyncutils.py"", line 341, in ctx_call
    result = await async_fn(*args, **kwargs)
  File ""/opt/hostedtoolcache/Python/3.10.4/x64/lib/python3.10/site-packages/prefect/flows.py"", line 1554, in deploy
    deployment_ids = await deploy_coro
  File ""/opt/hostedtoolcache/Python/3.10.4/x64/lib/python3.10/site-packages/prefect/utilities/asyncutils.py"", line 341, in ctx_call
    result = await async_fn(*args, **kwargs)
  File ""/opt/hostedtoolcache/Python/3.10.4/x64/lib/python3.10/site-packages/prefect/deployments/runner.py"", line 1281, in deploy
    await deployment.apply(image=image_ref, work_pool_name=work_pool_name)
  File ""/opt/hostedtoolcache/Python/3.10.4/x64/lib/python3.10/site-packages/prefect/utilities/asyncutils.py"", line 341, in ctx_call
    result = await async_fn(*args, **kwargs)
  File ""/opt/hostedtoolcache/Python/3.10.4/x64/lib/python3.10/site-packages/prefect/deployments/runner.py"", line 505, in apply
    return await self._create(work_pool_name, image, version_info)
  File ""/opt/hostedtoolcache/Python/3.10.4/x64/lib/python3.10/site-packages/prefect/deployments/runner.py"", line 394, in _create
    raise DeploymentApplyError(
prefect.deployments.runner.DeploymentApplyError: Error while applying deployment: Client error '422 Unprocessable Entity' for url '***/deployments/'
Response: {'exception_message': 'Invalid request received.', 'exception_detail': [{'type': 'extra_forbidden', 'loc': ['body', 'version_info'], 'msg': 'Extra inputs are not permitted', 'input': {'type': 'vcs:github', 'version': 'fe998bb8', 'commit_sha': 'fe998bb8b2de0ba05ca122f8975a8af6ad7b0d9b', 'message': 'Merge pull request #97 from Stunn-Inc/NoAzure_prefect', 'branch': 'master', 'repository': 'Stunn-Inc/AzureFR-validator', 'url': 'https://github.com/Stunn-Inc/AzureFR-validator/tree/fe998bb8b2de0ba05ca122f8975a8af6ad7b0d9b'}}], 'request_body': {'name': 'RA-documentai-workPool-dev', 'flow_id': '7b1a27d1-52eb-493b-9da2-3ec8559d2dca', 'paused': False, 'schedules': [], 'concurrency_limit': None, 'concurrency_options': None, 'enforce_parameter_schema': True, 'parameter_openapi_schema': {'title': 'Parameters', 'type': 'object', 'properties': {'fileReference': {'position': 0, 'title': 'fileReference'}}, 'required': ['fileReference']}, 'parameters': {}, 'tags': [], 'labels': {}, 'pull_steps': [{'prefect.deployments
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/422
```

### Version info

```Text
prefect version: 3.4.0
prefect-github version: 0.3.1
prefect-server version: 3.2.13
```

### Additional context

Just start receiving this error today, it was working and fully deploying the last few days ",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17989/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17989
17988,flow crashes due to FileNotFoundError from uv at import,closed,completed,2025-05-05T22:38:33Z,2025-05-06T18:14:51Z,2025-05-06T18:14:51Z,3,['bug'],rcash,,CONTRIBUTOR,"### Bug summary

uv raises a [FileNotFoundError](https://github.com/astral-sh/uv/blob/3218e364ae97d8bf1fe2007af7ec243e05b44da2/python/uv/_find_uv.py#L36) in new versions of Prefect at import when trying to kick a flow run off - when importing [bundles.py](https://github.com/PrefectHQ/prefect/blob/3.3.5/src/prefect/_experimental/bundles.py#L25) or functionality related to it. this is seen because the path `uv` looks for its binary at does not appear to match the Python installation used (Anaconda), in this case at least.

stack trace
```
19:27:46.471 | ERROR   | Flow run 'phi5-iyaar' - Unexpected exception encountered when trying to load flow
Traceback (most recent call last):
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/engine.py"", line 112, in <module>
    flow: ""Flow[..., Any]"" = load_flow(flow_run)
                             ^^^^^^^^^^^^^^^^^^^
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/flow_engine.py"", line 140, in load_flow
    flow = run_coro_as_sync(
           ^^^^^^^^^^^^^^^^^
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/utilities/asyncutils.py"", line 207, in run_coro_as_sync
    return call.result()
           ^^^^^^^^^^^^^
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py"", line 329, in result
    return self.future.result(timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py"", line 192, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File ""/home/ray/anaconda3/lib/python3.11/concurrent/futures/_base.py"", line 401, in __get_result
    raise self._exception
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py"", line 405, in _run_async
    result = await coro
             ^^^^^^^^^^
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/utilities/asyncutils.py"", line 188, in coroutine_wrapper
    return await task
           ^^^^^^^^^^
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/client/utilities.py"", line 69, in wrapper
    return await func(client, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/flows.py"", line 2518, in load_flow_from_flow_run
    from prefect.deployments.steps.core import StepExecutionError, run_steps
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/deployments/steps/__init__.py"", line 2, in <module>
    from .pull import (
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/deployments/steps/pull.py"", line 12, in <module>
    from prefect.runner.storage import BlockStorageAdapter, GitRepository, RemoteStorage
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/runner/__init__.py"", line 1, in <module>
    from .runner import Runner
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/runner/runner.py"", line 72, in <module>
    from prefect._experimental.bundles import (
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/_experimental/bundles.py"", line 28, in <module>
    uv_path = uv.find_uv_bin()
              ^^^^^^^^^^^^^^^^
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/uv/_find_uv.py"", line 36, in find_uv_bin
    raise FileNotFoundError(path)
FileNotFoundError: /home/ray/.local/bin/uv
19:27:46.483 | ERROR   | prefect.engine - Execution of flow run 'f43cc11f-5ba4-459d-91b0-7e02270af306' exited with unexpected exception
Traceback (most recent call last):
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/engine.py"", line 57, in handle_engine_signals
    yield
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/engine.py"", line 112, in <module>
    flow: ""Flow[..., Any]"" = load_flow(flow_run)
                             ^^^^^^^^^^^^^^^^^^^
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/flow_engine.py"", line 140, in load_flow
    flow = run_coro_as_sync(
           ^^^^^^^^^^^^^^^^^
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/utilities/asyncutils.py"", line 207, in run_coro_as_sync
    return call.result()
           ^^^^^^^^^^^^^
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py"", line 329, in result
    return self.future.result(timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py"", line 192, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File ""/home/ray/anaconda3/lib/python3.11/concurrent/futures/_base.py"", line 401, in __get_result
    raise self._exception
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py"", line 405, in _run_async
    result = await coro
             ^^^^^^^^^^
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/utilities/asyncutils.py"", line 188, in coroutine_wrapper
    return await task
           ^^^^^^^^^^
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/client/utilities.py"", line 69, in wrapper
    return await func(client, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/flows.py"", line 2518, in load_flow_from_flow_run
    from prefect.deployments.steps.core import StepExecutionError, run_steps
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/deployments/steps/__init__.py"", line 2, in <module>
    from .pull import (
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/deployments/steps/pull.py"", line 12, in <module>
    from prefect.runner.storage import BlockStorageAdapter, GitRepository, RemoteStorage
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/runner/__init__.py"", line 1, in <module>
    from .runner import Runner
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/runner/runner.py"", line 72, in <module>
    from prefect._experimental.bundles import (
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/prefect/_experimental/bundles.py"", line 28, in <module>
    uv_path = uv.find_uv_bin()
              ^^^^^^^^^^^^^^^^
  File ""/home/ray/anaconda3/lib/python3.11/site-packages/uv/_find_uv.py"", line 36, in find_uv_bin
    raise FileNotFoundError(path)
FileNotFoundError: /home/ray/.local/bin/uv
```

### Version info

```Text
3.3.5
```

### Additional context

this seems like it could be an upstream issue due to how `uv` resolves the path to itself, but also makes me wonder if this could have any broader impact on `conda` users of Prefect",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17988/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17988
17984,"this is a test, please ignore",closed,completed,2025-05-05T19:54:35Z,2025-05-05T20:27:28Z,2025-05-05T19:55:05Z,1,['bug'],cicdw,,MEMBER,"### Bug summary

![Image](https://media0.giphy.com/media/v1.Y2lkPTc5MGI3NjExNnFjODFuYmV2ZjZibWV4NmtrY2x2aDJ2MHdjeWsybWpqbmlmanBmNSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/hzpn4rIxysA7471IwF/giphy.gif)

### Version info

```Text
n/a
```

### Additional context

_No response_",cicdw,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17984/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17984
17982,UI Deployment Schedule Enable/Disable toggle resets Parameters Overrides,closed,completed,2025-05-05T17:43:44Z,2025-05-06T00:00:41Z,2025-05-06T00:00:11Z,1,['bug'],gabr1elt,znicholasbrown,NONE,"### Bug summary

Parameters overrides in schedules are reset (dissapear) after enabling/disabling the schedule.

### To reproduce

Set a parameter override on a schedule (from API or UI)
Enable or disable the Schedule.
Parameter override dissapears

### Version info

```Text
docker.io/prefecthq/prefect:3.4.0-python3.10
```

### Additional context

Maybe related to #17782 ",znicholasbrown,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17982/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17982
17977,Prefect UI overwrites the url of my link Artifact,closed,completed,2025-05-04T19:49:00Z,2025-05-13T22:38:43Z,2025-05-08T19:32:17Z,5,['bug'],liviumanea,znicholasbrown,NONE,"### Bug summary

In my prefect deployment I have to run it behind nginx in order to be able to serve the link artifacts and I have to configure prefect as follows so that it works behind nginx:

```Dockerfile
ENV PREFECT_SERVER_API_BASE_PATH=/prefect/api \
    PREFECT_API_URL=http://localhost:4200/prefect/api \
    PREFECT_UI_API_URL=/prefect/api \
    PREFECT_UI_SERVE_BASE=/prefect
```

In my flows, I am creating artifacts with the following code:

```python
    await create_link_artifact(
        key=""pga-report"",
        link=""http://localhost:8200/prefect/products/2025/05/04/pga-report.pdf"",
        link_text=""PGA Report"",
        description=""""""
        # PGA Report

        this is the pga report
        """""",
    )
```

When I go look at this artifact, I see the following data from the backend

```json
{""id"":""4a61752c-1735-41c6-a7d7-ea4a16604f24"",""created"":""2025-05-04T19:03:20.506642Z"",""updated"":""2025-05-04T19:03:20.506642Z"",""key"":""pga-report"",""type"":""markdown"",""description"":""\n        # PGA Report\n\n        this is the pga report\n        "",""data"":""[PGA Report](http://localhost:8200/prefect/products/2025/05/04/pga-report.pdf)"",""metadata_"":null,""flow_run_id"":""c6750171-cf29-4089-8a0c-0c79122e8ad4"",""task_run_id"":null}
```

If I visit `localhost:8200/prefect/products/2025/05/04/pga-report.pdf` in my browser then I can access the pdf file just fine. If I hover over the link on the artifact page the link looks like this:
`http://localhost:8200/prefect/prefect/products/2025/05/04/pga-report.pdf`. So it somehow adds another ""prefect"" in there and I don't know how to stop that. If I click that link, the UI tries to navigate as a single page app to that instead of just rendering the file in a new tab as I would like.

If I add a link that's completely unrelated to my prefect paths, for example

```python
link=""https://www.prefect.io/""
```

Then it's not messing with it.

Also, here is how I'm forwarding traffic with nginx onto Prefect

```text
  server {
    listen 80;

    # Serve static PDFs
    location /prefect/products/ {
      alias /usr/share/nginx/html/products/;
      autoindex on;
    }

    # Proxy to Prefect (UI and API)
    location /prefect {
      proxy_pass http://prefect:4200/prefect;
      proxy_http_version 1.1;

      proxy_set_header Host $host;
      proxy_set_header X-Real-IP $remote_addr;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
      proxy_set_header X-Forwarded-Proto $scheme;

    }
```

What I really wanted to do is set the link to something unrelated to prefect like

```text
http://localhost:8200/products/2025/05/04/pga-report.pdf
```

### Version info

```Text
Version:             3.3.7
API version:         0.8.4
Python version:      3.13.3
Git commit:          8f86aaee
Built:               Mon, Apr 28, 2025 03:04 PM
OS/Arch:             linux/aarch64
Profile:             ephemeral
Server type:         server
Pydantic version:    2.11.4
```

### Additional context

_No response_",znicholasbrown,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17977/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17977
17971,Unable to use PREFECT_API_AUTH_STRING with task worker based on `serve`,closed,completed,2025-05-02T19:55:53Z,2025-05-05T01:44:42Z,2025-05-05T01:44:42Z,1,"['bug', 'great writeup']",Rahlir,,NONE,"### Bug summary

I have a self-hosted kubernetes based prefect server. The prefect server is setup with `PREFECT_SERVER_API_AUTH_STRING`. Everything works fine as long as I use a dedicated kubernetes prefect worker based on helm. However, I am also trying to deploy a task-worker using a docker image that runs:
```python
from prefect.task_worker import serve
...
if __name__ == '__main__':
    serve(some_task)
```

This doesn't seem to work. When the pod based on this image starts up, I get an error:
```
Unable to authenticate to the subscription. Please ensure the provided `PREFECT_API_KEY` you are using is valid for this environment. Reason: Auth required but no token provided
```

I also tried to set `PREFECT_API_KEY={username}:{password}`. This _seemingly works at first_, the pod spins up just fine. However, when new task run is created and the task-runner tries to run it, I get an error:
```
Client error '401 Unauthorized' for url 'http://{my-server}:4200/api/csrf-token?client=fb8c9655-5f2a-4cc7-9ed7-ee803fb006a8'
```
which makes sense I guess, since the task-worker is probably using `API_KEY` instead of `AUTH_STRING` due to how priorities are setup.

I am guessing the problem is in `src/prefect/client/subscriptions.py`. For some reason on [line 81](https://github.com/PrefectHQ/prefect/blob/c80e444246c8805f1dfb684267e0d88dbfcc8d38/src/prefect/client/subscriptions.py#L81), the client uses `PREFECT_API_KEY` no matter whether `PREFECT_AUTH_STRING` is set or not. I am guessing server **expects a token** because `PREFECT_SERVER_API_AUTH_STRING` is set, but client only sends `PREFECT_API_KEY`, which should be unset when `PREFECT_API_AUTH_STRING` is used...

### Version info

```Text
Version:             3.3.5
API version:         0.8.4
Python version:      3.11.9
Git commit:          db4b7a33
Built:               Thu, Apr 17, 2025 09:25 PM
OS/Arch:             darwin/arm64
Profile:             local
Server type:         server
Pydantic version:    2.11.3
Integrations:
  prefect-kubernetes: 0.5.10
```

### Additional context

_No response_",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17971/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17971
17968,[ui] SendGrid Email Block doesn't show python code snippet correctly,open,,2025-05-02T15:25:14Z,2025-05-05T17:21:17Z,,0,['bug'],devinvillarosa,devinvillarosa,CONTRIBUTOR,"### Bug summary

When viewing the details of my SendGrid Email block, the python code snippet isn't parsing correctly.

Seems like `block_type.code_example` is not parsing correctly with https://github.com/PrefectHQ/prefect-ui-library/blob/main/src/components/BlockTypeSnippet.vue#L17

![Image](https://github.com/user-attachments/assets/45c13c9f-1f4e-402f-bee4-ac3a4d4b9bc7)

### Version info

```Text
Version:             3.3.6
API version:         0.8.4
Python version:      3.11.11
Git commit:          01441afa
Built:               Thu, Apr 24, 2025 07:26 PM
OS/Arch:             darwin/arm64
Profile:             local
Server type:         server
Pydantic version:    2.10.4
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17968/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17968
17964,`prefect work-pool create --type cloud-run:push --provision-infra` creates service account in wrong project if not using default,closed,completed,2025-05-02T07:48:14Z,2025-05-02T13:40:22Z,2025-05-02T13:40:22Z,0,['bug'],danfairs,,CONTRIBUTOR,"### Bug summary

`prefect work-pool create --type cloud-run:push --provision-infra` does not seem to respect the project selection when creating infrastructure, instead just using whatever default project the user has set. The bug is visible in this output, where I have replaced my preferred target project with MY_PROJECT, and whatever is set as my gcloud default project as OTHER_PROJECT:

```
Activating Cloud Run API
Activating Artifact Registry API
Creating Artifact Registry repository
Error running command:
{
    'command': 'gcloud artifacts repositories create prefect-images --repository-format=docker --location=europe-west2 --project=MY_PROJECT',
    'stdout': '',
    'stderr': 'ERROR: (gcloud.artifacts.repositories.create) ALREADY_EXISTS: the repository already exists\n'
}
Configuring authentication to Artifact Registry
Setting default Docker build namespace
Creating service account
Error running command:
{
    'command': 'gcloud iam service-accounts create prefect-cloud-run --display-name ""Prefect Cloud Run Service Account""',
    'stdout': '',
    'stderr': ""ERROR: (gcloud.iam.service-accounts.create) Resource in projects [OTHER_PROJECT] is the subject of a conflict: Service account prefect-cloud-run already exists within project
projects/OTHER_PROJECT.\n- '@type': type.googleapis.com/google.rpc.ResourceInfo\n  resourceName:
projects/OTHER_PROJECT/serviceAccounts/prefect-cloud-run@OTHER_PROJECT.iam.gserviceaccount.com\n""
}
Assigning roles to service account
Error running command:
{
    'command': 'gcloud projects add-iam-policy-binding MY_PROJECT --member=""serviceAccount:prefect-cloud-run@MY_PROJECT.iam.gserviceaccount.com"" --role=""roles/iam.serviceAccountUser""',
    'stdout': '',
    'stderr': 'ERROR: Policy modification failed. For a binding with condition, run ""gcloud alpha iam policies lint-condition"" to identify issues in condition.\nERROR:
(gcloud.projects.add-iam-policy-binding) INVALID_ARGUMENT: Service account prefect-cloud-run@MY_PROJECT.iam.gserviceaccount.com does not exist.\n'
}
Provisioning Infrastructure â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•¸â”â”â”â”â”â”â”â”â”â”â”â”â”  67% 0:00:02
Failed to provision infrastructure: Error assigning roles to service account. Please ensure you have the necessary permissions.
``` 

You can see that the command Prefect is running to create the service account does _not_ specify the project.

I was able to work around this by temporarily setting my default project to MY_PROJECT.

### Version info

```Text
Version:             3.3.3
API version:         0.8.4
Python version:      3.11.10
Git commit:          4100d4ea
Built:               Sat, Apr 05, 2025 01:44 AM
OS/Arch:             darwin/arm64
Profile:             local
Server type:         cloud
Pydantic version:    2.11.3
```

### Additional context

_No response_",desertaxle,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17964/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17964
17963,Better documentation for parameters including BaseModel parameter groups,closed,completed,2025-05-02T07:12:33Z,2025-05-05T15:55:02Z,2025-05-05T15:55:02Z,1,['enhancement'],bkkkk,,CONTRIBUTOR,"### Describe the current behavior

The documentation around parameters is good to get people started but there's a lot of details and more advanced features that are not documented, particularly around BaseModel groups and how the UI handles different data types.

### Describe the proposed behavior

The documentation for parameters could be way more helpful for end users. Off the top of my head we've encountered the following issues where documentation would've been helped:

* Using a `pendulum.Date` parameter renders a nice UI element in Cloud but `pendulum.DateTime` doesn't. It would be helpful to have a table with some kind of ""support"" tier for data types.
* Parameter groups using BaseModel behave quite differently and provide additional options above and beyond regular ""function argument"" parameters but these options are not really documented anywhere (As far as I can tell but maybe I'm wrong) and I end up finding out about these features when posting on Slack. Special features includes things like title to control the formatting of the field title in the UI, description to provide better documentation (using markdown for formatting), and position to determine the order of fields in the *Custom Run* form.

Happy to take a crack at the BaseModel docs part. Before I do that though I wanted to bring this up for discussion. It would be a shame for changes to be made such that the docs become outdated. It's maybe not worth starting if there's no appetite to take this on longer term.

### Example Use

_No response_

### Additional context

_No response_",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17963/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17963
17958,Flow run heartbeats accumulating until the end of a run,closed,completed,2025-05-01T17:59:34Z,2025-05-06T17:21:01Z,2025-05-06T17:21:01Z,2,['bug'],chrisguidry,,COLLABORATOR,"### Bug summary

We've had some reports from customers of a situation where automations they have set up on `prefect.flow-run.heartbeat` events are misbehaving.  In the several cases we've seen, we notice a pattern like this:

![Image](https://github.com/user-attachments/assets/8465d828-c556-4b9c-b758-66125a0ab143)

Where there's a long gap of hours between when a heartbeat _occurs_ and when it is _received_ by a Prefect server (Prefect Cloud in the pictured case).  In these cases,  we'll see that the events appear to all have `occurred` times correctly spaced out through the full duration of the flow run, but they all arrive (`received`) at the end very close to the `prefect.flow-run.Completed` event.

![Image](https://github.com/user-attachments/assets/c5ea7b43-ea06-4d18-86a5-0ebdb1fca86e)



### Version info

```Text
We have observed this in Prefect 3.2 and 3.3 clients, don't have specific version details.
```

### Additional context

_No response_",desertaxle,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17958/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17958
17956,ModuleNotFoundError with Kubernetes Dask task runner,open,,2025-05-01T12:36:44Z,2025-05-06T16:18:55Z,,7,['bug'],TWeatherston,,NONE,"### Bug summary

I'm honestly not too sure if this is a bug in Prefect or some issue with our setup but, after spending a couple of days trying to resolve it, I'm hoping you can point me in the right direction!

We are upgrading our Prefect from 2 -> 3. We have a number of flows that are running in Kubernetes using the Dask task runner. These flows work fine in Prefect 2 but always fail in 3 due to a `ModuleNotFoundError`. Non Dask flows all complete successfully.

A cut down example of code that is failing
```python
@flow(
    name=""Daily Collection"",
    task_runner=DaskTaskRunner(
        cluster_class=""dask_kubernetes.operator.KubeCluster"",
        adapt_kwargs={""minimum"": 15, ""maximum"": 200},
    ),
)
def daily_collection(
    collection_date: Optional[datetime.date] = None,
    feed_names: Optional[list[str]] = None,
):
    api = APIClient.load(""default"")

    feed_names = feed_names or get_list_of_feeds(api)
    file_name_futures = [get_file_names.submit(api, feed, collection_date) for feed in feed_names]
    file_names = [f.result() for f in file_name_futures]
```

The flows will fail with the following stacktrace:
```
Engine execution exited with unexpected exception
Traceback (most recent call last):
  File ""/usr/local/lib/python3.11/site-packages/distributed/scheduler.py"", line 4852, in update_graph
    graph = deserialize(graph_header, graph_frames).data
    ^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.11/site-packages/distributed/protocol/serialize.py"", line 452, in deserialize
    return loads(header, frames)
      ^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.11/site-packages/distributed/protocol/serialize.py"", line 111, in pickle_loads
    return pickle.loads(pik, buffers=buffers)
      ^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.11/site-packages/distributed/protocol/pickle.py"", line 92, in loads
    return pickle.loads(x)
    ^^^^^^^^^^^^^^^^^
ModuleNotFoundError: No module named 'collection_flow'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/usr/local/lib/python3.11/site-packages/prefect/flow_engine.py"", line 1527, in run_flow
    ret_val = run_flow_sync(**kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.11/site-packages/prefect/flow_engine.py"", line 1372, in run_flow_sync
    return engine.state if return_type == ""state"" else engine.result()
                                                       ^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.11/site-packages/prefect/flow_engine.py"", line 350, in result
    raise self._raised
  File ""/usr/local/lib/python3.11/site-packages/prefect/flow_engine.py"", line 763, in run_context
    yield self
  File ""/usr/local/lib/python3.11/site-packages/prefect/flow_engine.py"", line 1370, in run_flow_sync
    engine.call_flow_fn()
  File ""/usr/local/lib/python3.11/site-packages/prefect/flow_engine.py"", line 783, in call_flow_fn
    result = call_with_parameters(self.flow.fn, self.parameters)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.11/site-packages/prefect/utilities/callables.py"", line 210, in call_with_parameters
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File ""/opt/prefect/atheon_prefect/flows/collection/collection_flow.py"", line 186, in daily_collection
    result = future.result()
             ^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.11/site-packages/prefect_dask/task_runners.py"", line 135, in result
    future_result = self._wrapped_future.result(timeout=timeout)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.11/site-packages/distributed/client.py"", line 402, in result
    return self.client.sync(self._result, callback_timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.11/site-packages/distributed/client.py"", line 410, in _result
    raise exc.with_traceback(tb)
RuntimeError: Error during deserialization of the task graph. This frequently
occurs if the Scheduler and Client have different environments.
For more information, see
https://docs.dask.org/en/stable/deployment-considerations.html#consistent-software-environments
```

It runs perfectly fine if I run locally, using a local Dask cluster so I think it could be something to do with the Docker image but, as mentioned, this runs fine using essentially the same Docker image with Prefect 2.


### Version info

```Text
Version:             3.3.7
API version:         0.8.4
Python version:      3.11.11
Git commit:          8f86aaee
Built:               Mon, Apr 28, 2025 03:04 PM
OS/Arch:             darwin/arm64
Profile:             staging
Server type:         cloud
Pydantic version:    2.11.2
Integrations:
  prefect-gcp:       0.6.5
  prefect-dask:      0.3.5
  prefect-dbt:       0.6.6
  prefect-github:    0.3.1
  prefect-snowflake: 0.28.2
  prefect-aws:       0.5.9
  prefect-shell:     0.3.1
```

### Additional context

Looking at the various containers, I can see that the Prefect container, Dask worker and Dask scheduler all have the same file structure and PYTHONPATH (checked this as it's usually the issue for this kind of error)
",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17956/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17956
17955,Flow runs get stuck after server reboot in Kubernetes setup with Prefect 3,closed,completed,2025-04-30T22:10:16Z,2025-05-13T00:08:23Z,2025-05-13T00:08:22Z,4,['bug'],maitlandmarshall,,CONTRIBUTOR,"### Bug summary

**Description:**  
I am experiencing an issue in Prefect 3 with a setup consisting of a Kubernetes worker, Kubernetes self-hosted API, and Postgres database. When a flow run is in a running or pending state and the servers are rebooted (e.g., for weekly updates), the flow run remains stuck in that state permanently. This issue is particularly problematic when combined with concurrency limits set to cancel mode, as it causes all subsequent flows to be cancelled indefinitely.

**Steps to Reproduce:**  
1. Set up a Prefect 3 environment with a Kubernetes worker, Kubernetes self-hosted API, and Postgres database.  
2. Create a flow with concurrency limit 1 and set to cancel mode.  
3. Start a flow run.  
4. Reboot the servers while the flow run is in a running or pending state.  
5. Observe that the flow run remains stuck in its current state, and subsequent flows are cancelled indefinitely due to the concurrency limits.

**Expected Behavior:**  
After the servers are rebooted, the flow run should handle the disruption gracefully. It should either resume, be retried, or be marked as failed, but not remain stuck indefinitely.

**Actual Behavior:**  
The flow run remains stuck in the running or pending state. Additionally, when concurrency limits are set to cancel mode, all subsequent flows are cancelled indefinitely.

### Version info

```Text
- Prefect Version: 3.2.7
- Python Version: 3.11 
- OS/Arch: azure linux
- Kubernetes Version: v1.30.11 
- Postgres Version: 12.11.1
```

```yaml
chart: prefect/prefect-worker
version: 2025.2.21193831
```

```bash
pip show prefect-kubernetes
Name: prefect-kubernetes
Version: 0.5.3
Summary: Prefect integrations for interacting with Kubernetes.
Home-page:
Author:
Author-email: ""Prefect Technologies, Inc."" <help@prefect.io>
License: Apache License 2.0
Location: /usr/local/lib/python3.11/site-packages
Requires: exceptiongroup, kubernetes-asyncio, prefect, pyopenssl, tenacity
Required-by:
```

### Additional context

- This issue might be related to past issues in Prefect 2, such as [PrefectHQ/prefect#8409](https://github.com/PrefectHQ/prefect/issues/8409), which reported similar problems with Kubernetes flow runs remaining stuck after pod restarts. However, I could not find a specific fix for this issue in Prefect 3.  ",maitlandmarshall,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17955/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17955
17947,Prefect 2 incompatibility with Pydantic 2.11.4,closed,completed,2025-04-30T14:17:21Z,2025-04-30T20:19:36Z,2025-04-30T20:18:44Z,4,"['bug', 'upstream dependency']",j-tr,,CONTRIBUTOR,"### Bug summary

The latest Pydantic version (2.11.4) that has been released yesterday is not compatible with the latest Prefect 2 version (2.20.17).

```
$ pip show pydantic
WARNING: Package(s) not found: pydantic
$ pip install prefect==2.20.17
 ....
$ pip show pydantic
Name: pydantic
Version: 2.11.4
Summary: Data validation using Python type hints
Home-page: 
Author: 
Author-email: Samuel Colvin <s@muelcolvin.com>, Eric Jolibois <em.jolibois@gmail.com>, Hasan Ramezani <hasan.r67@gmail.com>, Adrian Garcia Badaracco <1755071+adriangb@users.noreply.github.com>, Terrence Dorsey <terry@pydantic.dev>, David Montague <david@pydantic.dev>, Serge Matveenko <lig@countzero.co>, Marcelo Trylesinski <marcelotryle@gmail.com>, Sydney Runkle <sydneymarierunkle@gmail.com>, David Hewitt <mail@davidhewitt.io>, Alex Hall <alex.mojaki@gmail.com>, Victorien Plot <contact@vctrn.dev>
License: 
Location: /usr/local/lib/python3.12/site-packages
Requires: annotated-types, pydantic-core, typing-extensions, typing-inspection
Required-by: prefect
$ prefect
Traceback (most recent call last):
  File ""/usr/local/bin/prefect"", line 5, in <module>
    from prefect.cli import app
  File ""/usr/local/lib/python3.12/site-packages/prefect/cli/__init__.py"", line 13, in <module>
    import prefect.cli.shell
  File ""/usr/local/lib/python3.12/site-packages/prefect/cli/shell.py"", line 56, in <module>
    @flow
     ^^^^
  File ""/usr/local/lib/python3.12/site-packages/prefect/flows.py"", line 1563, in flow
    Flow(
  File ""/usr/local/lib/python3.12/site-packages/prefect/context.py"", line 188, in __register_init__
    original_init(__self__, *args, **kwargs)
  File ""/usr/local/lib/python3.12/site-packages/prefect/flows.py"", line 347, in __init__
    self.parameters = parameter_schema(self.fn)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/prefect/utilities/callables.py"", line 325, in parameter_schema
    return generate_parameter_schema(signature, docstrings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/prefect/utilities/callables.py"", line 408, in generate_parameter_schema
    schema = create_schema(""Parameters"", model_cfg=ModelConfig, **model_fields)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/prefect/_internal/pydantic/v2_schema.py"", line 132, in create_v2_schema
    model = create_model(
            ^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/pydantic/main.py"", line 1761, in create_model
    return meta(
           ^^^^^
  File ""/usr/local/lib/python3.12/site-packages/pydantic/_internal/_model_construction.py"", line 110, in __new__
    config_wrapper = ConfigWrapper.for_model(bases, namespace, kwargs)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/pydantic/_internal/_config.py"", line 138, in for_model
    config_new.update(config_from_namespace)
TypeError: 'type' object is not iterable

```


### Version info

```Text
no output of prefect version, since the prefect command errors out.
```

### Additional context

_No response_",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17947/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17947
17945,Support AST fallback in flow.from_source() when ModuleNotFoundError occurs,open,,2025-04-30T13:14:21Z,2025-04-30T13:41:46Z,,2,['enhancement'],polwayne,,NONE,"**Summary:**
Currently, flow.from_source() crashes with a MissingFlowError when imported dependencies are missingâ€”even if the flow is correctly decorated with @flow. This makes it hard to inspect flows in deployment automation when not all runtime dependencies are installed.

**Use case:**
Iâ€™m using flow.from_source() on the server side to introspect flows and generate deployments (e.g., to extract parameter schemas). The problem is that flows may import packages like numpy, which arenâ€™t installed on the server thatâ€™s only responsible for deploying the flow, not executing it.

In Prefectâ€™s internal method load_flow_from_entrypoint, thereâ€™s already a fallback mechanism that uses AST parsing when a ScriptError occurs (like ModuleNotFoundError). But flow.from_source() doesnâ€™t currently support this fallback and raises a misleading MissingFlowError.

**Proposed behavior:**
Extend flow.from_source() to:
	â€¢	Catch ModuleNotFoundError, ImportError, or ScriptError
	â€¢	Fallback to safe_load_flow_from_entrypoint() as in load_flow_from_entrypoint
	â€¢	Or at least raise a clearer error message when the flow canâ€™t be loaded due to missing dependencies

**Why this is important:**
This would greatly improve developer experience and automation use cases around deployment creation pipelines in environments that do not have full runtime dependencies installed.",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17945/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17945
17944,[UI] Change the state of multiple flow runs at once,open,,2025-04-30T06:42:49Z,2025-05-05T16:47:00Z,,1,"['enhancement', 'ui']",Moortiii,,NONE,"### Describe the current behavior

In the current UI it is not possible to change the state for multiple Flow runs easily from the Runs tab. To achieve this you must either use the Prefect CLI, or the Prefect API.

### Describe the proposed behavior

In a previous release, the ability to delete multiple Flow runs from the Flow Run page was added. Make it possible to bulk-select Flow runs in the same way, and use this to change the state instead of deleting the flow runs.

### Example Use

**Health monitoring example:**

An issue with a third-party causes multiple flow runs to fail in a row (100+). External monitoring picks this up and reports that there are many failed jobs. This raises alarms and someone is dispatched to investigate. Once the issue is resolved, they want to change state of the flows, in order to show that everything is operating as expected again. Deleting the flows is poor practice, because it erases the history of the flow run. Normally, at this point, the user would have to run a script that leverages the Prefect CLI or Prefect API in order to bulk-update flow state.

With this new feature, the user would instead navigate to the ""Runs"" tab. Next, they select the necessary filters and tags they, and click on the ""Select all"" checkbox (or individual checkboxes). A new button is introduced that allows them to update the state for the selected flow runs. This brings up the same modal that is shown when updating the state for a single flow run. The user chooses the new state, and provides an optional description. This state-change is then applied to all selected flows.

The user has now changed the state for multiple flows, without having to leverage API-keys, or needing to install and use the Prefect CLI.

### Additional context

At our organization, users rarely have the Prefect CLI installed on their local system, as flows are deployed automatically by CI/CD and have their schedule pre-configured. For obvious reasons, we want to limit how frequently users have to reach for the Prefect API.

The example above is highly specific to (one of) the ways we perform health-monitoring of Prefect flow runs, but the feature itself feels like a natural extension to the Runs tab in Prefect 3.",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17944/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17944
17941,Links to parameters subsection in the Write Flows chapter are broken,closed,completed,2025-04-30T00:48:05Z,2025-04-30T02:22:44Z,2025-04-30T02:22:44Z,0,['bug'],bkkkk,,CONTRIBUTOR,"### Bug summary

There are currently 2 document links in the [Write and run flows](https://docs.prefect.io/v3/develop/write-flows) chapter that are meant to take people to the section called [Specify flow parameters](https://docs.prefect.io/v3/develop/write-flows#specify-flow-parameters) in that chapter and both of them are broken.

Happy to open a PR to address this issue.

### Version info

```Text
Version:             3.3.4
API version:         0.8.4
Python version:      3.11.11
Git commit:          7ca03553
Built:               Fri, Apr 11, 2025 12:27 AM
OS/Arch:             darwin/arm64
Profile:             local
Server type:         cloud
Pydantic version:    2.10.4
Integrations:
  prefect-slack:     0.3.0
  prefect-aws:       0.5.2
```

### Additional context

_No response_",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17941/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17941
17937,Expose Snowflake Integration Manager through Snowflake Connector block,open,,2025-04-29T16:20:04Z,2025-04-30T02:39:06Z,,1,['enhancement'],robfreedy,,CONTRIBUTOR,"### Describe the current behavior

Currently, the SnowflakeCredentials block exposes the private key directly, which creates potential security risks. Users who need to work with Snowflake Integration Manager must retrieve the private key from the credentials block, which unnecessarily exposes sensitive information that could be exfiltrated.

### Describe the proposed behavior

Expose the Snowflake [SimpleIngestManager](https://github.com/snowflakedb/snowflake-ingest-python) directly through the SnowflakeConnector instead of requiring users to extract the private key from the credentials block. This would:

1. Keep credentials properly encapsulated within the connector
2. Provide a more secure workflow that prevents secret exfiltration
3. Create a more cohesive experience for Snowflake-related operations

### Example Use

See github link attached above

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17937/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17937
17936,Visualize pending tasks in dependency grid,open,,2025-04-29T14:12:54Z,2025-04-29T14:12:54Z,,0,['enhancement'],bnaul,,CONTRIBUTOR,"### Describe the current behavior

When downstream task runs have been submitted to the task runner but are still pending, and one of the parent task fails, in the UI you can see the task runs listed but not graphed. Example:
```
import time

@task
def incr(x: int):
    time.sleep(x)
    print(f""{x=}"")
    if x > 1:
        raise ValueError(""Too big"")
    return x + 1
    
@flow
def incr_flow():
    a = 1
    b = incr.submit(a)
    c = incr.submit(b)
    d = incr.submit(c)
    return [b, c, d]

if __name__ == ""__main__"":
    incr_flow()

```

<img width=""1096"" alt=""Image"" src=""https://github.com/user-attachments/assets/8eb16734-ff81-4af6-8b6a-44dd60462e6c"" />

### Describe the proposed behavior

It would be nice to see more clearly what tasks would have run but didn't get a chance to, like the DAG view in Prefect 1.

### Example Use

_No response_

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17936/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17936
17935,"ValueError(f""{str(self)!r} is not in the subpath of {str(other)!r}"") on serve",open,,2025-04-29T08:44:30Z,2025-05-01T14:49:30Z,,3,['bug'],dinya,,NONE,"### Bug summary

Hello team,

I install ``my_etl`` package with ``pip install -e .``.

It includes import from other package ``etl_common`` (installed with ``pip install -e .`` too) in ``serve_sensor.py`` like:


```python
from etl_common.sensors import check_for_new_records_async

if __name__ == ""__main__"":
    check_for_new_records_async.serve()
```	

When I start serve from dir ``C:\Users\USER\Projects\etl\my-etl\bin`` with

```bash
python -m my_etl.serve_sensor
```

it raises

```
Traceback (most recent call last):
  File ""<frozen runpy>"", line 198, in _run_module_as_main
  File ""<frozen runpy>"", line 88, in _run_code
  File ""c:\users\USER\projects\etl\my-etl\my_etl\serve_sensor.py"", line 12, in <module>
    check_for_new_records_async.serve(
  File ""C:\opt\miniconda3\envs\prefect\Lib\site-packages\prefect\flows.py"", line 1078, in serve
    deployment_id = runner.add_flow(
                    ^^^^^^^^^^^^^^^^
  File ""C:\opt\miniconda3\envs\prefect\Lib\site-packages\prefect\utilities\asyncutils.py"", line 351, in coroutine_wrapper
    return run_coro_as_sync(ctx_call())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\opt\miniconda3\envs\prefect\Lib\site-packages\prefect\utilities\asyncutils.py"", line 207, in run_coro_as_sync
    return call.result()
           ^^^^^^^^^^^^^
  File ""C:\opt\miniconda3\envs\prefect\Lib\site-packages\prefect\_internal\concurrency\calls.py"", line 329, in result
    return self.future.result(timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\opt\miniconda3\envs\prefect\Lib\site-packages\prefect\_internal\concurrency\calls.py"", line 192, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File ""C:\opt\miniconda3\envs\prefect\Lib\concurrent\futures\_base.py"", line 401, in __get_result
    raise self._exception
  File ""C:\opt\miniconda3\envs\prefect\Lib\site-packages\prefect\_internal\concurrency\calls.py"", line 405, in _run_async
    result = await coro
             ^^^^^^^^^^
  File ""C:\opt\miniconda3\envs\prefect\Lib\site-packages\prefect\utilities\asyncutils.py"", line 188, in coroutine_wrapper
    return await task
           ^^^^^^^^^^
  File ""C:\opt\miniconda3\envs\prefect\Lib\site-packages\prefect\utilities\asyncutils.py"", line 341, in ctx_call
    result = await async_fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\opt\miniconda3\envs\prefect\Lib\site-packages\prefect\runner\runner.py"", line 375, in add_flow
    deployment = await to_deployment_coro
                 ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\opt\miniconda3\envs\prefect\Lib\site-packages\prefect\flows.py"", line 793, in ato_deployment
    return RunnerDeployment.from_flow(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\opt\miniconda3\envs\prefect\Lib\site-packages\prefect\deployments\runner.py"", line 686, in from_flow
    Path(flow_file).absolute().relative_to(Path.cwd().absolute())
  File ""C:\opt\miniconda3\envs\prefect\Lib\pathlib.py"", line 682, in relative_to
    raise ValueError(f""{str(self)!r} is not in the subpath of {str(other)!r}"")
ValueError: 'c:\\users\\USER\\projects\\etl\\etl-common\\etl_common\\sensors.py' is not in the subpath of 'C:\\Users\\USER\\Projects\\etl\\my-etl\\bin'
```

But when I start it from upper dir (at least from ``C:\Users\USER\Projects\etl``) it works well.

Is this a bug or an unexpected feature?

### Version info

```Text
Version:             3.3.4
API version:         0.8.4
Python version:      3.12.9
Git commit:          7ca03553
Built:               Fri, Apr 11, 2025 12:27 AM
OS/Arch:             win32/AMD64
Profile:             local
Server type:         server
Pydantic version:    2.10.6
Integrations:
  prefect-dask:      0.3.2
  prefect-docker:    0.6.2
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17935/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17935
17929,Prefect deployment run with --watch flag fails if heartbeats are enabled,closed,completed,2025-04-28T15:33:56Z,2025-04-28T17:14:52Z,2025-04-28T17:14:52Z,0,['bug'],masonmenges,,CONTRIBUTOR,"### Bug summary

If heartbeats are configured in the runtime environment for a flow run the --watch flag on the prefect deployment run cli command will fail with the following error as the heartbeat event from the flow run doesn't have a state-type associated with it.

```
Traceback (most recent call last):
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/site-packages/prefect/cli/_utilities.py"", line 44, in wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/site-packages/prefect/cli/_types.py"", line 156, in sync_fn
    return asyncio.run(async_fn(*args, **kwargs))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/asyncio/runners.py"", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/asyncio/runners.py"", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/asyncio/base_events.py"", line 687, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/site-packages/prefect/cli/deployment.py"", line 898, in run
    finished_flow_run = await wait_for_flow_run(
                        ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/site-packages/prefect/client/utilities.py"", line 99, in with_injected_client
    return await fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/site-packages/prefect/flow_runs.py"", line 144, in wait_for_flow_run
    state_type = StateType(event.resource[""prefect.state-type""])
                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/site-packages/prefect/events/schemas/labelling.py"", line 82, in __getitem__
    return self.root[label]
           ~~~~~~~~~^^^^^^^
KeyError: 'prefect.state-type'
```

### Version info

```Text
Version:             3.3.6
API version:         0.8.4
Python version:      3.12.4
Git commit:          01441afa
Built:               Thu, Apr 24, 2025 07:26 PM
OS/Arch:             darwin/arm64
Profile:             masonsandbox
Server type:         cloud
Pydantic version:    2.10.6
Integrations:
  prefect-dask:      0.3.2
  prefect-snowflake: 0.28.0
  prefect-slack:     0.3.0
  prefect-gcp:       0.6.2
  prefect-aws:       0.5.0
  prefect-gitlab:    0.3.1
  prefect-dbt:       0.6.4
  prefect-kubernetes: 0.5.8
  prefect-docker:    0.6.1
  prefect-sqlalchemy: 0.5.1
  prefect-shell:     0.3.1
```

### Additional context

_No response_",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17929/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17929
17921,Adding time zone to cron crashes command `flow-run ls`,closed,completed,2025-04-27T09:12:16Z,2025-04-28T14:38:18Z,2025-04-28T14:38:18Z,0,['bug'],ankush981,,NONE,"### Bug summary

I created the prefect.yaml file like this:

```
name: omnivio-multi-deployment

deployments:
  - name: pg_table_size_monitoring
    entrypoint: dbt_storage_analysis/slack_storage_alert.py:analyze_pg_table_sizes
    work_pool:
      name: work-pool
    job_variables:
      working_dir: dbt_storage_analysis
    schedule:
      cron: ""30 9 * * *"" # 3:00 PM IST (converted manually to UTC)
      timezone: ""Asia/Kolkata""
```
which I'm running like this: `prefect deploy --name pg_table_size_monitoring`

This works fine and shows the time in the desired time zone in the UI. However, now the command `prefect flow-run ls` breaks with the following trace:

```
Traceback (most recent call last):
  File ""/usr/lib/python3.10/zoneinfo/_common.py"", line 12, in load_tzdata
    return importlib.resources.open_binary(package_name, resource_name)
  File ""/usr/lib/python3.10/importlib/resources.py"", line 46, in open_binary
    return reader.open_resource(resource)
  File ""/usr/lib/python3.10/importlib/abc.py"", line 433, in open_resource
    return self.files().joinpath(resource).open('rb')
  File ""/usr/lib/python3.10/pathlib.py"", line 1119, in open
    return self._accessor.open(self, mode, buffering, encoding, errors,
FileNotFoundError: [Errno 2] No such file or directory: '/home/ubuntu/venv/lib/python3.10/site-packages/tzdata/zoneinfo/+05:30'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/ubuntu/venv/lib/python3.10/site-packages/prefect/cli/_utilities.py"", line 44, in wrapper
    return fn(*args, **kwargs)
  File ""/home/ubuntu/venv/lib/python3.10/site-packages/prefect/cli/_types.py"", line 156, in sync_fn
    return asyncio.run(async_fn(*args, **kwargs))
  File ""/usr/lib/python3.10/asyncio/runners.py"", line 44, in run
    return loop.run_until_complete(main)
  File ""/usr/lib/python3.10/asyncio/base_events.py"", line 649, in run_until_complete
    return future.result()
  File ""/home/ubuntu/venv/lib/python3.10/site-packages/prefect/cli/flow_run.py"", line 180, in ls
    human_friendly_diff(timestamp),
  File ""/home/ubuntu/venv/lib/python3.10/site-packages/prefect/types/_datetime.py"", line 84, in human_friendly_diff
    dt = dt.replace(tzinfo=ZoneInfo(getattr(dt.tzinfo, ""name"")))
  File ""/usr/lib/python3.10/zoneinfo/_common.py"", line 24, in load_tzdata
    raise ZoneInfoNotFoundError(f""No time zone found with key {key}"")
zoneinfo._common.ZoneInfoNotFoundError: 'No time zone found with key +05:30'
An exception occurred.
```

After removing the time zone and re-deploying, this doesn't happen, but the problem, of course, is that we now have to mentally calculate local time, which is undesirable.

Please let me know if any other info is needed!


### Version info

```Text
Version:             3.3.6
API version:         0.8.4
Python version:      3.10.12
Git commit:          01441afa
Built:               Thu, Apr 24, 2025 07:26 PM
OS/Arch:             linux/x86_64
Profile:             local
Server type:         server
Pydantic version:    2.11.3
```

### Additional context

_No response_",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17921/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17921
17916,Deployment yaml variable injection inline substitution,open,,2025-04-25T17:45:26Z,2025-04-25T17:45:26Z,,0,['enhancement'],jlwhelan28,,NONE,"### Describe the current behavior

Currently when working with the yaml definition of a deployment you can inject variables / block data, but the variable reference cannot be used for inline string substitution. In other words the variable reference contained by {{...}} must be the only thing present in the key value.

Example:
```
build:
- prefect_docker.deployments.steps.build_docker_image:
    id: build_image
    image_name: '{{ prefect.blocks.secret.my-private-image.value }}'
```




### Describe the proposed behavior

Handle inline substitution similar to how environment variables work in sh, or the cloudformation ""!Sub"" intrinsic function.

Example:
```
prefect.blocks.secret.my-private-repo.value -> resolves to my-private-repo.com
```
```
build:
- prefect_docker.deployments.steps.build_docker_image:
    id: build_image
    image_name: '{{ prefect.blocks.secret.my-private-repo.value }}/my-image-name'
```

Gets processed by prefect such that `image_name = my-private-repo.com/my-image-name`

### Example Use

_No response_

### Additional context

Originally suggested in https://github.com/PrefectHQ/prefect/issues/17604#issuecomment-2755086368",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17916/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17916
17914,Result persistence rest api endpoint for json serialized results from deployments,closed,completed,2025-04-25T17:00:07Z,2025-04-30T19:04:33Z,2025-04-30T19:04:33Z,2,['enhancement'],jlwhelan28,,NONE,"### Describe the current behavior

Currently it is possible to configure flow / task persistence https://docs.prefect.io/v3/develop/results

For a deployment, those results can be retrieved via

```python
from prefect.deployments import run_deployment
res = run_deployment(name=""my-deployment"", parameters={...})
print(res.state.result())
```

or 

```python
from prefect import get_client
async with get_client() as client:
    response = await client.read_flow_run('<flow-id>')
print(response.state.result())
```

Presumably these methods are using some combination of the existing API to facilitate the recreation of the flow result object in python using the configured serializer, but there isn't an direct api endpoint to facilitate that result retrieval.

### Describe the proposed behavior

For a configuration similar to 
```
PREFECT_RESULTS_PERSIST_BY_DEFAULT=true
PREFECT_DEFAULT_RESULT_STORAGE_BLOCK='s3-bucket/my-block'
PREFECT_RESULTS_DEFAULT_SERIALIZER=""json""
```

I would like to be able to retrieve my persisted flow results via REST API in a response body as well as through prefect python sdk.

### Example Use

Persisted results retrieved via python or rest api

```python
from prefect import get_client
async with get_client() as client:
    response = await client.read_flow_run('<flow-id>')
print(response.state.result())
```

```bash
curl -X GET https://my-prefect-server.com/flow/{id}/result
```

Where if flow serialization is configured to pickle or compressed pickle, it returns http 400.

### Additional context

If this suggestion goes against the prefect philosophy for result persistence, I respect that but would appreciate help to understand a bit more what patterns this community recommends to expose deployed flow ""output"" to a user base. I am working with this platform to deploy analytics in a context where an overall ecosystem of event driven asynchronous processes is not all that mature. A given deployment in this context may not have anything to ""push"" its result to, and needs to be used in a simpler call analytic / get response payload pattern. I'd like to be able to do that from any language without relying on a python environment with the prefect sdk installed.",,1,https://api.github.com/repos/PrefectHQ/prefect/issues/17914/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17914
17913,Manually retrying flows gets stuck in `AwaitingRetry` state,open,,2025-04-25T16:16:33Z,2025-04-25T16:17:40Z,,1,[],desertaxle,,MEMBER,"
### Discussed in https://github.com/PrefectHQ/prefect/discussions/17912

<div type='discussions-op-text'>

<sup>Originally posted by **MartinEmilJakobsen** April 25, 2025</sup>
I am experiencing some weird behavior of manual retry attempts getting stuck in AwaitingRetry state.
This happens consistently in the following example but it only occurs when retry is initiated from the UI of a failed flow that has been deployed with retries > 0.
Minimal reproducible example:
```
from prefect import flow
from prefect.docker import DockerImage
@flow(retries=3, retry_delay_seconds=5, cache_result_in_memory=False, persist_result=False)
def flow_of_ray_tasks():
    raise ValueError(""This is an error"")

if __name__ == ""__main__"":
    flow_of_ray_tasks.deploy(
        name=""test_flow_retry"",
        image=DockerImage(
            name=""<<my_docker_registry>>/docker/test"",
            tag=""latest"",
        ),
        push=True,
        work_pool_name=""docker-pool"",
        cron=""5 * * * *"",
        tags=[""docker-pool""],
    )
```
My prefect version:
```
Version:             3.3.5
API version:         0.8.4
Python version:      3.12.9
Git commit:          db4b7a33
Built:               Thu, Apr 17, 2025 09:25 PM
OS/Arch:             linux/x86_64
Profile:             local
Server type:         server
Pydantic version:    2.10.3
Integrations:
  prefect-aws:       0.5.10
  prefect-ray:       0.4.4
  prefect-docker:    0.6.3
```
Flow-run inspect when stuck in AwaitingRetry:
```
FlowRun(
    id='64d8462a-88e1-4b3c-9b83-32793726ef09',
    created=DateTime(2025, 4, 25, 15, 42, 23, 268262, tzinfo=Timezone('UTC')),
    updated=DateTime(2025, 4, 25, 15, 42, 58, 610000, tzinfo=Timezone('UTC')),
    name='thundering-guppy',
    flow_id='de7b6093-e012-417d-bb7a-8c1dfff96a33',
    state_id=UUID('8b13221b-91d1-407e-a848-33f3839a7571'),
    deployment_id=UUID('8ceab248-8cd8-45cb-8fc5-9c3293d1d0e2'),
    deployment_version='a9d49177bb38517847ef51a9f02624e4',
    work_queue_name='default',
    flow_version='a9d49177bb38517847ef51a9f02624e4',
    parameters={},
    context={},
    empirical_policy=FlowRunPolicy(retries=3, retry_delay=5, pause_keys=set(), retry_type='in_process'),
    tags=['docker-pool'],
    labels={
        'prefect.flow.id': 'de7b6093-e012-417d-bb7a-8c1dfff96a33',
        'prefect.deployment.id': '8ceab248-8cd8-45cb-8fc5-9c3293d1d0e2',
        'prefect.worker.name': 'DockerWorker d83d79e8-3ba9-48bb-9628-922d50bbbf82',
        'prefect.worker.type': 'docker',
        'prefect.work-pool.name': 'docker-pool',
        'prefect.work-pool.id': 'c1a5ba4a-96ac-4eca-abc3-8e9015cb0d3b'
    },
    run_count=4,
    expected_start_time=DateTime(2025, 4, 25, 15, 42, 23, 234210, tzinfo=Timezone('UTC')),
    next_scheduled_start_time=DateTime(2025, 4, 25, 15, 42, 58, 600442, tzinfo=Timezone('UTC')),
    start_time=DateTime(2025, 4, 25, 15, 42, 31, 607274, tzinfo=Timezone('UTC')),
    total_run_time=datetime.timedelta(microseconds=182368),
    estimated_run_time=datetime.timedelta(microseconds=182368),
    estimated_start_time_delta=datetime.timedelta(seconds=8, microseconds=373064),
    infrastructure_pid='http+docker://localhost:9eaa9a7d72c791c79a616fbcbb88c4442f008e27e021c5046b062591149641d4',
    work_queue_id=UUID('8a9a1012-f5e8-4aa4-8051-549f8e4d0cc7'),
    work_pool_id=UUID('c1a5ba4a-96ac-4eca-abc3-8e9015cb0d3b'),
    work_pool_name='docker-pool',
    state=State(
        id='8b13221b-91d1-407e-a848-33f3839a7571',
        type=StateType.SCHEDULED,
        name='AwaitingRetry',
        timestamp=datetime.datetime(2025, 4, 25, 15, 42, 58, 600771, tzinfo=TzInfo(UTC)),
        message='Retry from the UI',
        state_details=StateDetails(flow_run_id=UUID('64d8462a-88e1-4b3c-9b83-32793726ef09'), scheduled_time=DateTime(2025, 4, 25, 15, 42, 58, 600442, tzinfo=Timezone('UTC')), deferred=False)
    ),
    job_variables={},
    state_type=StateType.SCHEDULED,
    state_name='AwaitingRetry'
)
```",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17913/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17913
17907,Code to determine fields within a state is slow,closed,completed,2025-04-25T07:49:46Z,2025-04-25T13:56:14Z,2025-04-25T13:56:14Z,0,['enhancement'],ogenstad,,CONTRIBUTOR,"### Describe the current behavior

We're troubleshooting performance issues within our Prefect environment (thanks to @fatih-acar for identifying the issue).

In this case it's within the State schema with regards to how the code determines the available fields. The problem is that the Pydantic `.model_json_schema()` is very time consuming luckily there's an easy alternative.

### Describe the proposed behavior

An example highlighting the issue and solution.

```python
import timeit

from prefect.server.schemas.states import State

initial = ""field_keys = State.model_json_schema()['properties'].keys()""
compare = ""field_keys = State.model_fields.keys()""

initial_time = timeit.timeit(stmt=initial, number=100, globals=globals())
compare_time = timeit.timeit(stmt=compare, number=100, globals=globals())

print(f""Initial time: {initial_time:.6f} seconds"")
print(f""Compare time: {compare_time:.6f} seconds"")

print(sorted(State.model_json_schema()[""properties""].keys()) == sorted(State.model_fields.keys()))
```

Running this will output something like:
```
Initial time: 0.183675 seconds
Compare time: 0.000022 seconds
True
```

### Example Use

_No response_

### Additional context

_No response_",desertaxle,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17907/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17907
17905,Add option to use basic search instead of AI search in docs,closed,not_planned,2025-04-24T23:53:02Z,2025-04-29T14:58:50Z,2025-04-29T14:58:48Z,4,"['enhancement', 'docs']",jeffcarrico,,NONE,"### Describe the current behavior

The AI search can be slow, it can hallucinate, and often I find myself yearning for the basic search of past doc iterations. 



### Describe the proposed behavior

Ideally make the AI search opt-in, but would settle for it being opt-out.

### Example Use

_No response_

### Additional context

Here's a screenshot of the AI hallucinating a wrong answer (there is no `Flow.map` in 3.3.6 although I know this is something that has been talked about in issues past)


![Image](https://github.com/user-attachments/assets/2b9e2803-21a9-4ff8-bde3-f5a705fec91e)

![Image](https://github.com/user-attachments/assets/62f8f18a-be17-4cc4-8733-8cbc8c81d638)",zzstoatzz,2,https://api.github.com/repos/PrefectHQ/prefect/issues/17905/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17905
17904,Support selecting a specific commit in the `git_clone` pull step,closed,completed,2025-04-24T21:30:55Z,2025-04-30T15:42:11Z,2025-04-30T15:42:11Z,0,['enhancement'],kevingrismore,,CONTRIBUTOR,"### Describe the current behavior

The `git_clone` pull step accepts branches, but since it uses the `--branch` flag, providing a commit to `branch:` fails the step.

### Describe the proposed behavior

Support providing a SHA to the `branch` arg or a new argument so a run of a deployment can be pointed at a specific commit.

This will be especially useful in pinning commits for deployment versions.

### Example Use

```
- prefect.deployments.steps.git_clone:
    repository: https://github.com/kevingrismore/version-testing.git
    branch: ""{{ $GITHUB_SHA }}""
```

### Additional context

_No response_",kevingrismore,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17904/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17904
17902,prefect task-run ls --state-type fails,closed,completed,2025-04-24T19:35:13Z,2025-04-25T16:55:46Z,2025-04-25T16:55:46Z,0,['bug'],bnaul,,CONTRIBUTOR,"### Bug summary

```
(.venv) âžœ  prefect task-run ls  --state-type RUNNING
Traceback (most recent call last):
  File ""/Users/brett/model/.venv/lib/python3.10/site-packages/prefect/cli/_utilities.py"", line 44, in wrapper
    return fn(*args, **kwargs)
  File ""/Users/brett/model/.venv/lib/python3.10/site-packages/prefect/cli/_types.py"", line 156, in sync_fn
    return asyncio.run(async_fn(*args, **kwargs))
  File ""/opt/homebrew/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/runners.py"", line 44, in run
    return loop.run_until_complete(main)
  File ""/opt/homebrew/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py"", line 649, in run_until_complete
    return future.result()
  File ""/Users/brett/model/.venv/lib/python3.10/site-packages/prefect/cli/task_run.py"", line 75, in ls
    task_run_filter=TaskRunFilter(
  File ""/Users/brett/model/.venv/lib/python3.10/site-packages/pydantic/main.py"", line 212, in __init__
    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
pydantic_core._pydantic_core.ValidationError: 1 validation error for TaskRunFilter
state.name
  Field required [type=missing, input_value={'type': {'any_': [StateType.RUNNING]}}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.9/v/missing
An exception occurred.
```

### Version info

```Text
Version:             3.3.5
API version:         0.8.4
Python version:      3.10.16
Git commit:          db4b7a33
Built:               Thu, Apr 17, 2025 09:25 PM
OS/Arch:             darwin/arm64
Profile:             default
Server type:         cloud
Pydantic version:    2.9.2
Integrations:
  prefect-dask:      0.3.5
  prefect-gcp:       0.6.4
  prefect-kubernetes: 0.5.8
```

### Additional context

_No response_",desertaxle,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17902/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17902
17895,Super slow api and UI after upgrade,open,,2025-04-24T06:04:05Z,2025-05-14T04:17:06Z,,5,['bug'],Ishankoradia,,CONTRIBUTOR,"### Bug summary

We recently did an upgrade from `2.18.3` to `3.1.15`. The apis we have integrated became very slow & sluggish. The api to just fetch a flow run i.e. `GET /flow_runs/{id}` is taking ~ 3 secs. It was much faster before the upgrade. 

This is what our configuration setting looks like at the moment in prefect `3.1.15`. 
```
home: /home/ddp/.prefect
profiles_path: /home/ddp/.prefect/profiles.toml
debug_mode: false
api: {
  ""url"": ""http://localhost:4200/api"",
  ""auth_string"": null,
  ""key"": null,
  ""tls_insecure_skip_verify"": false,
  ""ssl_cert_file"": null,
  ""enable_http2"": false,
  ""request_timeout"": 60
}
cli: {
  ""colors"": true,
  ""prompt"": null,
  ""wrap_lines"": true
}
client: {
  ""max_retries"": 5,
  ""retry_jitter_factor"": 0.2,
  ""retry_extra_codes"": [],
  ""csrf_support_enabled"": true,
  ""metrics"": {
    ""enabled"": false,
    ""port"": 4201
  }
}
cloud: {
  ""api_url"": ""https://api.prefect.cloud/api"",
  ""enable_orchestration_telemetry"": true,
  ""ui_url"": ""https://app.prefect.cloud""
}
deployments: {
  ""default_work_pool_name"": null,
  ""default_docker_build_namespace"": null
}
experiments: {
  ""warn"": true,
  ""lineage_events_enabled"": false
}
flows: {
  ""default_retries"": 0,
  ""default_retry_delay_seconds"": 0
}
internal: {
  ""logging_level"": ""ERROR""
}
logging: {
  ""level"": ""INFO"",
  ""config_path"": ""/home/ddp/.prefect/logging.yml"",
  ""extra_loggers"": [],
  ""log_prints"": false,
  ""colors"": true,
  ""markup"": false,
  ""to_api"": {
    ""enabled"": true,
    ""batch_interval"": 2,
    ""batch_size"": 4000000,
    ""max_log_size"": 1000000,
    ""when_missing_flow"": ""warn""
  }
}
results: {
  ""default_serializer"": ""pickle"",
  ""persist_by_default"": false,
  ""default_storage_block"": null,
  ""local_storage_path"": ""/home/ddp/.prefect/storage""
}
runner: {
  ""process_limit"": 5,
  ""poll_frequency"": 10,
  ""heartbeat_frequency"": null,
  ""server"": {
    ""enable"": false,
    ""host"": ""localhost"",
    ""port"": 8080,
    ""log_level"": ""ERROR"",
    ""missed_polls_tolerance"": 2
  }
}
server: {
  ""logging_level"": ""WARNING"",
  ""analytics_enabled"": true,
  ""metrics_enabled"": false,
  ""log_retryable_errors"": false,
  ""register_blocks_on_start"": true,
  ""memoize_block_auto_registration"": true,
  ""memo_store_path"": ""/home/ddp/.prefect/memo_store.toml"",
  ""deployment_schedule_max_scheduled_runs"": 50,
  ""api"": {
    ""auth_string"": null,
    ""host"": ""127.0.0.1"",
    ""port"": 4200,
    ""default_limit"": 500,
    ""keepalive_timeout"": 5,
    ""csrf_protection_enabled"": false,
    ""csrf_token_expiration"": ""PT1H"",
    ""cors_allowed_origins"": ""*"",
    ""cors_allowed_methods"": ""*"",
    ""cors_allowed_headers"": ""*""
  },
  ""database"": {
    ""sqlalchemy"": {
      ""connect_args"": {
        ""application_name"": null
      },
      ""pool_size"": 60,
      ""pool_recycle"": 3600,
      ""pool_timeout"": 30,
      ""max_overflow"": 10
    },
    ""connection_url"": ""**********"",
    ""driver"": null,
    ""host"": null,
    ""port"": null,
    ""user"": null,
    ""name"": null,
    ""password"": ""**********"",
    ""echo"": false,
    ""migrate_on_start"": true,
    ""timeout"": 60,
    ""connection_timeout"": 60
  },
  ""deployments"": {
    ""concurrency_slot_wait_seconds"": 30
  },
  ""ephemeral"": {
    ""enabled"": false,
    ""startup_timeout_seconds"": 20
  },
  ""events"": {
    ""stream_out_enabled"": true,
    ""related_resource_cache_ttl"": ""PT5M"",
    ""maximum_labels_per_resource"": 500,
    ""maximum_related_resources"": 500,
    ""maximum_size_bytes"": 1500000,
    ""expired_bucket_buffer"": ""PT1M"",
    ""proactive_granularity"": ""PT5S"",
    ""retention_period"": ""P7D"",
    ""maximum_websocket_backfill"": ""PT15M"",
    ""websocket_backfill_page_size"": 250,
    ""messaging_broker"": ""prefect.server.utilities.messaging.memory"",
    ""messaging_cache"": ""prefect.server.utilities.messaging.memory"",
    ""maximum_event_name_length"": 1024
  },
  ""flow_run_graph"": {
    ""max_nodes"": 10000,
    ""max_artifacts"": 10000
  },
  ""services"": {
    ""cancellation_cleanup"": {
      ""enabled"": true,
      ""loop_seconds"": 120
    },
    ""event_persister"": {
      ""enabled"": false,
      ""batch_size"": 20,
      ""flush_interval"": 5
    },
    ""flow_run_notifications"": {
      ""enabled"": true
    },
    ""foreman"": {
      ""enabled"": true,
      ""loop_seconds"": 120,
      ""inactivity_heartbeat_multiple"": 3,
      ""fallback_heartbeat_interval_seconds"": 30,
      ""deployment_last_polled_timeout_seconds"": 300,
      ""work_queue_last_polled_timeout_seconds"": 300
    },
    ""late_runs"": {
      ""enabled"": true,
      ""loop_seconds"": 60,
      ""after_seconds"": ""PT1M""
    },
    ""scheduler"": {
      ""enabled"": true,
      ""loop_seconds"": 60,
      ""deployment_batch_size"": 100,
      ""max_runs"": 100,
      ""min_runs"": 3,
      ""max_scheduled_time"": ""P100D"",
      ""min_scheduled_time"": ""PT1H"",
      ""insert_batch_size"": 500
    },
    ""pause_expirations"": {
      ""enabled"": true,
      ""loop_seconds"": 5
    },
    ""task_run_recorder"": {
      ""enabled"": true
    },
    ""triggers"": {
      ""enabled"": true
    }
  },
  ""tasks"": {
    ""tag_concurrency_slot_wait_seconds"": 30,
    ""max_cache_key_length"": 2000,
    ""scheduling"": {
      ""max_scheduled_queue_size"": 1000,
      ""max_retry_queue_size"": 100,
      ""pending_task_timeout"": ""PT0S""
    }
  },
  ""ui"": {
    ""enabled"": true,
    ""api_url"": ""http://localhost:4200/api"",
    ""serve_base"": ""/"",
    ""static_directory"": null
  }
}
tasks: {
  ""refresh_cache"": false,
  ""default_retries"": 0,
  ""default_retry_delay_seconds"": 0,
  ""default_persist_result"": null,
  ""runner"": {
    ""thread_pool_max_workers"": null
  },
  ""scheduling"": {
    ""default_storage_block"": null,
    ""delete_failed_submissions"": true
  }
}
testing: {
  ""test_mode"": false,
  ""unit_test_mode"": false,
  ""unit_test_loop_debug"": true,
  ""test_setting"": ""FOO""
}
worker: {
  ""heartbeat_seconds"": 30,
  ""query_seconds"": 10,
  ""prefetch_seconds"": 10,
  ""webserver"": {
    ""host"": ""0.0.0.0"",
    ""port"": 8080
  }
}
ui_url: http://localhost:4200
silence_api_url_misconfiguration: false
```


### Version info

```Text
Version:             3.1.15
API version:         0.8.4
Python version:      3.10.9
Git commit:          3ac3d548
Built:               Thu, Jan 30, 2025 11:31 AM
OS/Arch:             linux/x86_64
Profile:             local
Server type:         server
Pydantic version:    2.10.6
Integrations:
  prefect-sqlalchemy: 0.5.2
  prefect-github:    0.3.1
  prefect-dbt:       0.6.6
  prefect-gcp:       0.6.4
  prefect-shell:     0.3.1
```

### Additional context

Some interesting RDS graphs at the time of upgrade . I can confirm that the slopes in the both the graphs are at the time of upgrade. 

<img width=""327"" alt=""Image"" src=""https://github.com/user-attachments/assets/2959dfac-8938-4ffd-abe1-dfe781459070"" />

<img width=""360"" alt=""Image"" src=""https://github.com/user-attachments/assets/52ea7a7c-f509-44c2-95c5-a758e88b0cce"" />

We also saw that prefect has been taking good amout of locks on the db which is probably making the reads slower. CPU of RDS is well under the limit. 
Is there some configuration that will allow me to use more connections & hopefully solve this bottleneck ? I have pasted our settings above. 

I am also seeing these in prefect server logs

```
prefect.server.services.recentdeploymentsscheduler - RecentDeploymentsScheduler took 59.25218 seconds to run, which is longer than its loop interval of 5 seconds.
.
.
.
prefect.server.services.recentdeploymentsscheduler - RecentDeploymentsScheduler took 163.870647 seconds to run, which is longer than its loop interval of 5 seconds.
.
.
.
prefect.server.services.flowrunnotifications - FlowRunNotifications took 8.167483 seconds to run, which is longer than its loop interval of 4 seconds.
.
.
.
prefect.server.services.failexpiredpauses - FailExpiredPauses took 6.492807 seconds to run, which is longer than its loop interval of 5.0 seconds.
```

This has been very frustrating. Any help or guidance is much appreciated ?",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17895/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17895
17893,Trigger automations from artifacts,open,,2025-04-23T15:39:42Z,2025-04-24T17:18:00Z,,3,['enhancement'],toby-coleman,,CONTRIBUTOR,"### Describe the current behavior

I have a flow that publishes a table artifact as described [here](https://docs.prefect.io/v3/develop/artifacts). Currently I can view this artifact in the Prefect Cloud UI, and access it via the API, but I cannot trigger an automation from it.

### Describe the proposed behavior

I'd like to be able to trigger automations based on a new artifact being published. An example might be:
* New table artifact created with some key value pairs;
* Based on the creation of this artifact, an automation gets triggered. For example, if a value in the artifact is greater than some threshold level, an alert is triggered to Slack/MSTeams, etc.

### Example Use

Users could simultaneously:
* Make use of artifacts to track metrics from a Prefect deployment, e.g. accuracy of a trained machine-learning model; and
* Receive alerts when those metrics deviate from expected norms, e.g. model accuracy is lower than a critical level.

### Additional context

Discussed with Rob Freedy on Prefect support email - current understanding is that this usage is not supported because there is no event that is emitted on artifact creation.",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17893/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17893
17892,Support `staticmethod` and `classmethod` flow entrypoints,closed,completed,2025-04-23T13:56:45Z,2025-05-06T13:49:56Z,2025-05-06T13:49:56Z,5,['enhancement'],vyagubov,,CONTRIBUTOR,"### Bug summary

I'm using Prefect with static methods defined inside classes and deploying with source code from GitLab using an explicit entrypoint.

My flow is defined like this:

```python
class ClassName:

    @staticmethod
    @flow
    def run() -> None:
        ...
```
I try to use:

```python
entrypoint = ""path/flow.py:ClassName.run""
```
However, Prefect raises an error saying it couldn't find the flow.

Expected Behavior:

Since @flow supports @staticmethod based on the source code here:
https://github.com/PrefectHQ/prefect/blob/093237bfa0681dfcb1baeaee9b96da9803b6a879/src/prefect/flows.py#L281 
I expect that specifying ClassName.run in the entrypoint should work.

Root Cause:
In the same file, later in the Flow class, the entrypoint is hardcoded as:
https://github.com/PrefectHQ/prefect/blob/093237bfa0681dfcb1baeaee9b96da9803b6a879/src/prefect/flows.py#L405

This ignores the class context (ClassName) and causes the flow to be inaccessible via the expected entrypoint path.


Current Workaround:
To make this work, I need to add a top-level alias:

```python
class ClassName:

    @staticmethod
    @flow
    def run() -> None:
        ...

run = ClassName.run  # workaround for entrypoint to resolve

# entrypoint = ""path/flow.py:run""
```
Suggested Fix:

Respect the class context in the entrypoint, or allow users to specify ClassName.run explicitly and resolve it correctly during loading.

### Version info

```Text
the last version of Prefect which is available in github.
```

### Additional context

_No response_",desertaxle,1,https://api.github.com/repos/PrefectHQ/prefect/issues/17892/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17892
17891,Add ability to trigger an event that matches multiple related resources,closed,completed,2025-04-23T09:13:41Z,2025-05-08T13:41:17Z,2025-05-08T13:41:17Z,4,['enhancement'],ogenstad,,CONTRIBUTOR,"### Describe the current behavior

When you create an automation you can match an event trigger against a dictionary for the related resources of the event. This limits how you can match against related resources of an event. Using the compound trigger you can do the same kind of match using multiple triggers however the compound triggers requires that there are multiple events before firing the automation.

### Describe the proposed behavior

What I'd like to do is to have the possibility to create a trigger that matches against a single event but where it also supports multiple related resources.

Locally we've implemented a workaround where we can use the compound trigger to achieve this but I'd love to see it implemented directly in Prefect.

When creating an automation we'd have a payload that looks something like this:

```python
{
  ""name"": ""combined-event-trigger"",
  ""description"": ""Automation that triggers when an event matches multiple related fields in combination"",
  ""enabled"": true,
  ""trigger"": {
    ""type"": ""compound"",
    ""require"": ""all"",
    ""within"": 0,
    ""triggers"": [
      {
        ""type"": ""event"",
        ""id"": ""cb96616c-6936-42c7-b54d-8dc0ad057029"",
        ""match"": {
          ""infrahub.node.kind"": ""BuiltinTag""
        },
        ""match_related"": {
            ""infrahub.field.name"": ""name"",
            ""infrahub.attribute.value"": [""name1"", ""name2"", ""name3""]
        },
        ""after"": [],
        ""expect"": [
          ""infrahub.node.updated""
        ],
        ""for_each"": [],
        ""posture"": ""Reactive"",
        ""threshold"": 1,
        ""within"": 0
      },
      {
        ""type"": ""event"",
        ""id"": ""cb96616c-6936-42c7-b54d-8dc0ad057029"",
        ""match"": {
          ""infrahub.node.kind"": ""BuiltinTag""
        },
        ""match_related"": {
            ""infrahub.field.name"": ""description"",
            ""infrahub.attribute.value"": [""desc1"", ""desc2"", ""desc3""]
        },
        ""after"": [],
        ""expect"": [
          ""infrahub.node.updated""
        ],
        ""for_each"": [],
        ""posture"": ""Reactive"",
        ""threshold"": 1,
        ""within"": 0
      }
    ]
  },
  ""actions"": [
    {
      ""type"": ""run-deployment"",
      ""source"": ""selected"",
      ""deployment_id"": ""a6cfdc5e-de44-496d-b451-38bce14449e6"",
      ""parameters"": {
        ""event_id"": ""{{ event.id }}"",
        ""event_type"": ""{{ event.event }}"",
        ""webhook_id"": ""18370d71-2616-0780-58d0-1746326b7f1d"",
        ""branch_name"": ""{{ event.resource['infrahub.branch.name'] }}"",
        ""event_payload"": {
          ""value"": {
            ""template"": ""{{ event.payload | tojson }}"",
            ""__prefect_kind"": ""jinja""
          },
          ""__prefect_kind"": ""json""
        },
        ""event_occured_at"": ""{{ event.occurred }}""
      },
      ""job_variables"": {}
    }
  ],
  ""actions_on_trigger"": [],
  ""actions_on_resolve"": []
}
```

The idea would be when we have an event that has multiple related resources where matching key might be the same. In this instance we'd want to trigger an automation if we had a related resource with that matched both of these:

* infrahub.field.name == ""name"" AND ""infrahub.attribute.value"" in [""name1"", ""name2"", ""name3]
* infrahub.field.name == ""description"" AND ""infrahub.attribute.value"" in [""desc1"", ""desc1"", ""desc1]

In our workaround we manage this by overriding the `find_interested_triggers` function within Prefect. However I'd like it to be natively supported within Prefect.

I'm not sure what this would be called perhaps an expanded of the regular EventTrigger, alternatively if EventTrigger could get an additional attribute where `match_related` would be a list of dictionaries instead of a single dictionary.

### Example Use

_No response_

### Additional context

If this feature is accepted I'd be happy to help with the implementation.",chrisguidry,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17891/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17891
17890,CallWebhook action double json encodes payload,open,,2025-04-23T04:26:52Z,2025-04-25T16:24:39Z,,3,"['bug', 'good first issue', 'great writeup']",willhcr,,NONE,"### Bug summary

When creating a payload, which is a jinja2 template, the event json is json encoded againt resulting in an escaped string.

```python
CallWebhook(block_document_id=webhook_id, payload='{{ event.model_dump_json()}}')
```

### Expected result
Webhook receives: `'{""json"":""data""}'`

### Actual Result
Webhook receives: `'""{\""json\"":\""data\""}""'`

### Details

`payload` is now a str (seems it used to be a dict), but call() is defined as `async def call(self, payload: dict[str, Any] | None = None) -> Response:`

https://github.com/PrefectHQ/prefect/blob/093237bfa0681dfcb1baeaee9b96da9803b6a879/src/prefect/server/events/actions.py#L1222

`payload` is passed to httpx request with the `json` keyword which results in the string being json encoded again

https://github.com/PrefectHQ/prefect/blob/093237bfa0681dfcb1baeaee9b96da9803b6a879/src/prefect/blocks/webhook.py#L76

### Resolution

If call() was updated to take a `str` and pass it to httpx.request as `content=payload` it should resolve the issue.

### Version info

```Text
Version:             3.3.5
API version:         0.8.4
Python version:      3.12.9
Git commit:          db4b7a33
Built:               Thu, Apr 17, 2025 09:25 PM
OS/Arch:             linux/x86_64
Profile:             ephemeral
Server type:         server
Pydantic version:    2.10.6
Integrations:
  prefect-docker:    0.6.3
  prefect-azure:     0.4.3
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17890/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17890
17889,Automations with a CallWebhook action are not visible in the Prefect UI,open,,2025-04-23T02:11:21Z,2025-05-02T13:06:54Z,,1,"['bug', 'ui']",willhcr,,NONE,"### Bug summary

When creating an Automation via Python code for use with a webhook, it is created successfully and functions, but is not visible in the UI.

Sample create script:
```python
import base64
from prefect.automations import Automation
from prefect.blocks.webhook import Webhook
from prefect.events import EventTrigger, CallWebhook, ResourceSpecification
from prefect.types import SecretDict
from pydantic import SecretStr

# Define webhook URL and auth headers
webhook_url = 'http://example.com/api/webhook'
basic_auth = 'luggage:12345'
auth_secret = base64.b64encode(basic_auth.encode('utf-8')).decode('utf-8')
headers = {
    ""Authorization"": f""Basic {auth_secret}"",
    ""Content-Type"": ""application/json""
}

# Create Webhook Block
webhook_block = Webhook(
    url=SecretStr(webhook_url),
    headers=SecretDict(headers),
    verify=False  # Set to True in production
)

# Save the webhook block
block_id = webhook_block.save(name='test-webhook', overwrite=True)
print(f'Created WebhookBlock with ID: {block_id}')

async def create_automation():
    """"""Create an automation that triggers on specific Prefect events""""""
    automation = Automation(
        name='test-webhook-automation',
        trigger=EventTrigger(
            expect={'prefect.flow-run.Completed', 'prefect.task-run.Running'},
            match=ResourceSpecification.model_validate({
                'prefect.resource.id': ['prefect.flow-run.*', 'prefect.task-run.*'],
            }),
            posture='Reactive'
        ),
        actions=[CallWebhook(block_document_id=block_id, payload='{{ event.model_dump_json() }}')]
    )
    result = await automation.acreate()
    print(f""Created automation: {result.id}"")

if __name__ == '__main__':
    import asyncio
    asyncio.run(create_automation())
```

The browser console displays the following error in the UI:

```
Error: Automation action type is missing case for: call-webhook
    gKe index-XA97onRR.mjs:2988
    map index-XA97onRR.mjs:31474
    u automation.ts:14
    map index-XA97onRR.mjs:31474
    getAutomations automationsApi.ts:18
    response vue-compositions.mjs:5397
    run reactivity.esm-bundler.js:77
    execute vue-compositions.mjs:5397
    subscribe vue-compositions.mjs:5384
    subscribe vue-compositions.mjs:5439
    xn vue-compositions.mjs:5501
    setup Automations.vue:48
    Kx runtime-core.esm-bundler.js:199
    _pe runtime-core.esm-bundler.js:7908
    gpe runtime-core.esm-bundler.js:7868
    ie runtime-core.esm-bundler.js:5216
    te runtime-core.esm-bundler.js:5182
    w runtime-core.esm-bundler.js:4700
    Ot runtime-core.esm-bundler.js:5327
    run reactivity.esm-bundler.js:225
    fe runtime-core.esm-bundler.js:5454
    ie runtime-core.esm-bundler.js:5230
    te runtime-core.esm-bundler.js:5182
    w runtime-core.esm-bundler.js:4700
    Ot runtime-core.esm-bundler.js:5327
    run reactivity.esm-bundler.js:225
    fe runtime-core.esm-bundler.js:5454
    ie runtime-core.esm-bundler.js:5230
    te runtime-core.esm-bundler.js:5182
    w runtime-core.esm-bundler.js:4700
    Ot runtime-core.esm-bundler.js:5327
    run reactivity.esm-bundler.js:225
    fe runtime-core.esm-bundler.js:5454
    ie runtime-core.esm-bundler.js:5230
    te runtime-core.esm-bundler.js:5182
    w runtime-core.esm-bundler.js:4700
    H runtime-core.esm-bundler.js:4933
    F runtime-core.esm-bundler.js:4855
    L runtime-core.esm-bundler.js:4820
    w runtime-core.esm-bundler.js:4688
    Ot runtime-core.esm-bundler.js:5327
    run reactivity.esm-bundler.js:225
    fe runtime-core.esm-bundler.js:5454
    registerDep runtime-core.esm-bundler.js:7202
    promise callback*registerDep runtime-core.esm-bundler.js:7187
    ie runtime-core.esm-bundler.js:5223
    te runtime-core.esm-bundler.js:5182
    w runtime-core.esm-bundler.js:4700
    Ot runtime-core.esm-bundler.js:5406
    run reactivity.esm-bundler.js:225
    runIfDirty reactivity.esm-bundler.js:263
    Kx runtime-core.esm-bundler.js:199
    TY runtime-core.esm-bundler.js:408
    promise callback*EY runtime-core.esm-bundler.js:322
    K4 runtime-core.esm-bundler.js:336
    cpe runtime-core.esm-bundler.js:7321
    scheduler runtime-core.esm-bundler.js:6197
    scheduler reactivity.esm-bundler.js:1830
    trigger reactivity.esm-bundler.js:253
    _9 reactivity.esm-bundler.js:311
    notify reactivity.esm-bundler.js:597
    trigger reactivity.esm-bundler.js:571
    set value reactivity.esm-bundler.js:1456
    J vue-router.mjs:3498
    V vue-router.mjs:3363
    promise callback*V vue-router.mjs:3330
    R vue-router.mjs:3255
    install vue-router.mjs:3699
    use runtime-core.esm-bundler.js:3863
    HNt colorMode.ts:23
    <anonymous> main.ts:22
vue-compositions.mjs:5399:85
```

### Version info

```Text
Version:             3.3.5
API version:         0.8.4
Python version:      3.12.9
Git commit:          db4b7a33
Built:               Thu, Apr 17, 2025 09:25 PM
OS/Arch:             linux/x86_64
Profile:             ephemeral
Server type:         server
Pydantic version:    2.10.6
Integrations:
  prefect-docker:    0.6.3
  prefect-azure:     0.4.3
```

### Additional context

The frontend is successfully retrieving the JSON data via API:

![Image](https://github.com/user-attachments/assets/ac41a60d-333f-4750-a566-5296d3539660)

But does not display anything in the UI:

![Image](https://github.com/user-attachments/assets/0707405b-5eba-46f0-b63e-b83d663b9e8e)",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17889/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17889
17888,Cache policy does not work in the task decorator when written in the following order TASK_SOURCE + INPUTS,closed,completed,2025-04-22T23:05:10Z,2025-04-30T20:57:05Z,2025-04-30T20:52:07Z,1,"['bug', 'needs:mre']",zhas1995,,NONE,"### Bug summary

Cache policy does not work in the task decorator when written in the following order TASK_SOURCE + INPUTS (cache_policy=INPUTS + TASK_SOURCE) [following the docs], but INPUTS + TASK_SOURCE works

### Version info

```Text
Prefect 3.3.4
```

### Additional context

_No response_",cicdw,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17888/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17888
17887,Prefect client creates incorrect flow runs parameters due to unexpected serialization behavior,closed,completed,2025-04-22T22:33:38Z,2025-05-13T23:29:47Z,2025-04-29T20:33:57Z,2,['bug'],levzem,,NONE,"### Bug summary

https://github.com/PrefectHQ/prefect/blob/main/src/prefect/client/orchestration/_deployments/client.py#L614

The Prefect client uses the `exclude_unset` setting for `model_dump()`, which has the unfortunate side effect of dropping default fields that were mutated afterwards.

A simple example is

```
class MyFlowParam(BaseModel):

    dropped: list[str] = Field(default_factory=list)

param = MyFlowParam()
param.dropped.append(""mutated"")

my_flow(param)
```

this will persist the flow run parameters as `{""param"": {}}` instead of `{""param"": {""dropped"": [""mutated""]}}`

I would recommend considering setting `exclude_default` instead of `exclude_unset` as this is a really nasty foot gun and took a lot of time for me to get to the bottom of.

See for more explanations below:
https://github.com/pydantic/pydantic/discussions/5749
https://github.com/pydantic/pydantic/issues/9866

### Version info

```Text
prefect: 3.2.6
```

### Additional context

_No response_",zzstoatzz,1,https://api.github.com/repos/PrefectHQ/prefect/issues/17887/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17887
17885,Automation Action does not pass non-string types to downstream deployment run that is triggered,closed,not_planned,2025-04-22T19:10:37Z,2025-05-01T17:04:04Z,2025-05-01T17:04:03Z,2,['bug'],robfreedy,,CONTRIBUTOR,"### Bug summary

When an Automation is triggered, an automation action to run a deployment allows for jinja templating to pass in parameters from the triggering flow run. When passing the parameters from the first flow run to the second flow run in the Automation Action, the Jinja templating does not allow for converting types or even passing in the same type. The automation action passes the values as strings to the downstream flow run. 

First Flow: 

```python
from prefect import flow

@flow
def first_flow(x: int, y: int):
    print(x+y)

if __name__ == ""__main__"":
    first_flow.serve(name=""first-flow"", parameters={""x"": 1, ""y"": 2})
```

Second Flow:

```python
from prefect import flow

@flow
def second_flow(x: int, y: int):
    print(x-y)

if __name__ == ""__main__"":
    second_flow.serve(name=""second-flow"")
```

Automation Definition: 

![Image](https://github.com/user-attachments/assets/e8e91f95-6d91-4861-a5ac-1f98861fab26)

![Image](https://github.com/user-attachments/assets/b6cd7b3c-6fbe-440b-97bb-d6bb7712b5c2)

Error from Automation Action Failed Event: 

```
""reason"": ""Validation error occurred for 'run-deployment' - Error creating flow run: Validation failed for field 'y'. Failure reason: '2' is not of type 'integer'"",
    ""validation_error"": ""Error creating flow run: Validation failed for field 'y'. Failure reason: '2' is not of type 'integer'"",
    ""status_code"": 409
```

### Version info

```Text
Version:             3.3.4
API version:         0.8.4
Python version:      3.11.10
Git commit:          7ca03553
Built:               Fri, Apr 11, 2025 12:27 AM
OS/Arch:             darwin/arm64
Profile:             test
Server type:         cloud
Pydantic version:    2.10.2
```

### Additional context

_No response_",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17885/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17885
17884,cloning private repo with submodule not working,closed,completed,2025-04-22T15:53:27Z,2025-04-22T17:21:14Z,2025-04-22T17:21:13Z,5,['bug'],benedictdebrah,,NONE,"### Bug summary

please i am trying to clone a private repo that has a submodule inn it.
cloning private repo works but it fails when i add include_submodules = (True or true) to clone the submodules .

![Image](https://github.com/user-attachments/assets/7a01c5bb-4c09-471c-b1c8-3e12f2ee918e)

```
pull:
  - prefect.deployments.steps.git_clone:
      repository:url
      credentials: ""{{ prefect.blocks.github-credentials.x }}""
      include_submodules: True (or true it still doesnt work)


```
the rest of the deployment continues

### Version info

```Text
Version:             3.3.5
API version:         0.8.4
Python version:      3.12.8
Git commit:          db4b7a33
Built:               Thu, Apr 17, 2025 09:25 PM
OS/Arch:             darwin/x86_64
Profile:             ephemeral
Server type:         cloud
Pydantic version:    2.11.3
Integrations:
  prefect-docker:    0.6.2
  prefect-github:    0.3.1
  prefect-shell:     0.3.1
```

### Additional context

_No response_",benedictdebrah,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17884/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17884
17883,Snowflake-Credentials block from Prefect-Snowflake does not work with encrypted private keys due to bad regex,closed,completed,2025-04-22T13:26:37Z,2025-05-05T20:48:22Z,2025-05-05T20:25:40Z,2,['bug'],konwiddak,,NONE,"### Bug summary

Snowflake-Credentials can be set up using private-public keypair. Ideally the key would be encrypted with a private key passphrase.

![Image](https://github.com/user-attachments/assets/f7438382-10dc-4b19-b0b4-d6318740c4b7)

An encrypted private key pem file is structured (this is not a real key!):

```
-----BEGIN RSA PRIVATE KEY-----
Proc-Type: 4,ENCRYPTED
DEK-Info: DES-EDE3-CBC,ABCDEF304983345

eeiuf9ehfiuehf989879heifhaiefa78fheahfe8a7hf8e7hf8ea7hf8ea7
ef9hea9afhe98y395874938749q38ya9r8h3f938hf938hf93qhf93ahhhh
30ru83q9r83q98r3q98rh39h8r3h838383rh39rh398qh938rh3q9hrjjjj
-----END RSA PRIVATE KEY-----
```

Unlike unencrypted keys, it contains the keywords Proc-Type and DEK-Info.

prefect/src/integrations/prefect-snowflake/prefect-snowflake/credentials.py

Line 226:

```
composed_private_key = self._compose_pem(private_key)
```

_compose_pem does a regex on the PEM file using the following pattern to split the key into parts:

```
_SIMPLE_PEM_CERTIFICATE_REGEX = ""^(-+[^-]+-+)([^-]+)(-+[^-]+-+)""
```

 Unfortunately this regex identifies the ""-"" in the ""Proc-Type"" keyword as the start of the last line of the PEM file and the - in DEK-Info as the end of the file. This means that it parses the key to be:

```
-----BEGIN RSA PRIVATE KEY-----\nProc\n-Type: 4,ENCRYPTED\r\nDEK-
```

This is now an invalid key and it throws an error:

```
 ValueError('Could not deserialize key data. The data may be in an incorrect format, the provided password may be incorrect, it may be encrypted with an unsupported algorithm, or it may be an unsupported key type (e.g. EC curves with explicit parameters).', [<OpenSSLError(code=503841036, lib=60, reason=524556, reason_text=unsupported)>])
```

If I patch line 226 to be:

```
composed_private_key = private_key
```

Then it loads and decrypts the key correctly, just without protection of malformed pem files.

The process needs to be adjusted to reassemble the pem file correctly.

### Version info

```Text
Version:             3.3.5
API version:         0.8.4
Python version:      3.12.10
Git commit:          db4b7a33
Built:               Thu, Apr 17, 2025 09:25 PM
OS/Arch:             win32/AMD64
Profile:             prod
Server type:         server
Pydantic version:    2.11.3
Integrations:
  prefect-dask:      0.3.4
  prefect-snowflake: 0.28.2
```

### Additional context

_No response_",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17883/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17883
17882,Secondary ordering in UI logs,open,,2025-04-22T10:37:00Z,2025-04-22T11:31:56Z,,0,['bug'],LukasJerabek,,NONE,"### Bug summary

Hello,

in case of low precision of timestamp column records like on a picture, we don't get the correct order in the UI of logs for tasks or flows. It would be nice to have secondary ordering in the UI as well, I think created is good adept?

![Image](https://github.com/user-attachments/assets/101d3384-8918-4724-b1df-234badcc0cc8)

### Version info

```Text
Version:             3.3.5
API version:         0.8.4
Python version:      3.13.1
Git commit:          db4b7a33
Built:               Thu, Apr 17, 2025 09:25 PM
OS/Arch:             linux/x86_64
Profile:             local
Server type:         server
Pydantic version:    2.10.4
Integrations:
  prefect-docker:    0.6.2
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17882/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17882
17881,-,closed,duplicate,2025-04-22T10:34:05Z,2025-04-22T10:37:07Z,2025-04-22T10:37:07Z,0,['enhancement'],LukasJerabek,,NONE,-,LukasJerabek,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17881/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17881
17879,extra loggers not writing to prefect API in prefect 3,closed,completed,2025-04-22T00:31:45Z,2025-04-22T18:07:27Z,2025-04-22T18:07:26Z,1,['bug'],rcash,,CONTRIBUTOR,"### Bug summary

logs from a logger added to `PREFECT_LOGGING_EXTRA_LOGGERS`  do not appear to be written to the prefect API or UI when running Prefect 3. the same code + configs result in the logs being output to the UI on Prefect 2 (2.20.16).

steps to reproduce:
deploy flow with helper module, ensure job variables to set logging config are set, then run flow - the ""adding"" INFO level log appears locally (using a process worker) but not in the UI. tested against cloud + self hosted w/ same behavior.

`add_flow.py`:
```
from prefect import flow

from my_helper_module import add_ints


@flow(log_prints=True)
def add_flow():
    print(""Starting Flow"")
    result = add_ints(1, 2)
    print(result)
```

`my_helper_module.py`:
```
import logging
import sys

logger = logging.getLogger(""my_logger"")

logger.setLevel(logging.INFO)
stream_handler = logging.StreamHandler(stream=sys.stdout)
stream_handler.setLevel(logging.INFO)
logger.addHandler(stream_handler)


def add_ints(a: int, b: int) -> int:
    logger.info(""Adding %i to %i yields %i"", a, b, a+ b)
    return a + b
```

`prefect.yaml`:
```
deployments:
- name: add-flow
  tags: []
  entrypoint: add_flow.py:add_flow
  parameters: {}
  work_pool:
    name: local-process-two
    job_variables: {
      env: {
        PREFECT_LOGGING_EXTRA_LOGGERS: my_logger,
        PREFECT_LOGGING_LEVEL: INFO
      }
    }
  schedules: []
```



### Version info

```Text
Version:             3.3.5
API version:         0.8.4
Python version:      3.12.9
Git commit:          db4b7a33
Built:               Thu, Apr 17, 2025 09:25 PM
OS/Arch:             darwin/arm64
Profile:             sbx-rowdy-cloud
Server type:         cloud
Pydantic version:    2.11.2
Integrations:
  prefect-gcp:       0.6.5
  prefect-gitlab:    0.3.1
  prefect-databricks: 0.3.0
  prefect-github:    0.3.1
  prefect-snowflake: 0.28.3
```

### Additional context

logs from the process worker when run on prefect three
```
17:28:46.194 | INFO    | prefect.flow_runs.worker - Worker 'ProcessWorker b27a9f18-3418-4045-ad7e-10d7918bab75' submitting flow run '24c0bf92-e161-4e2f-b1da-1c06305efec8'
17:28:46.266 | INFO    | prefect.flow_runs.runner - Opening process...
17:28:46.293 | INFO    | prefect.flow_runs.worker - Completed submission of flow run '24c0bf92-e161-4e2f-b1da-1c06305efec8'
17:28:47.179 | INFO    | Flow run 'zippy-mule' -  > Running set_working_directory step...
17:28:47.273 | INFO    | Flow run 'zippy-mule' - Beginning flow run 'zippy-mule' for flow 'add-flow'
17:28:47.274 | INFO    | Flow run 'zippy-mule' - View at http://localhost:4200/runs/flow-run/24c0bf92-e161-4e2f-b1da-1c06305efec8
17:28:47.274 | INFO    | Flow run 'zippy-mule' - Starting Flow
Adding 1 to 2 yields 3
17:28:47.275 | INFO    | my_logger - Adding 1 to 2 yields 3
17:28:47.275 | INFO    | Flow run 'zippy-mule' - 3
17:28:47.293 | INFO    | Flow run 'zippy-mule' - Finished in state Completed()
17:28:47.403 | INFO    | prefect.flow_runs.runner - Process for flow run 'zippy-mule' exited cleanly.
```

flow run logs in the UI:

![Image](https://github.com/user-attachments/assets/80243d04-1f87-47ec-9136-124ebfbf9a72)

job variable overrides (visible in the UI):

![Image](https://github.com/user-attachments/assets/69a2f000-fd2f-434f-bba3-e7af2fc23f4a)
",rcash,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17879/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17879
17877,Can't load block value in Jupyter notebook,open,,2025-04-21T17:13:38Z,2025-04-21T22:46:22Z,,1,['bug'],bnaul,,CONTRIBUTOR,"### Bug summary

```
from prefect.blocks.core import Block

Block.load(""secret/psql-host"").get()
```
Works in a regular shell but fails in Jupyter with
```
AttributeError                            Traceback (most recent call last)
Input In [8], in <cell line: 3>()
      1 from prefect.blocks.core import Block
----> 3 Block.load(""secret[/psql-host](http://localhost:8888/psql-host)"").get()

AttributeError: 'coroutine' object has no attribute 'get'
```
Presumably something from #16341 that's getting tripped up by the Jupyter runtime environment (a little weird though that it doesn't happen in IPython).

### Version info

```Text
Version:             3.3.5
API version:         0.8.4
Python version:      3.10.16
Git commit:          db4b7a33
Built:               Thu, Apr 17, 2025 09:25 PM
OS/Arch:             darwin/arm64
Profile:             default
Server type:         cloud
Pydantic version:    2.9.2
Integrations:
  prefect-dask:      0.3.3
  prefect-gcp:       0.6.4
  prefect-kubernetes: 0.5.8
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17877/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17877
17875,Unable to dynamically create a prefect deployment using flow_from_source from within a fastapi endpoint function,open,,2025-04-21T09:05:08Z,2025-05-01T04:12:01Z,,6,['bug'],GildeshAbhay,,NONE,"### Bug summary

Hi all,
We are trying to deploy a FastAPI endpoint, which calls a function to dynamically create a prefect deployment (sourced from git) but its failing.

Below is the code that is being used

```
async def create_deployment_for_batch_job(
    batch_job_id: int,
    project_id: int,
    user_id: str,
    query: str,
    limit: int,
    priority: str = ""low"",
    cron_schedule: str = None,
):
    """"""Creates a Prefect deployment for a batch job""""""
    print(""start"")
    deployment_name = f""batch_job_{batch_job_id}""
    print(""deployment_name"")
    # Create deployment that will call the endpoint
    deployment = await flow.from_source(
        source=git_repo,
        entrypoint=""backend/app/api/v1/endpoints/batch.py:run_batch_pipeline_flow"",

    )
    await deployment.deploy(
        name=deployment_name,
        work_pool_name=""my-local-pool"",
        parameters={
            ""query"": query,
            ""limit"": limit,
            ""priority"": priority,
            ""user_id"": user_id,
            ""project_id"": project_id,
            ""batch_job_id"": batch_job_id
        },
        # schedule=CronSchedule(cron=cron_schedule, timezone=""UTC"") if cron_schedule else None,
        tags=[""batch-pipeline"", ""prefect-git-deployment""]
    )
```
this is being called within the below function

```
@router.post(""/projects/{project_id}/batch_job_creation/"")
async def create_batch_job_publication_retrieval(
    project_id: int,
    query: str,
    limit: int ,
    priority: str,
    user: CurrentUser,
    cron_job_schedule: Optional[str] = None,
):
    """"""
    Create a new batch job for publication retrieval.    
    """"""
    user_id, _ = user
    batch_service = BatchService()
    try:
        match = re.search(r'\(""(\d{4})""\[PDAT\] *: *""(\d{4})""\[PDAT\]\)', query)
        if match:
            start_date = match.group(1)
            end_date = match.group(2)
        else:
            start_date = None
            end_date = None
        #started_at = time.time()
        current_year = datetime.now(timezone.utc).year
        start_date = start_date or str(current_year - 5)  # Default to 5 years ago
        end_date = end_date or str(current_year)          # Default to current year

        batch_job_id = await batch_service.create_batch_job(project_id=project_id, search_query=query, start_date=start_date, end_date=end_date, 
                                                            max_publications=limit, priority=priority, user_id=user_id, cron_job_schedule = cron_job_schedule)
        
        # TODO: This functionality works fine when run using from a standalone script [deployment_test.py in tests] but is failing here. Need to Debug.
        # Create Prefect deployment
        print(""passed batch job"", batch_job_id)
        await create_deployment_for_batch_job(
             batch_job_id=batch_job_id,
             project_id=project_id,
             user_id=user_id,
             query=query,
             limit=limit,
             priority=priority,
             cron_schedule=cron_job_schedule
        )
```
The above code gives these errors
cannot pickle 'coroutine' object
coroutine object does not have a function ""deploy"" (if i remove await from the flow_from_source function)
cannot call asyncio within a running event loop (when i tried to change await to asyncio.run())
Also tried making it a synchronous function (create_deployment_for_batch_job)
Also tried using create_task and then awaiting that task.
Tried these links
https://github.com/PrefectHQ/prefect/issues/15008
https://linen.prefect.io/t/23211429/ulva73b9p-i-d-like-to-deploy-a-flow-using-from-source-from-a
https://linen.prefect.io/t/26842108/ulva73b9p-ulva73b9p-i-am-upgrading-to-prefect-3-from-prefect
https://linen.prefect.io/t/26884307/ulva73b9p-how-do-i-run-prefect-within-a-docker-container-tha
and a few more but to no avail.

### Version info

```Text
Version:             3.3.2
API version:         0.8.4
Python version:      3.10.16
Git commit:          e49e3185
Built:               Thu, Apr 03, 2025 09:25 PM
OS/Arch:             win32/AMD64
Profile:             ephemeral
Server type:         cloud
Pydantic version:    2.11.2
Integrations:
  prefect-github:    0.3.1
```

### Additional context

Name: fastapi
Version: 0.115.12
Summary: FastAPI framework, high performance, easy to learn, fast to code, ready for production
Home-page: https://github.com/fastapi/fastapi
Author:
Author-email: =?utf-8?q?Sebasti=C3=A1n_Ram=C3=ADrez?= <tiangolo@gmail.com>
License:
Location: c:\users\abhay.saini\appdata\local\miniconda\envs\pie_v2\lib\site-packages    
Requires: pydantic, starlette, typing-extensions
Required-by: prefect",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17875/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17875
17868,Add support for `resolve_futures_to_results`,closed,completed,2025-04-20T01:51:14Z,2025-04-21T15:04:19Z,2025-04-21T15:04:19Z,0,['enhancement'],Andrew-S-Rosen,,CONTRIBUTOR,"### Describe the current behavior

Prefect currently has a nice utility function for resolving futures to states:

https://github.com/PrefectHQ/prefect/blob/c9c018d468694ea61ce3a482948bf4d03bb67227/src/prefect/futures.py#L605-L614

There is no analogous function for resolving futures to results.

### Describe the proposed behavior

An analogous function should be made called `resolve_futures_to_results`.

### Example Use

_No response_

### Additional context

_No response_",desertaxle,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17868/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17868
17867,Have a chance to terminate all flow's (concurrent) tasks on flow exit / canceling futures,open,,2025-04-19T20:12:53Z,2025-05-01T17:32:48Z,,2,['enhancement'],hnykda,,NONE,"### Bug summary

Consider this simple flow:

```
from prefect import flow, task
import time


@task
def long_task():
    time.sleep(100)


@task
def short_task():
    time.sleep(5)
    return True


@flow
def f():
    lt = long_task.submit()
    st = short_task.submit()
    if st.result():
        return ""I finished""
    return ""This will never happen""


if __name__ == ""__main__"":
    f.serve(name=""f"")
```

I want to trigger some stuff and I don't mind that I might cancel them mid-flight. What matters to me is that they all run as soon as possible just in case I will need them. However, if the flow above finishes (and even shows as `Completed`, confusingly), the future of long_task still seems to be still running.

I understand why, but I am surprised there doesn't seem to be a way to cancel all existing running tasks. I don't want to `wait` nor `result` (those would block other parts from the flow), and I don't see any `.cancel` or anything. In my ideal world, the warning would be raised and the task killed/terminated. 

Another variant of this is when a concurrent task raises - again, the other submitted task is not cancelled. Again, I realize that ""terminate all on any task failure"" is not a ""universal"" behavior everyone wants all the time, but I couldn't find any mention about this behavior and its adjustment in the docs.

![Image](https://github.com/user-attachments/assets/2c38d8be-ec82-4083-8be7-8829b4e08a12)

### Version info

```Text
Version:             3.3.5
API version:         0.8.4
Python version:      3.13.0
Git commit:          db4b7a33
Built:               Thu, Apr 17, 2025 09:25 PM
OS/Arch:             darwin/arm64
Profile:             local
Server type:         server
Pydantic version:    2.11.3
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17867/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17867
17865,Variable name validation restrictions - underscores only?,closed,completed,2025-04-19T08:32:09Z,2025-05-07T02:11:37Z,2025-05-06T23:44:28Z,3,[],lelouvincx,,CONTRIBUTOR,"## Background

I'm currently working on upgrading from the deprecated `String` blocks to the newer `Variable` objects as part of preparation for the June 2025 deprecation deadline (don't remember exactly, but I have an impression that I've read somewhere). However, I've hit a roadblock with variable naming conventions.

## The Issue

When trying to register a block with a variable name that contains hyphens, I'm receiving this validation error:

```
Failed to register GCP secrets for ci: 1 validation error for `VariableCreate` name.
Value error: Variable names must only contain lowercase letters, numbers, and underscores.
```

The specific variable name that's failing is `""gcp-cred""` because it contains a hyphen (`-`).

## Question

**Is there a specific technical reason or design principle behind restricting Variable names to only lowercase letters, numbers, and underscores?** 

This seems more restrictive than many other systems that commonly allow hyphens in identifiers. Since I need to migrate several blocks that use hyphenated naming conventions, understanding the reasoning would help me plan my migration approach better.

Also, if this is an intentional restriction, it might be helpful to have this more explicitly documented in the migration guides for those of us moving from String blocks (which presumably allowed hyphens) to Variables.

Thanks for any insights!",zzstoatzz,1,https://api.github.com/repos/PrefectHQ/prefect/issues/17865/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17865
17864,Update documentation for accessing transaction data with tasks,open,,2025-04-19T04:25:09Z,2025-05-12T17:23:52Z,,3,['bug'],willhcr,,NONE,"### Bug summary

Accessing transaction data from an on_rollback hook works, but not from an on_commit hook. Also it appears if an on_commit hook fails, the subsequent on_rollback hook also cannot access transaction data.

```python
from prefect import task
from prefect.transactions import transaction


@task
def begin(msg: str):
    print(f'begin: {msg}')


@task
def end(msg: str):
    print(f'end: {msg}')


@begin.on_commit
@begin.on_rollback
def always_cleanup(txn):
    job = txn.get('job')
    end(job)


@task
def txn_do_job():
    """"""This results in a ValueError(f""Could not retrieve value for unknown key: {name}"")""""""

    with transaction() as txn:
        job = '12345'
        txn.set('job', job)
        begin(job)
        # do work


@task
def txn_do_job_with_exc():
    """"""This runs begin() and end()""""""

    with transaction() as txn:
        job = '12345'
        txn.set('job', job)
        begin(job)
        # do work
        raise Exception('Error')


if __name__ == '__main__':
    txn_do_job()
    txn_do_job_with_exc()
```

### Version info

```Text
Version:             3.3.5
API version:         0.8.4
Python version:      3.12.10
Git commit:          db4b7a33
Built:               Thu, Apr 17, 2025 09:25 PM
OS/Arch:             linux/x86_64
Profile:             ephemeral
Server type:         ephemeral
Pydantic version:    2.10.6
Server:
  Database:          sqlite
  SQLite version:    3.47.1
Integrations:
  prefect-docker:    0.6.2
  prefect-azure:     0.4.3
```

### Additional context

```
begin: 12345
21:22:50.787 | INFO    | Task run 'begin' - Finished in state Completed()
21:22:50.792 | INFO    | Task run 'begin' - Running commit hook 'always_cleanup'
21:22:50.792 | ERROR   | Task run 'begin' - An error was encountered while running commit hook 'always_cleanup'
21:22:50.793 | ERROR   | Task run 'begin' - An error was encountered while committing transaction 'cf4cbc18f0fd6547e2311d85e77bd4e8'
Traceback (most recent call last):
  File ""/home/user/dev/proj/.venv/lib/python3.12/site-packages/prefect/transactions.py"", line 349, in commit
    self.run_hook(hook, ""commit"")
  File ""/home/user/dev/proj/.venv/lib/python3.12/site-packages/prefect/transactions.py"", line 401, in run_hook
    raise exc
  File ""/home/user/dev/proj/.venv/lib/python3.12/site-packages/prefect/transactions.py"", line 395, in run_hook
    hook(self)
  File ""/home/user/dev/proj/flows/tests/txn_sample.py"", line 18, in always_cleanup
    job = txn.get('job')
          ^^^^^^^^^^^^^^
  File ""/home/user/dev/proj/.venv/lib/python3.12/site-packages/prefect/transactions.py"", line 162, in get
    value = parent.get(name, default)
            ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/user/dev/proj/.venv/lib/python3.12/site-packages/prefect/transactions.py"", line 167, in get
    raise ValueError(f""Could not retrieve value for unknown key: {name}"")
ValueError: Could not retrieve value for unknown key: job
21:22:50.794 | INFO    | Task run 'begin' - Running rollback hook 'always_cleanup'
21:22:50.795 | ERROR   | Task run 'begin' - An error was encountered while running rollback hook 'always_cleanup'
21:22:50.796 | ERROR   | Task run 'begin' - An error was encountered while rolling back transaction 'cf4cbc18f0fd6547e2311d85e77bd4e8'
Traceback (most recent call last):
  File ""/home/user/dev/proj/.venv/lib/python3.12/site-packages/prefect/transactions.py"", line 349, in commit
    self.run_hook(hook, ""commit"")
  File ""/home/user/dev/proj/.venv/lib/python3.12/site-packages/prefect/transactions.py"", line 401, in run_hook
    raise exc
  File ""/home/user/dev/proj/.venv/lib/python3.12/site-packages/prefect/transactions.py"", line 395, in run_hook
    hook(self)
  File ""/home/user/dev/proj/flows/tests/txn_sample.py"", line 18, in always_cleanup
    job = txn.get('job')
          ^^^^^^^^^^^^^^
  File ""/home/user/dev/proj/.venv/lib/python3.12/site-packages/prefect/transactions.py"", line 162, in get
    value = parent.get(name, default)
            ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/user/dev/proj/.venv/lib/python3.12/site-packages/prefect/transactions.py"", line 167, in get
    raise ValueError(f""Could not retrieve value for unknown key: {name}"")
ValueError: Could not retrieve value for unknown key: job

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/user/dev/proj/.venv/lib/python3.12/site-packages/prefect/transactions.py"", line 414, in rollback
    self.run_hook(hook, ""rollback"")
  File ""/home/user/dev/proj/.venv/lib/python3.12/site-packages/prefect/transactions.py"", line 401, in run_hook
    raise exc
  File ""/home/user/dev/proj/.venv/lib/python3.12/site-packages/prefect/transactions.py"", line 395, in run_hook
    hook(self)
  File ""/home/user/dev/proj/flows/tests/txn_sample.py"", line 18, in always_cleanup
    job = txn.get('job')
          ^^^^^^^^^^^^^^
  File ""/home/user/dev/proj/.venv/lib/python3.12/site-packages/prefect/transactions.py"", line 162, in get
    value = parent.get(name, default)
            ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/user/dev/proj/.venv/lib/python3.12/site-packages/prefect/transactions.py"", line 167, in get
    raise ValueError(f""Could not retrieve value for unknown key: {name}"")
ValueError: Could not retrieve value for unknown key: job
21:22:50.798 | INFO    | Task run 'txn_do_job' - Finished in state Completed()
```",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17864/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17864
17857,Support for canceling a run currently running when another flow gets queued with the same parameters,open,,2025-04-18T16:10:02Z,2025-04-18T16:10:02Z,,0,['enhancement'],cbelsole,,CONTRIBUTOR,"### Describe the current behavior

Currently, this is not possible to my knowledge.

### Describe the proposed behavior

If a flow run gets picked up, it should cancel any flow run currently executing with the same parameters deduping the queue.

### Example Use

We ingest files which are updated when changed if there are rapid changes over time (even when we debounce them on our end) this can result in multiple flows with the same parameters in our pipeline. When this happens, prefect could cancel the currently running flow and enqueue the new one.

### Additional context

CC @gabcoyne ",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17857/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17857
17855,Create bulk route for submitting flow runs,open,,2025-04-18T16:05:34Z,2025-04-18T16:05:53Z,,0,['enhancement'],cbelsole,,CONTRIBUTOR,"### Describe the current behavior

We are currently calling `/deployments/<deployment id>/create_flow_run` to create a flow run. When using Prefect Cloud we are seeing rate limits (429) because we are submitting thousands of runs at a time which is a semi-normal use case for us.

### Describe the proposed behavior

Instead of getting rate limited, we would like to submit flow runs in batches at something like `/deployments/<deployment id>/create_flow_run/bulk` in order to not run into rate limits.

### Example Use

_No response_

### Additional context

CC: @gabcoyne ",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17855/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17855
17852,Important: Library incompatible with pydantic-settings v2.9.0,closed,completed,2025-04-18T08:46:45Z,2025-04-18T14:57:33Z,2025-04-18T14:57:33Z,3,['bug'],jbw-vtl,desertaxle,CONTRIBUTOR,"### Bug summary

Hi All,

Raising this here for awareness, it seems pydantic-settings just released v2.9.0 which introduced a breaking change, moving ConfigFileSourceMixin -> pydantic_settings.sources.base

Afraid this is causing a full outage, anyone upgrading dependencies will be impacted.

Needs to be resolved on pydantic-settings by exposing the class back on the package level, however short term would recommend to avoiding the version in `prefects` dependencies as well.

The change
https://github.com/pydantic/pydantic-settings/compare/v2.8.1...v2.9.0#diff-d12ba043c3a543bca2fb83d7bb5a38427e5c192486106bdfeca885eeb864687b

https://github.com/PrefectHQ/prefect/blob/main/src/prefect/settings/sources.py#L20

Recommended action for prefect users:
Pin `pydantic-settings==2.8.1` short term to avoid the problematic import

```text
(secops-prefect-py3.11) PS C:\Users\jbw\Python\projects\prefect\secops-prefect> prefect server start
Traceback (most recent call last):
  File ""<frozen runpy>"", line 198, in _run_module_as_main
  File ""<frozen runpy>"", line 88, in _run_code
  File ""C:\Users\jbw\Python\projects\prefect\secops-prefect\.venv\Scripts\prefect.exe\__main__.py"", line 4, in <module>
  File ""C:\Users\jbw\Python\projects\prefect\secops-prefect\.venv\Lib\site-packages\prefect\cli\__init__.py"", line 1, in <module>
    import prefect.settings
  File ""C:\Users\jbw\Python\projects\prefect\secops-prefect\.venv\Lib\site-packages\prefect\settings\__init__.py"", line 13, in <module>
    from prefect.settings.legacy import (
  File ""C:\Users\jbw\Python\projects\prefect\secops-prefect\.venv\Lib\site-packages\prefect\settings\legacy.py"", line 10, in <module>
    from prefect.settings.base import PrefectBaseSettings
  File ""C:\Users\jbw\Python\projects\prefect\secops-prefect\.venv\Lib\site-packages\prefect\settings\base.py"", line 20, in <module>
    from prefect.settings.sources import (
  File ""C:\Users\jbw\Python\projects\prefect\secops-prefect\.venv\Lib\site-packages\prefect\settings\sources.py"", line 18, in <module>
    from pydantic_settings.sources import (
ImportError: cannot import name 'ConfigFileSourceMixin' from 'pydantic_settings.sources' (C:\Users\jbw\Python\projects\prefect\secops-prefect\.venv\Lib\site-packages\pydantic_settings\sources\__init__.py)
```

Would suggest changing prefect dependency bounds to

```
""pydantic_settings>2.2.1,<3.0.0,!=2.9.0"",
```

### Version info

```Text
Using `3.3.1`, however the same issue exists on the current master
```

### Additional context

Will link the related issue on pydantic side shortly.",desertaxle,2,https://api.github.com/repos/PrefectHQ/prefect/issues/17852/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17852
17850,Make uv an optional runtime dependency,open,,2025-04-17T21:28:27Z,2025-04-17T23:22:25Z,,4,['enhancement'],BwL1289,,NONE,"### Describe the current behavior

Right now `uv` is a required runtime dependency but is only used in `_experimental` functionality [here](https://github.com/PrefectHQ/prefect/blob/main/src/prefect/_experimental/bundles.py#L27). It's also wrapped in try / except so the functionality may work without it being installed anyway.

I know that the `_experimental` module is used in a few places in the repo (notably [here](https://github.com/PrefectHQ/prefect/blob/main/src/prefect/runner/runner.py#L659-L660)), but because `uv` is not a typical runtime dependency, and because it's rust based, it should be avoided if not strictly necessary.
### Describe the proposed behavior

Make `uv` an optional dependency.

### Example Use

_No response_

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17850/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17850
17848,serialization error on canceling a flow run when using ProcessPoolExecutor,open,,2025-04-17T18:51:11Z,2025-04-17T18:52:21Z,,0,['bug'],rcash,,CONTRIBUTOR,"### Bug summary

canceling a flow run with a task that submits work to a `ProcessPoolExecutor` surfaces the following serialization error (where `MockValSer` cannot be converted to `SchemaSerializer` when dumping a model inside of Prefect?) on the flow run's pod, and leaves the Prefect UI stuck in a ""canceling"" state. this is seen when using a `prefect-kubernetes` work pool.

stack trace from the pod's logs - right after canceling from the UI:
```
Traceback (most recent call last):
  File ""/usr/local/lib/python3.10/site-packages/prefect/runner/runner.py"", line 586, in execute_flow_run
    async with anyio.create_task_group() as tg:
  File ""/usr/local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py"", line 740, in __aexit__
    raise exc_val
  File ""/usr/local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py"", line 714, in __aexit__
    await asyncio.wait(self._tasks)
  File ""/usr/local/lib/python3.10/asyncio/tasks.py"", line 384, in wait
    return await _wait(fs, timeout, return_when, loop)
  File ""/usr/local/lib/python3.10/asyncio/tasks.py"", line 491, in _wait
    await waiter
asyncio.exceptions.CancelledError: Cancelled by cancel scope ffffa422bfa0

During handling of the above exception, another exception occurred:

  + Exception Group Traceback (most recent call last):
  |   File ""/usr/local/lib/python3.10/site-packages/prefect/cli/_utilities.py"", line 44, in wrapper
  |     return fn(*args, **kwargs)
  |   File ""/usr/local/lib/python3.10/site-packages/prefect/cli/_types.py"", line 156, in sync_fn
  |     return asyncio.run(async_fn(*args, **kwargs))
  |   File ""/usr/local/lib/python3.10/asyncio/runners.py"", line 44, in run
  |     return loop.run_until_complete(main)
  |   File ""/usr/local/lib/python3.10/asyncio/base_events.py"", line 649, in run_until_complete
  |     return future.result()
  |   File ""/usr/local/lib/python3.10/site-packages/prefect/cli/flow_run.py"", line 375, in execute
  |     await runner.execute_flow_run(id)
  |   File ""/usr/local/lib/python3.10/site-packages/prefect/runner/runner.py"", line 582, in execute_flow_run
  |     async with context:
  |   File ""/usr/local/lib/python3.10/site-packages/prefect/runner/runner.py"", line 1676, in __aexit__
  |     await self._runs_task_group.__aexit__(*exc_info)
  |   File ""/usr/local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py"", line 736, in __aexit__
  |     raise BaseExceptionGroup(
  | exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
  +-+---------------- 1 ----------------
    | Traceback (most recent call last):
    |   File ""/usr/local/lib/python3.10/site-packages/prefect/runner/runner.py"", line 1111, in _cancel_run
    |     await self._mark_flow_run_as_cancelled(
    |   File ""/usr/local/lib/python3.10/site-packages/prefect/runner/runner.py"", line 1539, in _mark_flow_run_as_cancelled
    |     await self._client.set_flow_run_state(flow_run.id, state, force=True)
    |   File ""/usr/local/lib/python3.10/site-packages/prefect/client/orchestration/_flow_runs/client.py"", line 804, in set_flow_run_state
    |     state=state_create.model_dump(mode=""json"", serialize_as_any=True),
    |   File ""/usr/local/lib/python3.10/site-packages/pydantic/main.py"", line 390, in model_dump
    |     return self.__pydantic_serializer__.to_python(
    | TypeError: 'MockValSer' object cannot be converted to 'SchemaSerializer'
    +------------------------------------
An exception occurred.
```

MRE:
```
import asyncio
import random
import time
from concurrent.futures import ProcessPoolExecutor
from typing import List

from prefect import flow, task
from prefect.task_runners
from prefect.cache_policies import NO_CACHE


def cpu_intensive_function(batch_id: int, items: List[int]) -> List[int]:
    print(f""Processing batch {batch_id} with {len(items)} items"")

    results = []
    for item in items:
        start = time.time()
        processing_time = random.uniform(0.1, 0.5)
        time.sleep(processing_time)  # Simulate CPU work

        result = sum(i * i for i in range(item, item + 10000))
        results.append(result)

        elapsed = time.time() - start
        print(f""Batch {batch_id}: Item {item} processed in {elapsed:.2f}s"")

    return results

@task(cache_policy=NO_CACHE)
async def process_batch(
    executor: ProcessPoolExecutor,
    semaphore: asyncio.Semaphore,
    batch_id: int,
    batch_data: List[int],
) -> List[int]:
    print(f""Task started for batch {batch_id}"")

    async with semaphore:
        loop = asyncio.get_event_loop()
        results = await loop.run_in_executor(
            executor, cpu_intensive_function, batch_id, batch_data
        )

    print(f""Task completed for batch {batch_id}"")
    return results


async def intermediary_function(data: List[int]) -> List[List[int]]:
    print(""Starting intermediary function"")

    batch_size = max(1, len(data) // 10)
    batches = [data[i : i + batch_size] for i in range(0, len(data), batch_size)][:10]

    semaphore = asyncio.Semaphore(3)

    # Create ProcessPoolExecutor
    with ProcessPoolExecutor(max_workers=4) as executor:
        tasks = []
        for batch_id, batch_data in enumerate(batches):
            task_result = await process_batch(executor, semaphore, batch_id, batch_data)
            tasks.append(task_result)

    print(""Completed intermediary function"")
    return tasks


@flow(name=""Process Data With Pool"")
async def entrypoint():
    print(""Starting main flow"")

    data = list(range(100))

    results = await intermediary_function(data)

    total_results = sum(len(batch) for batch in results)
    print(f""Processed {total_results} items across {len(results)} batches"")

    return results


if __name__ == ""__main__"":
    asyncio.run(entrypoint())
```



### Version info

```Text
Version:             3.1.14
API version:         0.8.4
Python version:      3.12.9
Git commit:          5f1ebb57
Built:               Thu, Jan 23, 2025 1:22 PM
OS/Arch:             darwin/arm64
Profile:             sbx-rowdy-cloud
Server type:         cloud
Pydantic version:    2.9.2
Integrations:
  prefect-docker:    0.6.2
  prefect-kubernetes: 0.5.3
```

### Additional context

`ProcessPoolExecutor` farms work out using the [multiprocessing](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing) lib ([concurrent.futures docs](https://docs.python.org/3/library/concurrent.futures.html#processpoolexecutor)) - note that the pod backs off as expected when canceled, but the flow run state does not appear to get set successfully because of the above error.

this could be related to #12075 and expanding support for `multiprocessing` in Prefect",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17848/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17848
17846,Schedule Parameter Overrides do not apply on redeploy of Deployment,closed,completed,2025-04-17T17:31:00Z,2025-04-18T15:04:05Z,2025-04-18T15:04:05Z,0,['bug'],robfreedy,,CONTRIBUTOR,"### Bug summary

When deploying a Prefect flow using the prefect.yaml, you can set default parameters for each schedule. 

When re-deploying a flow that has these defined, the scheduled runs that appear for the deployment schedule do not have the parameter override values for each scheduled flow run. 

Python flow file

```py
#flow.py with parameters

import dask.dataframe
import dask.distributed
from prefect import flow, task

@task
def read_data(start: str, end: str) -> dask.dataframe.DataFrame:
    df = dask.datasets.timeseries(start, end, partition_freq=""4W"")
    return df

@flow()
def dask_pipeline(list_of_dates = None):
    df = read_data.submit(list_of_dates[""list_of_dates""][0], list_of_dates[""list_of_dates""][1])
    print(df)

if __name__ == ""__main__"":
    dask_pipeline()
```

prefect.yaml with schedule defined: 
```yaml
# Welcome to your prefect.yaml file! You can use this file for storing and managing
# configuration for deploying your flows. We recommend committing this file to source
# control along with your flow code.

# Generic metadata about this project
name: ecs-test-example
prefect-version: 3.3.4

# build section allows you to manage and build docker images
build: null

# push section allows you to manage if and how this project is uploaded to remote locations
push: null

# pull section allows you to provide instructions for cloning this project in remote locations
pull:
- prefect.deployments.steps.set_working_directory:
    directory: /Users/rob.freedy/Documents/prefect/scratch/ecs-test-example

# the deployments section allows you to provide configuration for deploying flows
deployments:
- name: test-schedule-param-override
  version: null
  tags: []
  concurrency_limit: null
  description: null
  entrypoint: flow.py:dask_pipeline
  parameters: 
    list_of_dates: {}
  work_pool:
    name: local-worker
    work_queue_name: null
    job_variables: {}
  schedules:
  - cron: '*/5 * * * *'
    timezone: UTC
    day_or: true
    active: true
    parameters:
      list_of_dates:
        list_of_dates:
          - 2030
          - 2040
```

Steps to reproduce: 

1. Copy the flow.py and prefect.yaml locally
2. Deploy flow.py using provided prefect.yaml and prefect deploy command
3. Change values in the schedule parameters section of the prefect.yaml
4. Re-deploy using prefect deploy command
5. Check in UI the scheduled flow runs parameters that are passed in 

<img width=""535"" alt=""Image"" src=""https://github.com/user-attachments/assets/19cce8a5-1942-4cc8-9bae-6e6e4c569492"" />


### Version info

```Text
Version:             3.3.4
API version:         0.8.4
Python version:      3.11.10
Git commit:          7ca03553
Built:               Fri, Apr 11, 2025 12:27 AM
OS/Arch:             darwin/arm64
Profile:             test
Server type:         cloud
Pydantic version:    2.10.2
Integrations:
  prefect-dask:      0.3.4
  prefect-azure:     0.4.2
  prefect-docker:    0.6.2
  prefect-gcp:       0.6.2
  prefect-github:    0.3.1
  prefect-snowflake: 0.28.2
  prefect-aws:       0.5.9
```

### Additional context

_No response_",zangell44,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17846/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17846
17844,Failed to upgrade database from 3.3.3 to 3.3.4 due to TimeoutError,open,,2025-04-17T09:09:18Z,2025-04-17T09:18:22Z,,0,['bug'],matt-genie,,NONE,"### Bug summary

An attempt to upgrade the server to the latest version (3.3.4) failed due to a TimeoutError

**Repro Steps**
Run `prefect server database upgrade`

```
Are you sure you want to upgrade the Prefect database at postgresql+asyncpg://postgres:***@localhost:5432/prefect? [y/N]: y
Running upgrade migrations ...
Traceback (most recent call last):
  File ""/home/pmateusz/dev/.venv/lib/python3.12/site-packages/prefect/cli/_utilities.py"", line 44, in wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File ""/home/pmateusz/dev/.venv/lib/python3.12/site-packages/prefect/cli/_types.py"", line 156, in sync_fn
    return asyncio.run(async_fn(*args, **kwargs))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/pmateusz/.local/share/uv/python/cpython-3.12.7-linux-x86_64-gnu/lib/python3.12/asyncio/runners.py"", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File ""/home/pmateusz/.local/share/uv/python/cpython-3.12.7-linux-x86_64-gnu/lib/python3.12/asyncio/runners.py"", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/pmateusz/.local/share/uv/python/cpython-3.12.7-linux-x86_64-gnu/lib/python3.12/asyncio/base_events.py"", line 687, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File ""/home/pmateusz/dev/.venv/lib/python3.12/site-packages/prefect/cli/server.py"", line 455, in upgrade
    await run_sync_in_worker_thread(alembic_upgrade, revision=revision, dry_run=dry_run)
  File ""/home/pmateusz/dev/.venv/lib/python3.12/site-packages/prefect/utilities/asyncutils.py"", line 233, in run_sync_in_worker_thread
    result = await anyio.to_thread.run_sync(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/pmateusz/.venv/lib/python3.12/site-packages/anyio/to_thread.py"", line 56, in run_sync
    return await get_async_backend().run_sync_in_worker_thread(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/pmateusz/dev/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py"", line 2461, in run_sync_in_worker_thread
    return await future
           ^^^^^^^^^^^^
  File ""/home/pmateusz/dev/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py"", line 962, in run
    result = context.run(func, *args)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/pmateusz/dev/.venv/lib/python3.12/site-packages/prefect/utilities/asyncutils.py"", line 243, in call_with_mark
    return call()
           ^^^^^^
  File ""/home/pmateusz/dev/.venv/lib/python3.12/site-packages/prefect/server/database/alembic_commands.py"", line 36, in wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File ""/home/pmateusz/dev/.venv/lib/python3.12/site-packages/prefect/server/database/alembic_commands.py"", line 72, in alembic_upgrade
    alembic.command.upgrade(alembic_config(), revision, sql=dry_run)
  File ""/home/pmateusz/dev/.venv/lib/python3.12/site-packages/alembic/command.py"", line 406, in upgrade
    script.run_env()
  File ""/home/pmateusz/dev/.venv/lib/python3.12/site-packages/alembic/script/base.py"", line 586, in run_env
    util.load_python_file(self.dir, ""env.py"")
  File ""/home/pmateusz/dev/.venv/lib/python3.12/site-packages/alembic/util/pyfiles.py"", line 95, in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/pmateusz/dev/.venv/lib/python3.12/site-packages/alembic/util/pyfiles.py"", line 113, in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""<frozen importlib._bootstrap_external>"", line 995, in exec_module
  File ""<frozen importlib._bootstrap>"", line 488, in _call_with_frames_removed
  File ""/home/pmateusz/dev/.venv/lib/python3.12/site-packages/prefect/server/database/_migrations/env.py"", line 201, in <module>
    run_async_from_worker_thread(apply_migrations)
  File ""/home/pmateusz/dev/.venv/lib/python3.12/site-packages/prefect/utilities/asyncutils.py"", line 254, in run_async_from_worker_thread
    return anyio.from_thread.run(call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/pmateusz/dev/.venv/lib/python3.12/site-packages/anyio/from_thread.py"", line 59, in run
    return async_backend.run_async_from_thread(func, args, token=token)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/pmateusz/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py"", line 2501, in run_async_from_thread
    return f.result()
           ^^^^^^^^^^
  File ""/home/pmateusz/.local/share/uv/python/cpython-3.12.7-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py"", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File ""/home/pmateusz/.local/share/uv/python/cpython-3.12.7-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py"", line 401, in __get_result
    raise self._exception
TimeoutError
```




### Version info

```Text
prefect version                                                                                                                                                  7s Py data-provider 11:01:38
Version:             3.3.3
API version:         0.8.4
Python version:      3.12.7
Git commit:          4100d4ea
Built:               Sat, Apr 05, 2025 01:44 AM
OS/Arch:             linux/x86_64
Profile:             ephemeral
Server type:         ephemeral
Pydantic version:    2.10.6
Server:
  Database:          postgresql
Integrations:
  prefect-slack:     0.3.1
```

### Additional context

I run a prefect server instance with ~18k runs daily with Postgres database (AWS RDS).
The database was not locked and no other prefect server instance was connected to it during the migration.
I tried using `PREFECT_API_DATABASE_TIMEOUT` but it doesn't seem to be used in this context.

I see in recent  migrations rebuild idices for the events table :https://github.com/PrefectHQ/prefect/blob/d90d684c9e0773b41bf092ad7ef17e22dda08c77/src/prefect/server/database/_migrations/versions/postgresql/2025_04_04_092158_7a73514ca2d6_add_ix_events__event_related_occurred_.py

In my case the table contains ~700k records. After removing old events (~650k records) the migrations run smoothly.

Could you consider adding a timeout flag to the `prefect server database upgrade` command?",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17844/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17844
17827,`prefect config unset` not working properly,closed,completed,2025-04-15T23:18:41Z,2025-04-17T02:03:58Z,2025-04-17T02:03:57Z,5,['bug'],gahtan-syarif,,NONE,"### Bug summary

running `prefect config unset PREFECT_API_URL` still yields:
```
PREFECT_PROFILE='local'
PREFECT_API_URL='http://127.0.0.1:4200/api' (from profile)
``` 
when running `prefect config view`

### Version info

```Text
Version:             3.3.4
API version:         0.8.4
Python version:      3.12.9
Git commit:          7ca03553
Built:               Fri, Apr 11, 2025 12:27 AM
OS/Arch:             win32/AMD64
Profile:             ephemeral
Server type:         ephemeral
Pydantic version:    2.11.3
Server:
  Database:          sqlite
  SQLite version:    3.45.3
```

### Additional context

_No response_",gahtan-syarif,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17827/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17827
17823,Prefect Cloud Telemetry not compatible with Windows,closed,completed,2025-04-15T14:58:29Z,2025-04-15T15:16:20Z,2025-04-15T15:16:19Z,0,['bug'],jbw-vtl,,CONTRIBUTOR,"### Bug summary

Hi Team,

We are trying to interact with prefect cloud in the latest prefect version, however it seems to be crashing when trying to setup the opentelemetry exporters.
https://github.com/PrefectHQ/prefect/blob/main/src/prefect/telemetry/instrumentation.py#L77

```
>>> import prefect
>>> prefect.flow
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\jbw\Python\projects\prefect\feeds-prefect-poc\.venv\Lib\site-packages\prefect\__init__.py"", line 120, in __getattr__
    module = importlib.import_module(mname, package=package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\jbw\Python\uv\python_installs\cpython-3.11.11-windows-x86_64-none\Lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""<frozen importlib._bootstrap>"", line 1204, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 1176, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 1147, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 690, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 940, in exec_module
  File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
  File ""C:\Users\jbw\Python\projects\prefect\feeds-prefect-poc\.venv\Lib\site-packages\prefect\main.py"", line 51, in <module>
    prefect.telemetry.bootstrap.setup_telemetry()
  File ""C:\Users\jbw\Python\projects\prefect\feeds-prefect-poc\.venv\Lib\site-packages\prefect\telemetry\bootstrap.py"", line 49, in setup_telemetry
    return setup_exporters(settings.api.url, settings.api.key.get_secret_value())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\jbw\Python\projects\prefect\feeds-prefect-poc\.venv\Lib\site-packages\prefect\telemetry\instrumentation.py"", line 77, in setup_exporters
    ""service.instance.id"": os.uname().nodename,
                           ^^^^^^^^
AttributeError: module 'os' has no attribute 'uname'. Did you mean: 'name'?
```

Manually replacing the `os.uname().nodename` with something else, i.e. static `<missing>`, I am able to successfully run commands again, such as `prefect flow ls`

![Image](https://github.com/user-attachments/assets/2f138e07-52b9-4ab6-85e0-825877af80c6)

### Version info

```Text
Afraid can't even run the command properly, see screenshot

prefect==3.3.4
python==3.11.11
windows=11
```

### Additional context

![Image](https://github.com/user-attachments/assets/049b9453-f77b-4296-aaac-57c042145b36)

Any help is greatly appreciated",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17823/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17823
17822,Prefect suspend_flow_run failed,open,,2025-04-15T10:19:27Z,2025-04-15T10:19:27Z,,0,['bug'],HubWu42,,NONE,"### Bug summary

<img width=""1103"" alt=""Image"" src=""https://github.com/user-attachments/assets/ba4fd839-55ef-43a8-b962-83f67ea3784e"" />


After the 'flow' execution, the function is suspended. The 'flow' state changes, but the execution does not pause and continues. Subsequently, it displays that the 'flow' is not in a paused state.

### Version info

```Text
prefect v3.3.3
python v3.10
```

### Additional context

`from time import sleep
from prefect import get_client, suspend_flow_run
from prefect.deployments import run_deployment
from prefect.states import Suspended
import asyncio

flow_run_id = ""bc8e3580-634a-461e-b3ae-c32780622f4f""

def run_flow() -> str:
    try:
        flow_run = run_deployment(
            name=flow_run_id,
            timeout=10 
        )
        print(f""flow_run: {flow_run}"")
        return str(flow_run.id)
    except Exception as e:
        print(f""failed: {e}"")
        return """"

async def suspend_flow(flow_run_id: str) -> bool:
    try:
        result = await suspend_flow_run(flow_run_id=flow_run_id)
        print(f""result: {result}"")
        return True
    except Exception as e:
        print(f""suspend_failed: {e}"")
        return False

async def resume_flow(flow_run_id) -> bool:
    try:
        async with get_client() as client:
            result = await client.resume_flow_run(flow_run_id=flow_run_id)
            print(f""resume result: {result}"")
            return result
    except Exception as e:
        print(f""resume result: {e}"")
        return False


if __name__ == ""__main__"":
    new_run_id = run_flow()
    print(f""Flowï¼ŒRun ID: {new_run_id}"")

    # result = asyncio.run(resume_flow(""3c2cc53b-cbdd-4e0c-a8a8-5843a0d3272c""))


    if new_run_id:
        sleep(10)
        if asyncio.run(suspend_flow(new_run_id)):
            print(""success"")
            if asyncio.run(resume_flow(new_run_id)):
                print(""success"")`",,1,https://api.github.com/repos/PrefectHQ/prefect/issues/17822/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17822
17821,Prefect Docker Package not updated,closed,completed,2025-04-15T09:58:00Z,2025-04-15T14:17:50Z,2025-04-15T14:17:49Z,2,['bug'],jbw-vtl,,CONTRIBUTOR,"### Bug summary

HI Team,

We recently contributed to prefect docker, introducing the DOCKER_CLIENT_TIMEOUT to be passed to the underlying docker client.

This was merged into master, however it seems the prefect-docker package itself was not updated since november.

Unsure how the release process for the integrations works, any help is greatly appreviated

### Version info

```Text
this referes to the most recent prefect-docker version v0.6.2
```

### Additional context

https://pypi.org/project/prefect-docker/
![Image](https://github.com/user-attachments/assets/73bfbc61-9fed-40a1-b718-44622886f858)

It seems like all the  below changes have not made it into recent releases (unless i am missing something)

![Image](https://github.com/user-attachments/assets/804694f3-b68f-4d06-b0cd-9c6fc45f901a)


https://pypi.org/project/prefect-docker/",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17821/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17821
17820,space in path causes error when running deployment (Windows),closed,completed,2025-04-15T05:23:31Z,2025-04-17T14:27:06Z,2025-04-17T14:27:06Z,6,['bug'],gahtan-syarif,desertaxle,NONE,"### Bug summary

```python
from prefect import flow, task

@task
def append_timestamp():
    from datetime import datetime
    now = datetime.now().strftime(""%Y-%m-%d %H:%M:%S"")
    with open(""timestamps.txt"", ""a"") as f:
        f.write(now + ""\n"")
    print(f""Appended: {now}"")

@flow
def timestamp_logger_test():
    append_timestamp()


if __name__ == ""__main__"":
    timestamp_logger_test.from_source(
        source=r""C:/Users/Gahtan Syarif Nahdi/Desktop/prefect"",
        entrypoint=""prefect-test.py:timestamp_logger_test""
    ).deploy(
        name=""my-third-deployment"",
        work_pool_name=""my-work-pool""
    )
```
returns:
``` 
12:16:28.922 | INFO    | prefect.flow_runs.runner - Opening process...
'C:\Users\Gahtan' is not recognized as an internal or external command,
operable program or batch file.
12:16:29.035 | ERROR   | prefect.flow_runs.runner - Process for flow run 'portable-pigeon' exited with status code: 1
```

### Version info

```Text
Version:             3.3.4
API version:         0.8.4
Python version:      3.12.9
Git commit:          7ca03553
Built:               Fri, Apr 11, 2025 12:27 AM
OS/Arch:             win32/AMD64
Profile:             local
Server type:         server
Pydantic version:    2.11.3
```

### Additional context

_No response_",desertaxle,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17820/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17820
17818,Performance Issues with High Volume Flow Submission (150+ flows) - UI Delay and Resource Spikes,open,,2025-04-14T22:29:19Z,2025-04-15T20:28:41Z,,2,['bug'],yuqil-lookr-fyi,,NONE,"### Bug summary

**Description:**
We're evaluating Prefect for production use (Series A+ company) and encountered unexpected behavior during scale testing with 150+ simple ""hello world"" flows in a Minikube environment.

**Test Setup:**
Environment: Minikube (Mac M3, 36GB RAM)
**Prefect Config:**
Concurrency limited to 6 slots
Worker/agent pods: 0.5Gi request / 1Gi limit memory, 1 CPU
Enabled auto-scaling for both server and workers

**Test Scenario:**
Submitted 150+ hello world flows (say 1000 ""hello world"" by 10 tasks, each tasks say 100 times) simultaneously. Expected PostgreSQL to handle queuing with only 6 active runs
Expected Behavior:
- Immediate visibility of all 150 flow runs in UI (queued/running)
- PostgreSQL to manage queue state with minimal resource overhead
- Smoothly fit into the 6 concurrency slots (this works the lower number of flows)

**Observed Behavior:**

UI Delay: 3-5 minute gap before any runs appear in UI

Resource Spike:
- Initial low CPU/memory usage
- Sudden system freeze with: Docker reporting 2000% CPU (beyond theoretical 1100% max for 11 cores) Memory pressure leading to system unresponsiveness

**Key Questions:**

- Processing Delay: Why does the UI take 3-5 minutes to reflect submitted flows? Is this related to:
API queue processing?

- Resource Contention: Why queuing high number of flows (which should be disk-backed via PostgreSQL) cause such severe memory/CPU spikes? (I also tried 10 - 150 flows, they cpu and memory utilization is similar, which is expected due to limited concurrency slot)

### Version info

```Text
Version:             3.3.3
API version:         0.8.4
Python version:      3.9.6
Git commit:          4100d4ea
Built:               Sat, Apr 05, 2025 01:44 AM
OS/Arch:             darwin/arm64
Profile:             ephemeral
Server type:         server
Pydantic version:    2.11.2
Integrations:
  prefect-dask:      0.3.4
  prefect-docker:    0.6.2
  prefect-kubernetes: 0.5.9
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17818/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17818
17817,prefect deployment run --watch and events stream not showing all logs or events,closed,completed,2025-04-14T22:16:41Z,2025-04-15T20:25:42Z,2025-04-15T20:25:42Z,4,"['bug', 'cloud']",rcash,,CONTRIBUTOR,"### Bug summary

Running a flow with `prefect deployment run --watch` seems to hang and not display all events for a given flow- e.g. the last log displayed will be that of the flow is in state 'Pending' or 'Running', then will not poll or display anything more well past the flow run completing successfully (verified via the UI or worker logs).

Similar behavior is seen with `prefect events stream` - nothing emitted after ""Subscribing to event stream..."" even with flows being scheduled + running or additional things being shown in the Events UI on Cloud.

Steps to reproduce:
1. Deploy flow then run with `prefect deployment run --watch` or `prefect events stream` -- observe difference in what is reported in UI to CLI process

### Version info

```Text
Version:             3.3.3
API version:         0.8.4
Python version:      3.12.9
Git commit:          4100d4ea
Built:               Sat, Apr 05, 2025 01:44 AM
OS/Arch:             darwin/arm64
Profile:             sbx-rowdy-cloud
Server type:         cloud
Pydantic version:    2.11.2
Integrations:
  prefect-gcp:       0.6.5
  prefect-databricks: 0.3.0
  prefect-github:    0.3.1
```

### Additional context

screenshot of CLI (to show I had to kill the command):

![Image](https://github.com/user-attachments/assets/47f38afa-a088-4b52-88a5-a6492e5abdbd)

screenshot of UI:

![Image](https://github.com/user-attachments/assets/770436db-ac9e-4dd2-a06e-c397f963c469)

tried passing in the `--watch-interval` flag to no effect as well (also warned `poll_interval` was deprecated + would be removed in the future)
",rcash,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17817/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17817
17816,Unable to deploy flows when importing a large Python file,closed,not_planned,2025-04-14T19:33:20Z,2025-04-14T23:34:10Z,2025-04-14T23:33:18Z,3,['bug'],brokenthumbs,,NONE,"### Bug summary

I am attempting to deploy a Prefect flow using `prefect deploy`. 
This flow contains an import on a Python file that contains 5000 lines and about 100 classes.
This flow deploys successfully with Prefect 2.x, and Prefect 3.1.13.

With Prefect 3.2.14 an Prefect 3.3.3, `prefect deploy` does not finish when attempting to deploy this same flow.
When I reduced the file to 500 lines and 10 classes, Prefect 3.3.3 `prefect deploy` does successfully deploy the flow.

What behavior changed between Prefect 3.1.13 and Prefect 3.2.14 that would remove my ability to deploy my flow that imports the large Python file?


### Version info

```Text
Version:             3.3.3
API version:         0.8.4
Python version:      3.11.11
Git commit:          4100d4ea
Built:               Sat, Apr 05, 2025 01:44 AM
OS/Arch:             linux/x86_64
Profile:             ephemeral
Server type:         ephemeral
Pydantic version:    2.11.3
Server:
  Database:          sqlite
  SQLite version:    3.40.1
Integrations:
  prefect-slack:     0.3.1
  prefect-gcp:       0.5.11
```

### Additional context

- I noticed that this bug report was fixed in 3.1.13, and I can confirm that I am able to deploy my flow successfully with 3.1.13. https://github.com/PrefectHQ/prefect/issues/15621
- However, that same flow is unable to be deployed in 3.2.14 and 3.3.3. 
- Is there some feature or functionality that I am unaware of that would cause newer versions of Prefect to be unable to deploy this specific flow?",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17816/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17816
17814,Add a --dry-run switch or equivalent to prefect deploy,open,,2025-04-14T18:57:46Z,2025-05-07T17:22:00Z,,2,['enhancement'],tjordahl,,NONE,"### Describe the current behavior

My continuous integration/deployment fails when there is a problem in the prefect.yaml file and I would like something to be able to validate all the entries so this can be done before the changes are merged and attempted to be deployed. 

The current `prefect deploy --all` will deploy all flows up until it encounters an error, then stop.  This leaves my Depoyments in a state of half new, half old deployments.




### Describe the proposed behavior

In addition to validating the YAML schema for `prefect.yaml`, this should catch items such as:
- Invalid parameter values
- Incorrect endpoint specifications (missing file/function)
- Other validation

In short, everything but the `POST /deployment` operation.  A `--dry-run` switch to `prefect deploy` would be ideal

### Example Use

```bash
prefect deploy --all --dry-run
```


### Additional context

Slack thread: https://prefect-community.slack.com/archives/CL09KU1K7/p1744654952403849
Relevant issue: https://github.com/PrefectHQ/prefect/issues/16996",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17814/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17814
17813,Built-in blocks are unavailable for creation with UI and CLI,closed,not_planned,2025-04-14T10:16:04Z,2025-04-16T15:37:16Z,2025-04-16T15:37:15Z,4,['bug'],dinya,,NONE,"### Bug summary

Hello team,


Built-in (default) block list (http://127.0.0.1:4200/blocks/catalog) is empty for a new installation:

<img width=""500"" alt=""Image"" src=""https://github.com/user-attachments/assets/b5fe8bfc-a4a7-4311-bb6b-7c0e86942c57"" />

and 

```bash
$ prefect block types ls
                       Block Types
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Block Type Slug â”ƒ Description â”ƒ Generate creation link â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

But it looks like it should look like this https://docs.prefect.io/v3/develop/blocks#built-in-blocks

Bu if I call the following examples:


```python

from prefect.blocks.core import Block

class Cube(Block):
    edge_length_inches: float

Cube(edge_length_inches=2.25).save(""rubiks-cube"")

from prefect.blocks.system import Secret

Secret(value=""sk-1234567890"").save(""test-secret"", overwrite=True)
```

... ``Cube`` and ``Secret`` blocks are appeared at http://127.0.0.1:4200/blocks/catalog (and are available to create with UI)

<img width=""500"" alt=""Image"" src=""https://github.com/user-attachments/assets/f992fe67-8d79-439d-b7a6-04cc0d328e32"" />

and are listable with CLI:

```bash
$ prefect block types ls
                                       Block Types
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Block Type Slug â”ƒ Description                            â”ƒ Generate creation link      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ cube            â”‚                                        â”‚ prefect block create cube   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ secret          â”‚ A block that represents a secret value â”‚ prefect block create secret â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

But other built-in blocks are still unavailable for creation:

```bash
$ prefect block create smb
Block type 'smb' not found!
Available block types: secret, cube
```

### Version info

```Text
Version:             3.3.4
API version:         0.8.4
Python version:      3.12.9
Git commit:          7ca03553
Built:               Fri, Apr 11, 2025 12:27 AM
OS/Arch:             win32/AMD64
Profile:             local
Server type:         server
Pydantic version:    2.10.6
Integrations:
  prefect-dask:      0.3.2
  prefect-docker:    0.6.2
```

### Additional context

_No response_",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17813/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17813
17804,It's not possible to set the working directory of a Docker workpool without using pulls steps,open,,2025-04-11T07:50:16Z,2025-04-14T03:23:22Z,,1,['bug'],NicholasPini,,NONE,"### Bug summary

I'm using a Docker workpool, and I want to be able to deploy flows using the CLI commands. The problem is that I cannot do that, because Prefect automatically adds a `set_working_directory` pull step to the flow which sets the directory to the current working directory *on my local machine*, which obviously does not exist in the Docker container.

The only way to override this behavior is to set the `set_working_directory` pull step, but this is only possible in the YAML file, and it is not supported when deploying using Python scripts or CLI commands. Also, Docker workpools do not appear to have a `working_dir` job variable.

Am I missing something, or am I just forced to use a prefect.yaml file to deploy my flows? Note that I do not build Docker images using Prefect's build steps, so I would use the prefect.yaml file just to be able to set the working directory, which is a bit annoying.

### Version info

```Text
Version:             3.3.2
API version:         0.8.4
Python version:      3.10.16
Git commit:          e49e3185
Built:               Thu, Apr 03, 2025 09:25 PM
OS/Arch:             darwin/arm64
Profile:             planetek
Server type:         server
Pydantic version:    2.11.2
Integrations:
  prefect-docker:    0.6.2
  prefect-aws:       0.5.9
  prefect-shell:     0.3.1
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17804/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17804
17803,Add global concurrency limit to the deployment update route,closed,completed,2025-04-10T22:10:55Z,2025-04-23T13:59:40Z,2025-04-23T13:59:40Z,0,['enhancement'],cbelsole,,CONTRIBUTOR,"### Describe the current behavior

Currently, [when you create a deployment you can set a global_concurrency_limit](https://docs.prefect.io/v3/api-ref/rest-api/server/deployments/create-deployment#response-global-concurrency-limit). If you an existing deployment that setting does not exist [on the update call](https://docs.prefect.io/v3/api-ref/rest-api/server/deployments/update-deployment).

### Describe the proposed behavior

The update call should have an option to add a global_concurrency_limit so we don't have to create a new deployment in order to set a limit.

### Example Use

_No response_

### Additional context

_No response_",desertaxle,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17803/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17803
17799,secret exposed in GithubCredentials block updated event page in UI,closed,completed,2025-04-10T18:13:53Z,2025-04-16T17:43:21Z,2025-04-16T17:43:21Z,1,"['bug', 'cloud']",rcash,zangell44,CONTRIBUTOR,"### Bug summary

Personal access tokens for Github Credentials blocks appear to be exposed in the UI in the ""Raw"" section of the ""Block document updated"" page. The value seems to be obfuscated for the created event, but not for the updated event.

Steps to reproduce:
1. Create a new Github Credentials block then edit it + save (or find an existing GIthub Credentials block)
2. Navigate to the Events page for the workspace and filter by the block name
3. Click on the ""Block document updated"" event then the ""Raw"" tab - see the value exposed in payload/data/token

### Version info

```Text
Version:             3.3.3
API version:         0.8.4
Python version:      3.12.9
Git commit:          4100d4ea
Built:               Sat, Apr 05, 2025 01:44 AM
OS/Arch:             darwin/arm64
Profile:             sbx-rowdy-cloud
Server type:         cloud
Pydantic version:    2.11.2
Integrations:
  prefect-gcp:       0.6.5
  prefect-databricks: 0.3.0
  prefect-github:    0.3.1
```

### Additional context

screenshot of the value exposed for a fake credentials block update + it being hidden in the created event

![Image](https://github.com/user-attachments/assets/916b7c7f-93b0-42b9-8c5d-12452ebc5c48)

![Image](https://github.com/user-attachments/assets/7b2de4fe-567e-4e93-bfa6-3b2da645797e)

let me know if there's any other version info I can provide pertaining to the UI",zangell44,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17799/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17799
17798,JSON input in UI corrupts parameters,closed,completed,2025-04-10T09:15:29Z,2025-05-06T14:16:27Z,2025-05-06T14:15:29Z,2,['bug'],j-tr,znicholasbrown,CONTRIBUTOR,"### Bug summary

Switching dict parameters to JSON parameter inputs view serializes the value and adds a ""__prefect_kind"": ""json"" field.

This means the structure of the parameters that arrive at the flow run upon execution is different depending on whether the flow was started with the form or json view. When using pydantic models, this results in a validation error when submitting flows from the json view.

```
from prefect import flow

@flow
def main(
    my_param: dict[str, str] = {
        ""foo"": ""bar"",
    },
):
    print(f""Hello! {my_param}"")

if __name__ == ""__main__"":
    main.serve(name=""mre"")
```

Form view
![Image](https://github.com/user-attachments/assets/91a1329a-581f-4fa5-a534-5bfea80d5fdd)

Output: `Hello! {'foo': 'bar'}`

Json view
![Image](https://github.com/user-attachments/assets/94c0e3da-0706-41e2-91e6-c0eb428bfb83)
Output: `Hello! {'value': '{\n  ""foo"": ""bar""\n}', '__prefect_kind': 'json'}`

### Version info

```Text
Version:             3.3.3
API version:         0.8.4
Python version:      3.12.9
Git commit:          4100d4ea
Built:               Sat, Apr 05, 2025 01:44 AM
OS/Arch:             linux/x86_64
Server type:         cloud
Pydantic version:    2.11.3
```

### Additional context

possibly related to https://github.com/PrefectHQ/prefect/issues/17782",znicholasbrown,2,https://api.github.com/repos/PrefectHQ/prefect/issues/17798/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17798
17792,Unable to cancel flow with concurrent nested subflows - TypeError when cancelling flow - 'Process' object cannot be interpreted as an intege,closed,duplicate,2025-04-09T17:56:31Z,2025-04-09T17:59:32Z,2025-04-09T17:59:30Z,1,['bug'],StefanIgnjatovic12,,NONE,"# TypeError: 'Process' object cannot be interpreted as an integer when cancelling Prefect flow

## Bug summary
When attempting to cancel a flow run via the Prefect UI, the cancellation fails with the following error:
```
prefect.flow_runs.runner - Encountered exception while killing process for flow run '01e68940-8616-425b-93c4-ba53722a2c2b'. Flow run may not be cancelled.
Traceback (most recent call last):
  File ""E:\python\my_app\venv\Lib\site-packages\prefect\runner\runner.py"", 
line 1095, in _cancel_run
    await self._kill_process(pid)
  File ""E:\python\my_app\venv\Lib\site-packages\prefect\runner\runner.py"", 
line 906, in _kill_process
    os.kill(pid, signal.CTRL_BREAK_EVENT)
TypeError: 'Process' object cannot be interpreted as an integer
```

The error seems to be happening because Prefect is trying to kill a process using `os.kill()`, but it's passing a `Process` object directly instead of extracting the process ID (integer) from it.

The flow then remains in the cancelling state indefinitely. 

## Reproduction steps
1. Create an asynchronous Prefect flow with nested subflows
2. Run the main flow which attempts to run multiple subflows with semaphore 
3. Attempt to cancel the main flow run through the Prefect UI while it's running

## Minimal Reproducible Example
I was unable to create a minimal example due to the complexity of my workflows, but the issue appears to be in Prefect's internal process handling when cancelling flows on Windows.

Here's a simplified version of my flow setup that triggers the issue:

```python
from prefect import flow, get_run_logger
import asyncio
from datetime import datetime

@flow(name=""Subflow"")
async def subflow():
    """"""A simple subflow that sleeps.""""""
    logger = get_run_logger()
    logger.info(""Starting subflow"")
    await asyncio.sleep(60)  # Long enough to attempt cancellation
    logger.info(""Finishing subflow"")

@flow(name=""Main Flow"", flow_run_name=f""MainFlow-{datetime.now().strftime('%Y%m%d-%H%M%S')}"")
async def main_flow(total_runs: int = 2, max_concurrent: int = 2):
    """"""Run multiple subflows concurrently.""""""
    logger = get_run_logger()
    logger.info(f""Starting {total_runs} subflows with max concurrency {max_concurrent}"")
    
    # Create a semaphore to limit concurrency
    semaphore = asyncio.Semaphore(max_concurrent)
    
    # Helper to run one subflow with semaphore
    async def run_with_semaphore(i: int):
        async with semaphore:
            logger.info(f""Starting subflow {i}"")
            try:
                await subflow()
            except Exception as e:
                logger.error(f""Subflow {i} error: {e}"")
    
    # Create tasks for all runs
    tasks = [asyncio.create_task(run_with_semaphore(i)) for i in range(total_runs)]
    
    # Wait for all tasks
    await asyncio.gather(*tasks, return_exceptions=True)

if __name__ == ""__main__"":
    main_flow.serve(
        name=""cancellation-test"",
        parameters={""total_runs"": 2, ""max_concurrent"": 2}
    )
```




### Version info

```Text
Version:             3.3.3
API version:         0.8.4
Python version:      3.11.9
Git commit:          4100d4ea
Built:               Sat, Apr 05, 2025 01:44 AM
OS/Arch:             win32/AMD64
Profile:             default
Server type:         server
Pydantic version:    2.11.2
```

### Additional context

_No response_",desertaxle,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17792/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17792
17789,Add support for inline embedded images in `email_send_message` function,closed,completed,2025-04-09T16:58:34Z,2025-04-09T17:39:44Z,2025-04-09T17:39:43Z,1,['enhancement'],zzstoatzz,,COLLABORATOR,"related to https://github.com/PrefectHQ/prefect/discussions/17788



### Current Behavior
The `email_send_message` function in `prefect-email` currently only supports sending images as attachments using the `attachments` parameter, which adds files with `Content-Disposition: attachment`.



### Proposed Enhancement
Extend the function to support embedding images inline within HTML email content using the `Content-ID` mechanism and MIME multipart/related structure.


1. Add a new parameter to `email_send_message`: 
   ```python
   inline_images: Optional[dict[str, str]] = None
where keys are content IDs and values are file paths

For each inline image:

Read the image file and create a MIMEImage part
Set the Content-ID header with the specified ID
Add the part to the message with proper MIME structure


The implementation would look something like:

```python
from email.mime.image import MIMEImage

# Add after handling attachments
for cid, filepath in (inline_images or {}).items():
    with open(filepath, ""rb"") as img_file:
        img = MIMEImage(img_file.read())
        img.add_header('Content-ID', f'<{cid}>')
        img.add_header('Content-Disposition', 'inline')
        message.attach(img)
```

### Example Use

```python
email_send_message(
    email_server_credentials=credentials,
    subject=""Report with Chart"",
    msg=""""""
    <html>
      <body>
        <p>Here's the monthly chart:</p>
        <img src=""cid:chart1"">
      </body>
    </html>
    """""",
    email_to=""recipient@example.com"",
    inline_images={""chart1"": ""/path/to/chart.png""}
)
```

### Additional context

This should be possible using only the stdlib `email` library we're already using",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17789/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17789
17787,Adding Inline images in Prefect Email,closed,completed,2025-04-09T16:24:39Z,2025-04-09T16:37:33Z,2025-04-09T16:37:33Z,0,['enhancement'],lavishkhandelwal,,CONTRIBUTOR,"### Describe the current behavior

Currently, there is no option to embed the image directly in the email body; the only available method is to send it as an attachment.

### Describe the proposed behavior

I want the ability to embed images directly within the body of the email, allowing recipients to view the image inline without needing to open it as an attachment. This would enhance the visual presentation and improve the overall user experience.

### Example Use

_No response_

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17787/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17787
17785,`ValueError: No lock held by` for tasks running in the same Thread with `SERIALIZABLE` cache isolation,closed,completed,2025-04-09T12:19:55Z,2025-04-14T22:33:08Z,2025-04-14T22:32:02Z,2,['bug'],mpolonioli,,NONE,"### Bug summary

Hello, I would like to introduce cache isolation at `SERIALIZABLE` level in my project but when trying to do so I faced an issue that I was able to reproduce in the following code snippet:
```python
import asyncio
import random

from prefect import task
from prefect.cache_policies import INPUTS, TASK_SOURCE

from prefect.locking.memory import MemoryLockManager
from prefect.transactions import IsolationLevel

cache_policy = (INPUTS + TASK_SOURCE).configure(
    isolation_level=IsolationLevel.SERIALIZABLE,
    lock_manager=MemoryLockManager(),
)

@task(cache_policy=cache_policy)
async def my_task(x: int):
    await asyncio.sleep(random.randint(1, 3))
    result = x + random.randint(1, 100)
    print (f""Task result: {result}"")
    return result

async def main():
    tasks = [my_task(42) for _ in range(3)]
    results = await asyncio.gather(*tasks)
    print(f""All task results: {results}"")

if __name__ == ""__main__"":
    asyncio.run(main())
```
When running the code above all the tasks acquire the lock and runs concurrently producing different results even if they uses the same cache key and when two of them try to release the lock the error `ValueError: No lock held by...` is logged. Below the complete console log:
```console
Task result: 80
13:55:59.633 | INFO    | Task run 'my_task' - Finished in state Completed()
Task result: 103
13:56:01.631 | ERROR   | Task run 'my_task' - An error was encountered while committing transaction '922f24a6e44d5c6d3e1bc2b4cc0ef084'
Traceback (most recent call last):
  File ""<project_root>/.venv/lib/python3.12/site-packages/prefect/transactions.py"", line 338, in commit
    self.store.release_lock(self.key)
  File ""<project_root>/.venv/lib/python3.12/site-packages/prefect/results.py"", line 775, in release_lock
    return self.lock_manager.release_lock(key, holder)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""<project_root>/.venv/lib/python3.12/site-packages/prefect/locking/memory.py"", line 178, in release_lock
    raise ValueError(
ValueError: No lock held by Mac.local:41014:8727021632:MainThread for transaction with key 922f24a6e44d5c6d3e1bc2b4cc0ef084
13:56:01.638 | INFO    | Task run 'my_task' - Finished in state Completed()
13:56:01.643 | ERROR   | Task run 'my_task' - An error was encountered while committing transaction '922f24a6e44d5c6d3e1bc2b4cc0ef084'
Traceback (most recent call last):
  File ""<project_root>/.venv/lib/python3.12/site-packages/prefect/transactions.py"", line 338, in commit
    self.store.release_lock(self.key)
  File ""<project_root>/.venv/lib/python3.12/site-packages/prefect/results.py"", line 775, in release_lock
    return self.lock_manager.release_lock(key, holder)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""<project_root>/.venv/lib/python3.12/site-packages/prefect/locking/memory.py"", line 178, in release_lock
    raise ValueError(
ValueError: No lock held by Mac.local:41014:8727021632:MainThread for transaction with key 922f24a6e44d5c6d3e1bc2b4cc0ef084
13:56:01.644 | INFO    | Task run 'my_task' - Finished in state Completed()
Task result: 66
All task results: [103, 80, 66]

Process finished with exit code 0
```
I noticed that the documentation about [cache isolation](https://docs.prefect.io/v3/develop/task-caching#cache-isolation) uses `threading` in the example provided but it does not mention it is a requirement when using `SERIALIZABLE` level.
Is it actually a requirement to run tasks that uses the same cache key in different `Threads`?.

If it is a requirement would it be ok to run some tasks in separate threads and other in the main thread using `asyncio.to_thread` like in the example below?
```python
import asyncio
import random

from prefect import task
from prefect.cache_policies import INPUTS, TASK_SOURCE

from prefect.locking.memory import MemoryLockManager
from prefect.transactions import IsolationLevel

cache_policy = (INPUTS + TASK_SOURCE).configure(
    isolation_level=IsolationLevel.SERIALIZABLE,
    lock_manager=MemoryLockManager(),
)

@task(cache_policy=cache_policy)
async def my_task(x: int):
    await asyncio.sleep(random.randint(1, 3))
    result = x + random.randint(1, 100)
    print (f""Task result: {result}"")
    return result

async def main():
    tasks = []
    tasks.extend([my_task(i) for i in range(3)])
    tasks.extend([asyncio.to_thread(asyncio.run, my_task(42)) for _ in range(3)])
    results = await asyncio.gather(*tasks)
    print(f""All task results: {results}"")

if __name__ == ""__main__"":
    asyncio.run(main())
```

Thanks in advance!

### Version info

```Text
Version:             3.0.11
API version:         0.8.4
Python version:      3.12.6
Git commit:          a17ccfcf
Built:               Thu, Oct 24, 2024 5:36 PM
OS/Arch:             darwin/arm64
Profile:             dev-local
Server type:         server
Pydantic version:    2.9.2
Integrations:
  prefect-docker:    0.6.2
```

### Additional context

_No response_",zzstoatzz,1,https://api.github.com/repos/PrefectHQ/prefect/issues/17785/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17785
17784,Prefect integrations support for Python3.13,closed,completed,2025-04-09T11:12:06Z,2025-04-09T18:52:00Z,2025-04-09T18:49:38Z,3,['enhancement'],lazargugleta,,NONE,"### Describe the current behavior

Hello,
Would it be possible to add support for prefect integrations like prefect-docker and prefect-bitbucket since Prefect supports python3.13 without pendulum dependency?

### Describe the proposed behavior

Remove the pendulum as a dependency and increase Pyhon version range to include 3.13.

### Example Use

_No response_

### Additional context

_No response_",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17784/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17784
17782,"[Bug] Prefect UI Schedule Parameter Override Corrupts Parameters,but  API Works Correctly",closed,completed,2025-04-09T03:48:30Z,2025-05-06T14:15:56Z,2025-05-06T14:15:28Z,2,['bug'],zyn71,znicholasbrown,NONE,"### Bug summary

**Describe the bug**

Configuring parameter overrides for a Schedule via the Prefect UI results in corrupted parameters being passed to the flow run. Specifically, the target parameter field (e.g., `dataset_ids`) is incorrectly replaced with the *entire* flow parameter set, serialized as a JSON string within a `{""value"": ""..."", ""__prefect_kind"": ""json""}` structure which will cause flow run error.

Crucially, configuring the same parameter override directly via the Prefect API (e.g., using `httpx` or the Python client) works as expected.

**To Reproduce**

1.  Define a flow with parameters (e.g., `dataset_ids: List[int]`).
2.  Create a Deployment for the flow.
3.  **Using the Prefect UI**: Create a Schedule for the deployment and configure it to override the `dataset_ids` parameter (e.g., set value to `[35]`).
4.  Trigger the schedule or wait for it to run.
5.  Observe the flow run logs: The `dataset_ids` parameter received by the flow is the corrupted JSON structure containing the full parameter set, not `[35]`. This often leads to `TypeError: unhashable type: 'dict'`.

**Expected behavior**

When using the UI to override `dataset_ids` to `[35]`, the flow run should receive `dataset_ids=[35]`, consistent with the behavior when using the API.

**Actual behavior (UI only)**

The flow run receives `dataset_ids` as `{""value"": ""{ ""dataset_ids"": [1, 2]}"", ""__prefect_kind"": ""json""}` (example structure).


### Version info

```Text
Version:             3.2.7
API version:         0.8.4
Python version:      3.10.12
Git commit:          d4d9001e
Built:               Fri, Feb 21, 2025 7:39 PM
OS/Arch:             linux/x86_64
Profile:             ephemeral
Server type:         ephemeral
Pydantic version:    2.10.6
Server:
  Database:          sqlite
  SQLite version:    3.37.2
Integrations:
  prefect-docker:    0.6.2
  prefect-kubernetes: 0.5.3
  prefect-gitlab:    0.3.1
```

### Additional context

_No response_",znicholasbrown,1,https://api.github.com/repos/PrefectHQ/prefect/issues/17782/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17782
17780,An error occurred (ThrottlingException) when calling the GetLogEvents operation,open,,2025-04-08T19:35:06Z,2025-04-11T20:15:35Z,,9,['bug'],cbelsole,,CONTRIBUTOR,"### Bug summary

We are receiving this error when using the ECS worker type at high load:

```
botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the GetLogEvents operation (reached max retries: 4): Rate exceeded
```

<img width=""1246"" alt=""Image"" src=""https://github.com/user-attachments/assets/79dffd05-2e72-4327-8a25-5fad842e2eac"" />

This quota is not adjustable by customer support.

### Version info

```Text
This is mostly true. On AWS 

Version:             3.3.1
API version:         0.8.4
Python version:      3.12.9
Git commit:          6a164620
Built:               Tue, Apr 01, 2025 2:39 AM
OS/Arch:             linux/arm64 
Profile:             ephemeral
Server type:         server
Pydantic version:    2.9.2
Integrations:
  prefect-docker:    0.6.2
  prefect-aws:       0.5.5
```

### Additional context

Raw stacktrace:
```
18:41:03.374 | ERROR   | prefect.flow_runs.worker - Failed to read log events with request {'logGroupName': '/ecs/p-doc-processing-prefect-flow', 'logStreamName': 'ecs/doc-processing-prefect-flow/7984252a2e2941abbf3e43cdf60fba9d', 'startTime': 1744137627781}
Traceback (most recent call last):
  File ""/usr/local/lib/python3.12/site-packages/prefect_aws/workers/ecs_worker.py"", line 1222, in _stream_available_logs
    response = logs_client.get_log_events(**request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/botocore/client.py"", line 570, in _api_call
    return self._make_api_call(operation_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/botocore/context.py"", line 124, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/botocore/client.py"", line 1031, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the GetLogEvents operation (reached max retries: 4): Rate exceeded
```",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17780/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17780
17776,Can't upload logs from task runner setup,open,,2025-04-08T17:39:33Z,2025-04-08T17:39:48Z,,0,['enhancement'],bnaul,,CONTRIBUTOR,"### Describe the current behavior

Currently the task runner gets initialized before we enter the flow run context. This means that if we're for example creating a Dask cluster, any logs about how the cluster was created (or fails to get created) do not get associated with the flow run and can't be viewed in the UI.

### Describe the proposed behavior

It seems like a little tweak to the ordering [here](https://github.com/PrefectHQ/prefect/blob/main/src/prefect/flow_engine.py#L600-L616) would be sufficient: as long as we call `task_runner.__enter__` after `FlowRunContext.__enter__`, any logs/events would propagated as expected which would make debugging Dask (and I assume Ray) cluster issues much simpler.

### Example Use

_No response_

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17776/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17776
17772,Flow run wait_for isn't waiting for all dependent task runs to finish,open,,2025-04-08T15:28:33Z,2025-04-16T17:23:12Z,,4,"['bug', 'needs:mre']",TNeece,,NONE,"### Bug summary

```
@flow(name='API Load',
      log_prints=True)
def load_autoims_data():
    new_changes_since = datetime.now().strftime('%d%m%Y%H%M%S')
    
    changes_since = String.load('changes-since')
    changes_since = changes_since.value

    token = (b64encode((username + ':' + password).encode('ascii'))).decode('ascii')

    conn = connect_to_snowflake()

    condition_report = prep_condition_report.submit(conn, token, changes_since)
    inventory = prep_inventory.submit(conn, token, changes_since)
    sold = prep_sold.submit(conn, token, changes_since)
    notes = prep_notes.submit(conn, token, changes_since)

    new_changes_since = String(value=new_changes_since)
    new_changes_since.save(name='autoims-changes-since', overwrite=True)

    run_dbt = run_dbt_job.submit(wait_for=[condition_report, inventory, sold, notes]).result()
```

Submitting at recommendation of Rob Freedy from prefect. We have flows intermittently failing. He dug into logs internally and came to this conclusion.

For all of these flow runs, it seems like the wait_for isn't waiting for all of the dependent task runs to finish but is trying to start the run_dbt_job and that is why these flow runs are failing.

### Version info

```Text
PS C:\GitRepo\prefect-business-intelligence> prefect version
Traceback (most recent call last):
  File ""C:\Users\<user>\AppData\Local\Programs\Python\Python39\lib\site-packages\prefect\cli\_utilities.py"", line 44, in wrapper
    return fn(*args, **kwargs)
  File ""C:\Users\<user>\AppData\Local\Programs\Python\Python39\lib\site-packages\prefect\cli\_types.py"", line 156, in sync_fn
    return asyncio.run(async_fn(*args, **kwargs))
  File ""C:\Users\<user>\AppData\Local\Programs\Python\Python39\lib\asyncio\runners.py"", line 44, in run
    return loop.run_until_complete(main)
  File ""C:\Users\<user>\AppData\Local\Programs\Python\Python39\lib\asyncio\base_events.py"", line 642, in run_until_complete
    return future.result()
  File ""C:\Users\<user>\AppData\Local\Programs\Python\Python39\lib\site-packages\prefect\cli\root.py"", line 115, in version
    ""Built"": parse_datetime(prefect.__version_info__[""date""]).strftime(
ValueError: Invalid format string

But we are on prefect 3.3.1
```

### Additional context

_No response_",,1,https://api.github.com/repos/PrefectHQ/prefect/issues/17772/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17772
17767,Prefect server experiencing deadlocks with Postgres database,open,,2025-04-08T09:42:51Z,2025-05-13T12:48:31Z,,5,['bug'],ashrielbrian,,NONE,"### Bug summary

We deploy Prefect server using helm (`2024.6.24152434`) into EKS, with RDS Postgres 14.13 as the backing database.

Lately, we've been experiencing frequent deadlocks after upgrading to Prefect 3.3.1. 

```
09:14:35.587 | ERROR   | prefect.server.utilities.messaging.memory - Failed in consume_loop
Traceback (most recent call last):
  File ""/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py"", line 545, in _prepare_and_execute
    self._rows = deque(await prepared_stmt.fetch(*parameters))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/asyncpg/prepared_stmt.py"", line 176, in fetch
    data = await self.__bind_execute(args, 0, timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/asyncpg/prepared_stmt.py"", line 267, in __bind_execute
    data, status, _ = await self.__do_execute(
                      ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/asyncpg/prepared_stmt.py"", line 256, in __do_execute
    return await executor(protocol)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""asyncpg/protocol/protocol.pyx"", line 206, in bind_execute
asyncpg.exceptions.DeadlockDetectedError: deadlock detected
DETAIL:  Process 6676 waits for ShareLock on transaction 47526832; blocked by process 6679.
Process 6679 waits for ShareLock on speculative token 1 of transaction 47526833; blocked by process 6676.
HINT:  See server log for query details.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py"", line 1964, in _exec_single_context
    self.dialect.do_execute(
  File ""/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/default.py"", line 945, in do_execute
    cursor.execute(statement, parameters)
  File ""/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py"", line 580, in execute
    self._adapt_connection.await_(
  File ""/usr/local/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py"", line 132, in await_only
    return current.parent.switch(awaitable)  # type: ignore[no-any-return,attr-defined] # noqa: E501
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py"", line 196, in greenlet_spawn
    value = await result
            ^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py"", line 558, in _prepare_and_execute
    self._handle_exception(error)
  File ""/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py"", line 508, in _handle_exception
    self._adapt_connection._handle_exception(error)
  File ""/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py"", line 792, in _handle_exception
    raise translated_error from error
sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_dbapi.Error: <class 'asyncpg.exceptions.DeadlockDetectedError'>: deadlock detected
DETAIL:  Process 6676 waits for ShareLock on transaction 47526832; blocked by process 6679.
Process 6679 waits for ShareLock on speculative token 1 of transaction 47526833; blocked by process 6676.
HINT:  See server log for query details.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/usr/local/lib/python3.12/site-packages/prefect/server/utilities/messaging/memory.py"", line 356, in _consume_loop
    await handler(message)
  File ""/usr/local/lib/python3.12/site-packages/prefect/server/services/task_run_recorder.py"", line 210, in message_handler
    await record_task_run_event(event)
  File ""/usr/local/lib/python3.12/site-packages/prefect/server/services/task_run_recorder.py"", line 169, in record_task_run_event
    await _insert_task_run(session, task_run, task_run_attributes)
  File ""/usr/local/lib/python3.12/site-packages/prefect/server/services/task_run_recorder.py"", line 54, in _insert_task_run
    await session.execute(
  File ""/usr/local/lib/python3.12/site-packages/sqlalchemy/ext/asyncio/session.py"", line 463, in execute
    result = await greenlet_spawn(
             ^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py"", line 201, in greenlet_spawn
    result = context.throw(*sys.exc_info())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py"", line 2365, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/session.py"", line 2251, in _execute_internal
    result: Result[Any] = compile_state_cls.orm_execute_statement(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/sqlalchemy/orm/bulk_persistence.py"", line 1294, in orm_execute_statement
    result = conn.execute(
             ^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py"", line 1416, in execute
    return meth(
           ^^^^^
  File ""/usr/local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py"", line 523, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py"", line 1638, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py"", line 1843, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py"", line 1983, in _exec_single_context
    self._handle_dbapi_exception(
  File ""/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py"", line 2352, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File ""/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/base.py"", line 1964, in _exec_single_context
    self.dialect.do_execute(
  File ""/usr/local/lib/python3.12/site-packages/sqlalchemy/engine/default.py"", line 945, in do_execute
    cursor.execute(statement, parameters)
  File ""/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py"", line 580, in execute
    self._adapt_connection.await_(
  File ""/usr/local/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py"", line 132, in await_only
    return current.parent.switch(awaitable)  # type: ignore[no-any-return,attr-defined] # noqa: E501
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py"", line 196, in greenlet_spawn
    value = await result
            ^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py"", line 558, in _prepare_and_execute
    self._handle_exception(error)
  File ""/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py"", line 508, in _handle_exception
    self._adapt_connection._handle_exception(error)
  File ""/usr/local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py"", line 792, in _handle_exception
    raise translated_error from error
sqlalchemy.exc.DBAPIError: (sqlalchemy.dialects.postgresql.asyncpg.Error) <class 'asyncpg.exceptions.DeadlockDetectedError'>: deadlock detected
DETAIL:  Process 6676 waits for ShareLock on transaction 47526832; blocked by process 6679.
Process 6679 waits for ShareLock on speculative token 1 of transaction 47526833; blocked by process 6676.
HINT:  See server log for query details.
[SQL: INSERT INTO task_run (flow_run_id, task_key, dynamic_key, flow_run_run_count, empirical_policy, task_inputs, tags, name, run_count, expected_start_time, start_time, total_run_time, id, created, updated) VALUES ($1::UUID, $2::VARCHAR, $3::VARCHAR, $4::INTEGER, $5, $6, $7::JSONB, $8::VARCHAR, $9::INTEGER, $10::TIMESTAMP WITH TIME ZONE, $11::TIMESTAMP WITH TIME ZONE, $12::INTERVAL, $13::UUID, $14::TIMESTAMP WITH TIME ZONE, $15::TIMESTAMP WITH TIME ZONE) ON CONFLICT (id) DO UPDATE SET flow_run_id = $16::UUID, task_key = $17::VARCHAR, dynamic_key = $18::VARCHAR, flow_run_run_count = $19::INTEGER, empirical_policy = $20, task_inputs = $21, tags = $22::JSONB, name = $23::VARCHAR, run_count = $24::INTEGER, expected_start_time = $25::TIMESTAMP WITH TIME ZONE, start_time = $26::TIMESTAMP WITH TIME ZONE, total_run_time = $27::INTERVAL, id = $28::UUID, updated = $29::TIMESTAMP WITH TIME ZONE WHERE task_run.state_timestamp < $30::TIMESTAMP WITH TIME ZONE]
```



### Version info

```Text
Version:             3.3.1
API version:         0.8.4
Python version:      3.12.9
Git commit:          6a164620
Built:               Tue, Apr 01, 2025 2:41 AM
OS/Arch:             linux/x86_64
Profile:             ephemeral
Server type:         ephemeral
Pydantic version:    2.11.1
Server:
  Database:          sqlite
  SQLite version:    3.40.1
Integrations:
  prefect-redis:     0.2.2
  prefect-kubernetes: 0.5.9
```

### Additional context

I'm not sure if it's related to this https://github.com/PrefectHQ/prefect/issues/16299. In terms of load, we have around 30-40 pipelines running, but only around ~5-10 at any one time, so not particularly heavy workloads. We use Kubernetes workers for the workloads.

We also get warnings of the `CancellationCleanup` taking longer than the loop interval:

```
09:15:04.236 | WARNING | prefect.server.services.cancellationcleanup - CancellationCleanup took 53.716827 seconds to run, which is longer than its loop interval of 20.0 seconds.
09:16:00.380 | WARNING | prefect.server.services.cancellationcleanup - CancellationCleanup took 56.141906 seconds to run, which is longer than its loop interval of 20.0 seconds.
09:16:56.335 | WARNING | prefect.server.services.cancellationcleanup - CancellationCleanup took 55.95355 seconds to run, which is longer than its loop interval of 20.0 seconds.
09:17:49.045 | WARNING | prefect.server.services.cancellationcleanup - CancellationCleanup took 52.707539 seconds to run, which is longer than its loop interval of 20.0 seconds.
09:18:55.992 | WARNING | prefect.server.services.cancellationcleanup - CancellationCleanup took 66.945765 seconds to run, which is longer than its loop interval of 20.0 seconds.
09:20:02.635 | WARNING | prefect.server.services.recentdeploymentsscheduler - RecentDeploymentsScheduler took 5.264522 seconds to run, which is longer than its loop interval of 5 seconds.
09:20:04.380 | WARNING | prefect.server.services.cancellationcleanup - CancellationCleanup took 68.379368 seconds to run, which is longer than its loop interval of 20.0 seconds.
09:20:33.036 | WARNING | prefect.server.services.recentdeploymentsscheduler - RecentDeploymentsScheduler took 5.393272 seconds to run, which is longer than its loop interval of 5 seconds.
09:20:43.139 | WARNING | prefect.server.services.recentdeploymentsscheduler - RecentDeploymentsScheduler took 5.096183 seconds to run, which is longer than its loop interval of 5 seconds.
```",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17767/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17767
17764,late flow runs get deleted on new prefect deploy,closed,completed,2025-04-07T23:21:40Z,2025-04-11T00:24:04Z,2025-04-11T00:24:03Z,4,['bug'],rcash,desertaxle,CONTRIBUTOR,"### Bug summary

flow runs that are late or awaitingconcurrencyslot in a given deployment are deleted and not rescheduled when a fresh `prefect deploy` is issued for the deployment.

steps to reproduce:
1. deploy a simple flow like below to a process workpool
2. make sure schedule is active + flow runs are being kicked off
3. kill the process worker temporarily, let a few of the scheduled flow runs stack up as late
4. bring the process worker back up + run `prefect deploy`
5. all the late runs seem to have disappeared - and are replaced with the new deployment's runs, if applicable.

flow code:
```
import time
from prefect import flow, task


@task(log_prints=True)
def generic_task(name: str, sleep_time: int):
    print(f""Task {name} Started"")
    print(f""sleeping for {sleep_time} seconds"")
    time.sleep(sleep_time)
    print(f""Task {name} Completed"")

@flow(log_prints=True)
def generic_flow():
    print(""Starting Flow"")
    a = generic_task.submit(""a"",25)
    print(a.result())
```

prefect.yaml contents:
```
deployments:
- name: default
  parameters: {}
  parameter_openapi_schema: {}
  entrypoint: simple_flow.py:generic_flow
  schedule:
    interval: 10 # seconds
    slug: ""default-schedule""
    timezone: ""America/New_York""
    active: true
```




### Version info

```Text
Version:             3.3.3
API version:         0.8.4
Python version:      3.12.9
Git commit:          4100d4ea
Built:               Sat, Apr 05, 2025 01:44 AM
OS/Arch:             darwin/arm64
Profile:             sbx-rowdy-cloud
Server type:         cloud
Pydantic version:    2.11.2
Integrations:
  prefect-databricks: 0.3.0
```

### Additional context

alternatively, set a `concurrency_limit` of 1 on the deployment and the task sleep to an amount of time greater than the interval on the schedule. let a few runs stack up, re-run `prefect deploy` and all the awaitingconcurrencyslot flow runs disappear.",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17764/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17764
17761,10~20s slowdown when importing `prefect-aws`,open,,2025-04-07T17:28:30Z,2025-04-07T18:47:18Z,,3,['bug'],PPPSDavid,,NONE,"### Bug summary

We recently ran into a delay of 10~20 seconds whenever we import the Python package `prefect_aws`. This is a bit surprising and hard to work around, particularly for flows that have a short latency requirement.

This should be able to be reproduced with the following setup:

Install prefect-aws (latest version is fine) via pip install ""prefect[aws]"" 

In a Python terminal / script, do `import prefect_aws ` and time its execution

We have confirmed that this behavior continues to exist as of prefect v3.3.2 freshly installed last week, as well as prefect 2.x in a separate environment.

### Version info

```Text
Unable to paste in full due to IP restrictions, but:

Version: 3.3.2
API version 0.8.4
Python version 3.11.11
ephemeral server and profile
Integration: prefect-aws 0.5.9
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17761/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17761
17756,AttributeError when using a string for DaskTaskRunner cluster_class,closed,duplicate,2025-04-07T14:09:19Z,2025-04-07T14:12:46Z,2025-04-07T14:11:54Z,2,['bug'],TWeatherston,,NONE,"### Bug summary

When using a string value for the DaskTaskRunner cluster_class parameter, I get the error `AttributeError: 'str' object has no attribute '__module__'`.  This looks to be caused by the client property calling `to_qualified_name` on cluster_class instead of resolved_cluster_class

Minimal example:
```python
from prefect import flow, task
from prefect_dask import DaskTaskRunner


@task()
def return_one():
    return 1


@flow(
    task_runner=DaskTaskRunner(
        cluster_class=""dask.distributed.LocalCluster"",
    ),
)
def example():
    return_one.submit()


if __name__ == ""__main__"":
    example()

```

Stacktrace:
```
Traceback (most recent call last):
  File ""/flows/collection/example.py"", line 20, in <module>
    example()
  File ""/.venv/lib/python3.11/site-packages/prefect/flows.py"", line 1671, in __call__
    return run_flow(
           ^^^^^^^^^
  File ""/.venv/lib/python3.11/site-packages/prefect/flow_engine.py"", line 1527, in run_flow
    ret_val = run_flow_sync(**kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File ""/.venv/lib/python3.11/site-packages/prefect/flow_engine.py"", line 1372, in run_flow_sync
    return engine.state if return_type == ""state"" else engine.result()
                                                       ^^^^^^^^^^^^^^^
  File ""/.venv/lib/python3.11/site-packages/prefect/flow_engine.py"", line 350, in result
    raise self._raised
  File ""/.venv/lib/python3.11/site-packages/prefect/flow_engine.py"", line 763, in run_context
    yield self
  File ""/.venv/lib/python3.11/site-packages/prefect/flow_engine.py"", line 1370, in run_flow_sync
    engine.call_flow_fn()
  File ""/.venv/lib/python3.11/site-packages/prefect/flow_engine.py"", line 783, in call_flow_fn
    result = call_with_parameters(self.flow.fn, self.parameters)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/.venv/lib/python3.11/site-packages/prefect/utilities/callables.py"", line 210, in call_with_parameters
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File ""/flows/collection/example.py"", line 16, in example
    return_one.submit()
  File ""/.venv/lib/python3.11/site-packages/prefect/tasks.py"", line 1230, in submit
    future = task_runner.submit(self, parameters, wait_for)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/.venv/lib/python3.11/site-packages/prefect_dask/task_runners.py"", line 431, in submit
    future = self.client.submit(
             ^^^^^^^^^^^
  File ""/.venv/lib/python3.11/site-packages/prefect_dask/task_runners.py"", line 353, in client
    f""`{to_qualified_name(self.cluster_class)}`""
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/.venv/lib/python3.11/site-packages/prefect/utilities/importtools.py"", line 47, in to_qualified_name
    return obj.__module__ + ""."" + obj.__qualname__
           ^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute '__module__'. Did you mean: '__mod__'?

```

### Version info

```Text
Version:             3.3.3
API version:         0.8.4
Python version:      3.11.11
Git commit:          4100d4ea
Built:               Sat, Apr 05, 2025 01:44 AM
OS/Arch:             darwin/arm64
Profile:             dev
Server type:         cloud
Pydantic version:    2.11.2
Integrations:
  prefect-dask:      0.3.4
  prefect-gcp:       0.6.5
  prefect-dbt:       0.6.6
  prefect-github:    0.3.1
  prefect-snowflake: 0.28.2
  prefect-aws:       0.5.9
  prefect-shell:     0.3.1
```

### Additional context

_No response_",desertaxle,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17756/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17756
17754,Prefect Task is not serialized by distributed.protocol.serialize,open,,2025-04-07T08:04:39Z,2025-04-26T08:06:50Z,,4,"['bug', 'upstream dependency']",nkanazawa1989,,NONE,"### Bug summary

It seems like the Prefect Task cannot be serialized with `distributed.protocol.serialize`. I slightly modified [this test](https://github.com/PrefectHQ/prefect/blob/de45c87cee0eae0ef7b4937ba6dbe01f84f695f3/src/integrations/prefect-dask/tests/test_task_runners.py#L85-L108) and created the following script.

```python
from dask_jobqueue import PBSCluster
from prefect import flow, task
from prefect_dask import DaskTaskRunner


@task
def task_a():
    return ""a""


@task
def task_b():
    return ""b""


@task
def task_c(b: str):
    return b + ""c""


@flow(version=""test"")
def test_flow():
    a = task_a.submit()
    b = task_b.submit()
    c = task_c.submit(b)
    return a, b, c


def main():
    with PBSCluster(
        walltime=""00:02:00"",
        processes=1,
        cores=2,
        memory=""2GiB"",
        local_directory=""/tmp"",
        job_extra_directives=[""-V""],
    ) as cluster:
        task_runner = DaskTaskRunner(cluster=cluster)
        
        a, b, c = test_flow.with_options(task_runner=task_runner)()

    print(a, b, c)


if __name__ == ""__main__"":
    main()
```

Running this script on my PBS login node with Prefect server installation will cause the following exception.
```
Encountered exception during execution: TypeError('Could not serialize object of type HighLevelGraph', '<ToPickle: HighLevelGraph with 1 layers.\n<dask.highlevelgraph.HighLevelGraph object at 0x7f39bf1a42d0>\n 0. 139885965356672\n>')
Traceback (most recent call last):
  File ""...venv/lib/python3.11/site-packages/distributed/protocol/pickle.py"", line 60, in dumps
    result = pickle.dumps(x, **dump_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_pickle.PicklingError: Can't pickle <function task_a at 0x7f39bd445ee0>: it's not the same object as __main__.task_a

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""...venv/lib/python3.11/site-packages/distributed/protocol/pickle.py"", line 65, in dumps
    pickler.dump(x)
_pickle.PicklingError: Can't pickle <function task_a at 0x7f39bd445ee0>: it's not the same object as __main__.task_a

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""...venv/lib/python3.11/site-packages/distributed/protocol/serialize.py"", line 366, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""...venv/lib/python3.11/site-packages/distributed/protocol/serialize.py"", line 78, in pickle_dumps
    frames[0] = pickle.dumps(
                ^^^^^^^^^^^^^
  File ""...venv/lib/python3.11/site-packages/distributed/protocol/pickle.py"", line 77, in dumps
    result = cloudpickle.dumps(x, **dump_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""...venv/lib/python3.11/site-packages/cloudpickle/cloudpickle.py"", line 1537, in dumps
    cp.dump(obj)
  File ""...venv/lib/python3.11/site-packages/cloudpickle/cloudpickle.py"", line 1303, in dump
    return super().dump(obj)
           ^^^^^^^^^^^^^^^^^
TypeError: cannot pickle 'generator' object

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""...venv/lib/python3.11/site-packages/prefect/flow_engine.py"", line 763, in run_context
    yield self
  File ""...venv/lib/python3.11/site-packages/prefect/flow_engine.py"", line 1370, in run_flow_sync
    engine.call_flow_fn()
  File ""...venv/lib/python3.11/site-packages/prefect/flow_engine.py"", line 783, in call_flow_fn
    result = call_with_parameters(self.flow.fn, self.parameters)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""...venv/lib/python3.11/site-packages/prefect/utilities/callables.py"", line 210, in call_with_parameters
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File ""/home/.../simple-test.py"", line 24, in test_flow
    a = task_a.submit()
        ^^^^^^^^^^^^^^^
  File ""...venv/lib/python3.11/site-packages/prefect/tasks.py"", line 1230, in submit
    future = task_runner.submit(self, parameters, wait_for)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""...venv/lib/python3.11/site-packages/prefect_dask/task_runners.py"", line 431, in submit
    future = self.client.submit(
             ^^^^^^^^^^^^^^^^^^^
  File ""...venv/lib/python3.11/site-packages/prefect_dask/client.py"", line 64, in submit
    future = super().submit(
             ^^^^^^^^^^^^^^^
  File ""...venv/lib/python3.11/site-packages/distributed/client.py"", line 2174, in submit
    futures = self._graph_to_futures(
              ^^^^^^^^^^^^^^^^^^^^^^^
  File ""...venv/lib/python3.11/site-packages/distributed/client.py"", line 3377, in _graph_to_futures
    header, frames = serialize(ToPickle(dsk), on_error=""raise"")
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""...venv/lib/python3.11/site-packages/distributed/protocol/serialize.py"", line 392, in serialize
    raise TypeError(msg, str_x) from exc
TypeError: ('Could not serialize object of type HighLevelGraph', '<ToPickle: HighLevelGraph with 1 layers.\n<dask.highlevelgraph.HighLevelGraph object at 0x7f39bf1a42d0>\n 0. 139885965356672\n>')
```

PBS dependency is too much complicated to debug further.

### Version info

```Text
Version:             3.3.2
API version:         0.8.4
Python version:      3.11.11
Git commit:          e49e3185
Built:               Thu, Apr 03, 2025 09:25 PM
OS/Arch:             linux/x86_64
Profile:             local
Server type:         server
Pydantic version:    2.9.2
Integrations:
  prefect-dask:      0.3.4
```

### Additional context

```
distributed==2025.3.0
dask==2025.3.0
dask-jobqueue==0.9.0
prefect-dask==0.3.4
```",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17754/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17754
17750,Prefect3: Logs created in tasks run with DaskTaskRunner dont appear in UI,open,,2025-04-06T17:41:23Z,2025-05-02T03:12:13Z,,4,['bug'],OliverKleinBST,,NONE,"### Bug summary

Logs created in tasks run with DaskTaskRunner dont appear in UI

```
from prefect.task_runners import PrefectTaskRunner
from prefect_dask import DaskTaskRunner, get_dask_client
from dask_kubernetes.operator import KubeCluster
from prefect import flow, task
from prefect import get_run_logger

@task(log_prints=True)
def say_hello(name):
    print(f""hello {name}"")
    logger = get_run_logger()
    logger.info(f""hello {name}"")


@task(log_prints=True)
def say_goodbye(name):
    print(f""goodbye {name}"")

@flow(task_runner=DaskTaskRunner(
    cluster_class=KubeCluster,
    cluster_kwargs={
        ""name"": ""my-dask-cluster"",
        ""image"": ""ghcr.io/dask/dask:latest"",
        ""n_workers"": 4,
        ""env"": {
            ""EXTRA_PIP_PACKAGES"": ""prefect[dask]==3.2.15 dask_kubernetes"",
            ""PREFECT_API_URL"": ""http://...:4200/api"",
            ""PREFECT_LOGGING_EXTRA_LOGGERS"": ""dask"", 
        }
    },
))
def greetings_dask(names):
    for name in names:
        say_hello.submit(name).result()
        say_goodbye.submit(name).result()

if __name__ == ""__main__"":
    greetings_dask([""arthur"", ""trillian"", ""ford"", ""marvin""])
```

### Version info

```Text
Version:             3.2.15
API version:         0.8.4
Python version:      3.11.11
Git commit:          0f5a3081
Built:               Fri, Mar 28, 2025 3:28 PM
OS/Arch:             linux/x86_64
Profile:             ephemeral
Server type:         server
Pydantic version:    2.11.1
Integrations:
  prefect-azure:     0.4.3
  prefect-docker:    0.6.2
  prefect-shell:     0.3.1
  prefect-kubernetes: 0.5.9
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17750/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17750
17749,Improving Daylight-Savings-Time robustness in scheduler,open,,2025-04-05T09:20:52Z,2025-04-07T17:43:30Z,,2,['enhancement'],ariebovenberg,,NONE,"### Describe the current behavior

First let me say Iâ€™m very happy to see my project (`whenever`) is useful to you. I check in on new adopters of the library to gain valuable feedback on how itâ€™s used in the real world.

Reading prefectâ€™s datetime code using `whenever`, I see you already take care to account for DST.
I had a suggestion to improve things a bit more.

In `server/schemas/schedules.py`, it says:

>             # break the interval into `days` and `seconds` because the datetime
>             # library will handle DST boundaries properly if days are provided, but not
>             # if we add `total seconds`. Therefore, `next_date + self.interval`
>             # fails while `next_date.add(days=days, seconds=seconds)` works.

Yesâ€”but itâ€™s a bit more nuanced. The problem more precisely is that `datetime.timedelta` always assumes 24-hour days. So `timedelta(days=2)` and `timedelta(hours=48)` are indistinguishable:

```python
>>> timedelta(hours=48)
datetime.timedelta(days=2)
>>> timedelta(days=2)
datetime.timedelta(days=2)
```

Due to this, Prefect users would still have problems scheduling â€œexactly 48 hoursâ€, since the code in `schedules.py` will silently assume this means 2 calendar days. But, of course, assuming the opposite would hurt users that specify `timedelta(days=2)`.

Below an example where this distinction matters. So long as you canâ€™t distinguish the two durations, you canâ€™t have consistently correct code.

```
2023-03-25T10[Europe/Amsterdam] + 48 hours -> 2023-03-27T11[Europe/Amsterdam]
2023-03-25T10[Europe/Amsterdam] + 2 days -> 2023-03-27T10[Europe/Amsterdam]
```



### Describe the proposed behavior

In the end, this canâ€™t be fixed using `datetime.timedelta` (or `pendulum.Duration`), since they donâ€™t distinguish calendar days from 24-hour periods.

Datetime libraries in other languages have solved this problem by separating calendar days from exact hours. Drawing inspiration from these libraries, `whenever` defines the `DateTimeDelta` type:

```python
>>> from whenever import DateTimeDelta
>>> DateTimeDelta(days=2)
DateTimeDelta(P2D)
>>> DateTimeDelta(hours=48)
DateTimeDelta(PT48H)
```

`ZonedDateTime(â€¦).add(delta)` will then work as expected, distinguishing calendar days from exact hours.

Now, I'm not suggesting to *replace* `timedelta` with `DateTimeDelta` ðŸ˜‰, but supporting it as an option could help users be explicit when they need to be.

*PS: of course, let me know if there are any other suggestions/complaints about `whenever` so far*

### Example Use

_No response_

### Additional context

_No response_",,1,https://api.github.com/repos/PrefectHQ/prefect/issues/17749/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17749
17735,Exception occur in worker causing restarts,open,,2025-04-04T15:33:43Z,2025-04-17T12:23:08Z,,6,['bug'],giacomochiarella,,NONE,"### Bug summary


In Prefect 3.2.14, I'm having this exception. Would be great some guidance in understanding what it is about. Once the agent restarts all the running jobs are hanging in running state. The only way to make them recover is to set another deployment which restarts all the running/pending/schedule flow runs which are those states since X hours
```
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |  + Exception Group Traceback (most recent call last):
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |  |  File â€œ/usr/local/lib/python3.10/site-packages/prefect/cli/_utilities.pyâ€, line 44, in wrapper
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |  |   return fn(*args, **kwargs)
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |  |  File â€œ/usr/local/lib/python3.10/site-packages/prefect/cli/_types.pyâ€, line 155, in sync_fn
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |  |   return asyncio.run(async_fn(*args, **kwargs))
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |  |  File â€œ/usr/local/lib/python3.10/asyncio/runners.pyâ€, line 44, in run
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |  |   return loop.run_until_complete(main)
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |  |  File â€œ/usr/local/lib/python3.10/asyncio/base_events.pyâ€, line 649, in run_until_complete
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |  |   return future.result()
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |  |  File â€œ/usr/local/lib/python3.10/site-packages/prefect/cli/worker.pyâ€, line 169, in start
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |  |   await worker.start(
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |  |  File â€œ/usr/local/lib/python3.10/site-packages/prefect/workers/process.pyâ€, line 149, in start
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |  |   async with self as worker:
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |  |  File â€œ/usr/local/lib/python3.10/site-packages/prefect/workers/process.pyâ€, line 242, in __aexit__
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |  |   await super().__aexit__(*exc_info)
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |  |  File â€œ/usr/local/lib/python3.10/site-packages/prefect/workers/base.pyâ€, line 1344, in __aexit__
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |  |   await self.teardown(*exc_info)
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |  |  File â€œ/usr/local/lib/python3.10/site-packages/prefect/workers/base.pyâ€, line 726, in teardown
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |  |   await self._exit_stack.__aexit__(*exc_info)
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |  |  File â€œ/usr/local/lib/python3.10/contextlib.pyâ€, line 714, in __aexit__
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |  |   raise exc_details[1]
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |  |  File â€œ/usr/local/lib/python3.10/contextlib.pyâ€, line 697, in __aexit__
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |  |   cb_suppress = await cb(*exc_details)
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |  |  File â€œ/usr/local/lib/python3.10/site-packages/anyio/_backends/_asyncio.pyâ€, line 772, in __aexit__
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |  |   raise BaseExceptionGroup(
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |  | exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |  +-+---------------- 1 ----------------
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |   | Exception Group Traceback (most recent call last):
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |   |  File â€œ/usr/local/lib/python3.10/contextlib.pyâ€, line 697, in __aexit__
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |   |   cb_suppress = await cb(*exc_details)
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |   |  File â€œ/usr/local/lib/python3.10/site-packages/prefect/runner/runner.pyâ€, line 1688, in __aexit__
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |   |   await self._runs_task_group.__aexit__(*exc_info)
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |   |  File â€œ/usr/local/lib/python3.10/site-packages/anyio/_backends/_asyncio.pyâ€, line 772, in __aexit__
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |   |   raise BaseExceptionGroup(
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |   | exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |   +-+---------------- 1 ----------------
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |    | Traceback (most recent call last):
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |    |  File â€œ/usr/local/lib/python3.10/site-packages/prefect/runner/runner.pyâ€, line 1584, in wrapper
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |    |   result = fn(*args, **kwargs)
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |    | KeyError: UUID(â€˜dadccbfd-41a7-40ca-8ace-574390f79d2aâ€™)
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 |    +------------------------------------
Apr 04 15:15:17 ip-172-30-1-217 start_prefect.sh[1855]: agent_1 | An exception occurred.
```

unfortunately it is not clear what the exception is about

### Version info

```Text
Prefect 3.2.14
Python 3.10
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17735/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17735
17734,DaskTaskRunner with string cluster_class raises AttributeError,closed,completed,2025-04-04T15:09:13Z,2025-04-04T15:59:43Z,2025-04-04T15:59:43Z,0,['bug'],nkanazawa1989,,NONE,"### Bug summary

`DaskTaskRunner` raises the following error when instantiated with a string `cluster_class` and a task is submitted.

```
...
  File ""/.../lib/python3.11/site-packages/prefect_dask/task_runners.py"", line 353, in client
    f""`{to_qualified_name(self.cluster_class)}`""
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/.../lib/python3.11/site-packages/prefect/utilities/importtools.py"", line 47, in to_qualified_name
    return obj.__module__ + ""."" + obj.__qualname__
           ^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute '__module__'
```

for example
```python
    task_runner = DaskTaskRunner(
        cluster_class=""dask_jobqueue.pbs.PBSCluster"",
        cluster_kwargs={
            ...
        },
    )
    
    myflow.with_options(task_runner=task_runner)(...)
```

### Version info

```Text
Version:             3.3.2
API version:         0.8.4
Python version:      3.11.11
Git commit:          e49e3185
Built:               Thu, Apr 03, 2025 09:25 PM
OS/Arch:             linux/x86_64
Profile:             local
Server type:         server
Pydantic version:    2.9.2
Integrations:
  prefect-dask:      0.3.4
```

### Additional context

This block must use `self.resolved_cluster_class` instead of `self.cluster_class`

https://github.com/PrefectHQ/prefect/blob/366d251f100b7db28235bec7ccaf5759161cbbf8/src/integrations/prefect-dask/prefect_dask/task_runners.py#L349-L357",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17734/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17734
17729,flow_runs graph-v2 requests fail with sqlite,closed,completed,2025-04-04T10:10:36Z,2025-04-05T01:45:43Z,2025-04-05T01:29:03Z,2,['bug'],tothandor,,NONE,"### Bug summary

This is the same issue as with #16487 , but the fix applied there does not work.

Here's my suggestion for the fix.

```patch
--- /srv/prefect/venv/lib64/python3.12/site-packages/prefect/server/utilities/database.py.orig  2025-04-04 11:55:32.064626946 +0200
+++ /srv/prefect/venv/lib64/python3.12/site-packages/prefect/server/utilities/database.py       2025-04-04 11:54:43.143732972 +0200
@@ -160,10 +160,10 @@
         if value is None:
             return None
         else:
-            if value.tzinfo is None:
+            if value.tzinfo is None and dialect.name != 'sqlite':
                 raise ValueError(""Timestamps must have a timezone."")
             elif dialect.name == ""sqlite"":
-                return value.astimezone(ZoneInfo(""UTC""))
+                return value.replace(tzinfo=datetime.timezone.utc)
             else:
                 return value
```

The error is triggered when a `datetime.datetime.min` (i.e. `datetime.datetime(1, 1, 1, 0, 0)`) is passed to `process_bind_param()` as `value`. `.astimezone()` cannot be applied on this datetime (`year 0 is out of range`), but apparently `.replace(tzinfo=...)` works.


### Version info

```Text
Version:             3.3.2
API version:         0.8.4
Python version:      3.12.3
Git commit:          e49e3185
Built:               Thu, Apr 03, 2025 09:25 PM
OS/Arch:             linux/x86_64
Profile:             default
Server type:         server
Pydantic version:    2.10.5
Integrations:
  prefect-sqlalchemy: 0.5.2
```

### Additional context

OS: AlmaLinux 8.10

$ sqlite3 --version
3.26.0 2018-12-01 12:34:55 bf8c1b2b7a5960c282e543b9c293686dccff272512d08865f4600fb58238alt1

$ pip show aiosqlite
Name: aiosqlite
Version: 0.21.0

",desertaxle,2,https://api.github.com/repos/PrefectHQ/prefect/issues/17729/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17729
17728,Events with large related_resources causes looping insert error,closed,completed,2025-04-04T09:47:28Z,2025-04-07T16:15:07Z,2025-04-07T16:15:07Z,2,['bug'],ogenstad,,CONTRIBUTOR,"### Bug summary

When submitting events to prefect the with a large amount of data in the `related` field can cause the `ix_events__event_related_occurred` index can prevent events from being inserted into the database and cause looping errors as Prefect continues to attempt to insert the too large event (I don't know if there's a limit to the number of tries here).

A sample script to highlight this behaviour:

```python
import os
import uuid
from typing import Any

from prefect.events import emit_event


def define_event() -> dict[str, Any]:
    settings_related = os.environ.get(""RESOURCE_MULTIPLIER"")
    settings_data = os.environ.get(""DATA_MULTIPLIER"")
    data_multiplier = int(settings_data) if settings_data else 1
    resource_multiplier = int(settings_related) if settings_related else 1

    related_resources = [
        {
            ""prefect.resource.id"": str(uuid.uuid4()),
            ""prefect.resource.role"": ""test.related"",
            ""data"": str(uuid.uuid4()) * data_multiplier,
        }
        for _ in range(resource_multiplier)
    ]
    event = {
        ""event"": ""test.event"",
        ""resource"": {""prefect.resource.id"": str(uuid.uuid4())},
        ""related"": related_resources,
    }

    print(f""Data multiplier: {data_multiplier}"")
    print(f""Related resources: {resource_multiplier}"")

    return event


event = define_event()

emit_event(**event)
```

Running this with:

```bash
RESOURCE_MULTIPLIER=35 python emit_events.py
```

Would cause the error loop to begin as this can be seen within the logs of Postgres:

```bash
2025-04-04 09:04:59.614 UTC [129] ERROR:  index row size 2912 exceeds btree version 4 maximum 2704 for index ""ix_events__event_related_occurred""
2025-04-04 09:04:59.614 UTC [129] DETAIL:  Index row references tuple (0,4) in relation ""events"".
2025-04-04 09:04:59.614 UTC [129] HINT:  Values larger than 1/3 of a buffer page cannot be indexed.
        Consider a function index of an MD5 hash of the value, or use full text indexing.
2025-04-04 09:04:59.614 UTC [129] STATEMENT:  INSERT INTO events (occurred, event, resource_id, resource, related_resource_ids, related, payload, received, recorded, follows, id, created, updated) VALUES ($1::TIMESTAMP WITH TIME ZONE, $2::VARCHAR, $3::VARCHAR, $4::JSONB, $5::JSONB, $6::JSONB, $7::JSONB, $8::TIMESTAMP WITH TIME ZONE, $9::TIMESTAMP WITH TIME ZONE, $10::UUID, $11::UUID, $12::TIMESTAMP WITH TIME ZONE, $13::TIMESTAMP WITH TIME ZONE) ON CONFLICT DO NOTHING RETURNING events.id
2025-04-04 09:05:04.620 UTC [129] ERROR:  index row size 2912 exceeds btree version 4 maximum 2704 for index ""ix_events__event_related_occurred""
2025-04-04 09:05:04.620 UTC [129] DETAIL:  Index row references tuple (0,5) in relation ""events"".
2025-04-04 09:05:04.620 UTC [129] HINT:  Values larger than 1/3 of a buffer page cannot be indexed.
        Consider a function index of an MD5 hash of the value, or use full text indexing.
2025-04-04 09:05:04.620 UTC [129] STATEMENT:  INSERT INTO events (occurred, event, resource_id, resource, related_resource_ids, related, payload, received, recorded, follows, id, created, updated) VALUES ($1::TIMESTAMP WITH TIME ZONE, $2::VARCHAR, $3::VARCHAR, $4::JSONB, $5::JSONB, $6::JSONB, $7::JSONB, $8::TIMESTAMP WITH TIME ZONE, $9::TIMESTAMP WITH TIME ZONE, $10::UUID, $11::UUID, $12::TIMESTAMP WITH TIME ZONE, $13::TIMESTAMP WITH TIME ZONE) ON CONFLICT DO NOTHING RETURNING events.id
```

Alternatively if you send in a single related resource with large content.

```bash
DATA_MULTIPLIER=10000 python emit_events.py

```

If the intention is that these type of events shouldn't be supported I'd expect them to be rejected by the Prefect API, otherwise that the index would be swapped for something else.


### Version info

```Text
â¯ prefect version
Version:             3.3.2
API version:         0.8.4
Python version:      3.12.8
Git commit:          e49e3185
Built:               Thu, Apr 03, 2025 09:25 PM
OS/Arch:             darwin/arm64
Profile:             ephemeral
Server type:         server
Pydantic version:    2.10.6
Integrations:
  prefect-redis:     0.2.2
```

### Additional context

_No response_",desertaxle,1,https://api.github.com/repos/PrefectHQ/prefect/issues/17728/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17728
17727,Deleting worker from work pool deletes WRONG worker,open,,2025-04-04T09:06:33Z,2025-05-04T16:52:13Z,,2,"['bug', 'ui']",LukasJerabek,,NONE,"### Bug summary

In a work pool detail, you click on one worker, try to delete him, but then in the prompt the last one in table is the one that is being deleted, no matter which you clicked.

![Image](https://github.com/user-attachments/assets/1fb15ec5-6fc7-4654-802e-bedb2c213003)


### Version info

```Text
Version:             3.2.14
API version:         0.8.4
Python version:      3.11.9
Git commit:          efcde6dc
Built:               Fri, Mar 21, 2025 5:28 PM
OS/Arch:             win32/AMD64
Profile:             ephemeral
Server type:         ephemeral
Pydantic version:    2.11.1
Server:
  Database:          sqlite
  SQLite version:    3.45.1
Integrations:
  prefect-email:     0.4.1
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17727/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17727
17710,Async Task Calling Async Flow: RuntimeError('Event loop is closed'),closed,completed,2025-04-03T03:04:50Z,2025-04-03T21:02:43Z,2025-04-03T21:02:43Z,1,['bug'],jcppython,,NONE,"### Bug summary

code example
```
from prefect import flow, task 
import asyncio 
 
 
@flow 
async def process(item): 
    await asyncio.sleep(5) 
    print(item) 
 
 
@task 
async def async_task(item): 
    await process(item) 
 
 
@flow 
async def async_flow(): 
    features = async_task.map([1,2,3]) 
    features.result() 
     
 
if __name__ == '__main__': 
    asyncio.run(async_flow()) 
```

error message

```
    self._transport.close()
  File ""xxx/lib/python3.12/asyncio/selector_events.py"", line 1213, in close
    super().close()
  File ""xxx/lib/python3.12/asyncio/selector_events.py"", line 875, in close
    self._loop.call_soon(self._call_connection_lost, None)
  File ""xxx/lib/python3.12/asyncio/base_events.py"", line 799, in call_soon
    self._check_closed()
  File ""xxx/lib/python3.12/asyncio/base_events.py"", line 545, in _check_closed
    raise RuntimeError('Event loop is closed')
RuntimeError: Event loop is closed
```


### Version info

```Text
Version:             3.2.15
API version:         0.8.4
Python version:      3.12.9
Git commit:          0f5a3081
Built:               Fri, Mar 28, 2025 3:28 PM
OS/Arch:             linux/x86_64
Profile:             ephemeral
Server type:         server
Pydantic version:    2.10.3
```

### Additional context

_No response_",zzstoatzz,1,https://api.github.com/repos/PrefectHQ/prefect/issues/17710/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17710
17709,Collapse related tasks (generated by e.g. calls to `map`) in Flow run DAG,closed,duplicate,2025-04-03T02:53:14Z,2025-04-03T03:27:40Z,2025-04-03T03:27:38Z,1,['enhancement'],AmagicalFishy,,NONE,"### Describe the current behavior

Currently, Prefect creates a node for every task. This sometimes results in overly branched DAG graphs that aren't very readable, making it difficult to visually trace what's going on (for example, in the case of flows w/ many tasks, generated by `map`). 

![Image](https://github.com/user-attachments/assets/8c54ccb9-418f-4460-84dc-a96495771f77)

One solution to this is [nesting these generated tasks under another task or flow](https://github.com/PrefectHQ/prefect/discussions/17620). This works technically, but forces restructuring code around DAG graph generation, and (in the case of sub-flow) splits up the flow into multiple flows or (in the case of tasks) makes them difficult to separate.

### Describe the proposed behavior

In the DAG, collapse all tasks created by `map` (maybe, more generally, when tasks are tagged with the same tag, or within the same ""task group"", or something of the sort). 

This is already do-able given what happens when tasks run in a sub-flow (all tasks in the sub-flow are collapsed into a single node on the DAG). Maybe include an option in the bottom-right gear-box menu to collapse or uncollapse?

### Example Use

_No response_

### Additional context

_No response_",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17709/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17709
17703,Dangling flow runs from deleted schedules cause duplicates,open,,2025-04-02T21:12:20Z,2025-05-12T21:11:17Z,,6,"['bug', 'great writeup']",Ultramann,,CONTRIBUTOR,"### Bug summary

We've been experiencing incorrectly duplicated flow runs executing at the same time on our self-hosted prefect server. This is an issue for us because some of our flow require resource locks and so duplicated flows create a race condition.

Digging into the prefect database I found that the duplication seems to be coming from different idempotency keys where the difference comes from the schedule id, and the duplicate flow runs seem to be coming from schedules that no longer exist.
```sql
with cte as (
  select deployment_id, expected_start_time
  from flow_run
  group by deployment_id, expected_start_time
  having count(*) > 1
)
select cte.deployment_id, fr.created, fr.state_type, fr.idempotency_key, fr.created_by, ds.id is not null as schedule_exists
from flow_run fr
join cte
on fr.deployment_id = cte.deployment_id
and fr.expected_start_time = cte.expected_start_time
left join deployment_schedule ds
on created_by->>'id' = ds.id::text
order by cte.deployment_id, cte.expected_start_time
```

Below you can see some flow run records from this query. The first two rows show duplicate runs where one failed and the other completed. This isn't remarkable as we expect deployment schedules to be deleted over time. The next two rows, however, show duplicate scheduled flow runs where one has an existing schedule, and the other refers to a schedule that no longer exists. Because they refer to different schedules the idepempotency key is different and therefore the duplicates aren't detected.

![Image](https://github.com/user-attachments/assets/b1d36117-8798-4ea3-9889-84a7d92e0b5d)

If I'm reading the source code correctly, I think running `prefect deploy` for a deployment that already exists should result in the old flow runs getting deleted, see code path below, so I'm not sure why this isn't happening for my scheduled flow runs all the time. Code path
1. [`prefect deploy`](https://github.com/PrefectHQ/prefect/blob/3f0c87e32e54e1f184df275c4263705b9ad90b6e/src/prefect/cli/deploy.py#L239)
2. [`_run_single_deploy`](https://github.com/PrefectHQ/prefect/blob/3f0c87e32e54e1f184df275c4263705b9ad90b6e/src/prefect/cli/deploy.py#L487)
3. [`RunnerDeployment.apply`](https://github.com/PrefectHQ/prefect/blob/af89e980e1c2ffbd54ca5a8b4e3ce4782a62570f/src/prefect/deployments/runner.py#L430)
4. [`RunnerDeployment._update`](https://github.com/PrefectHQ/prefect/blob/af89e980e1c2ffbd54ca5a8b4e3ce4782a62570f/src/prefect/deployments/runner.py#L370)
5. [`DeploymentAsyncClient.update_deployment`](https://github.com/PrefectHQ/prefect/blob/c8986edebb2dde3e2a931adbe24d2eaefcb799cb/src/prefect/client/orchestration/_deployments/client.py#L706)
6. [`update_deployment`](https://github.com/PrefectHQ/prefect/blob/3f0c87e32e54e1f184df275c4263705b9ad90b6e/src/prefect/server/api/deployments.py#L183)
7. [`models.deployments.update_deployment`](https://github.com/PrefectHQ/prefect/blob/3f0c87e32e54e1f184df275c4263705b9ad90b6e/src/prefect/server/api/deployments.py#L303)
8. [`_delete_scheduled_runs`](https://github.com/PrefectHQ/prefect/blob/3f0c87e32e54e1f184df275c4263705b9ad90b6e/src/prefect/server/models/deployments.py#L265)

I might be missing something in that order, but I'm pretty sure it's close because I see logs for PATCH requests to `/api/deployments`, number 6 above, on the server during deployment. Note, we don't have slugs for our schedules.

## Reproduction
I have tried and failed to create a minimal repro. I can't tell if this is because the issue is related to the way we deploy which is difficult to reproduce minimally, or if it's related to something else in our setup that doesn't exist in a local repro, or if it just occurs randomly with low probability and I haven't gotten 'lucky"" enough to reproduce it. I can say that this happens consistently during our deployments.

### Version info

```Text
Version:             3.2.11
API version:         0.8.4
Python version:      3.11.11
Git commit:          9481694f
Built:               Wed, Mar 5, 2025 10:00 PM
OS/Arch:             linux/x86_64
Profile:             ephemeral
Server type:         ephemeral
Pydantic version:    2.11.1
Server:
  Database:          postgresql
Integrations:
  prefect-gcp:       0.6.4
```",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17703/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17703
17699,flow timeout_seconds not respected,open,,2025-04-02T16:57:02Z,2025-04-18T01:02:43Z,,2,"['bug', 'arch:windows']",pda-vtl,,NONE,"### Bug summary

Looking to use timeout functionality as documented on https://docs.prefect.io/v3/develop/write-flows#write-and-run-flows. 

Using Prefect 3.3.1, the below does not timeout:

```python
import time

from prefect import flow

@flow(timeout_seconds=10, log_prints=True)
def show_timeouts():
    while True:
        print(""sleeping..."")
        time.sleep(1)

show_timeouts()
```

### Version info

```Text
Version:             3.3.1
API version:         0.8.4
Python version:      3.11.11
Git commit:          6a164620
Built:               2025-04-01 02:39:35.818228+00:00
OS/Arch:             win32/AMD64
Profile:             local
Server type:         server
Pydantic version:    2.11.1
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17699/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17699
17696,Being able to set the loop interval of RecentDeploymentsScheduler,closed,completed,2025-04-02T15:39:08Z,2025-04-09T21:27:53Z,2025-04-09T21:27:53Z,4,['enhancement'],giacomochiarella,,NONE,"### Describe the current behavior

There is a warning saying
`RecentDeploymentsScheduler took 6.806892 seconds to run, which is longer than its loop interval of 5 seconds`
and it is not possible to configure the loop interval

### Describe the proposed behavior

It would be good to have an environment variable to be able to set the loop interval.
It could worth to have an environment variable to suppress the warning but in my opinion this is secondary.

### Example Use

`PREFECT_API_SERVICES_DEPLOYMENT_SCHEDULER_LOOP_SECONDS=X`

### Additional context

_No response_",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17696/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17696
17695,extra parameters in flow schedules for deployments created via the API,closed,completed,2025-04-02T15:19:01Z,2025-04-02T15:58:13Z,2025-04-02T15:58:13Z,2,['bug'],rcash,,CONTRIBUTOR,"### Bug summary

Creating a deployment via the API and then editing the schedule associated with it in the UI appears to add extra parameters `value` and `__prefect_kind`, causing scheduled flow runs to crash. 

hit the API to create deployment:
```
import requests

ACCOUNT_ID = ""9b649228-0419-40e1-9e0d-44954b5c0ab6""
WORKSPACE_ID = ""714c2bde-f932-44fe-872a-3bd42118735c""
PREFECT_API_URL = (
    f""https://api.prefect.cloud/api/accounts/{ACCOUNT_ID}/workspaces/{WORKSPACE_ID}""
)
PREFECT_API_KEY = ""<api_key_goes_here>""

headers = {""Authorization"": f""Bearer {PREFECT_API_KEY}""}

create_deployment_data = {
    ""name"": ""my-test-deployment"",
    ""version"": None,
    ""flow_id"": ""83fb917e-d092-4f54-a3e7-fd00e3945ee5"",
    ""schedules"": [{""schedule"": {""interval"": 30, ""timezone"": ""America/New_York""}}],
    ""parameter_openapi_schema"": {},
    ""parameters"": {},
    ""pull_steps"": [
        {
            ""prefect.deployments.steps.set_working_directory"": {
                ""directory"": ""/Users/rowdy/Projects/support-311""
            }
        }
    ],
    ""work_pool_name"": ""rowdys-local-process-workpool"",
    ""schedule"": {
        ""interval"": 30,
        ""timezone"": ""America/New_York"",
    },
    ""path"": None,
    ""entrypoint"": ""flow.py:generic_flow"",
}
create_deployment_endpoint = f""https://api.prefect.cloud/api/accounts/{ACCOUNT_ID}/workspaces/{WORKSPACE_ID}/deployments/""

response = requests.post(
    create_deployment_endpoint, headers=headers, json=create_deployment_data
)
response.raise_for_status()
print(""deployment created successfully"")
print(response.json())
```

then navigate to the deployment in the UI and edit the schedule - anchor date, interval value, etc.

flow logs for error from a flow run then scheduled afterwards:
```
Worker 'ProcessWorker 825a9836-b5d3-4923-89b9-a138e87130c2' submitting flow run '2d5d9505-2d78-4a58-8181-3b330d85ab7d'
08:09:54 AM
Info
Running on worker id: c00cd213-56e8-4239-8858-9f2deb5b3b3a. See worker logs here: https://app.prefect.cloud/account/9b649228-0419-40e1-9e0d-44954b5c0ab6/workspace/714c2bde-f932-44fe-872a-3bd42118735c/work-pools/work-pool/rowdys-local-process-workpool/worker/c00cd213-56e8-4239-8858-9f2deb5b3b3a
08:09:54 AM
Info
Opening process...
08:09:56 AM
Info
Completed submission of flow run '2d5d9505-2d78-4a58-8181-3b330d85ab7d'
08:09:56 AM
Info
 > Running set_working_directory step...
08:09:57 AM
Info
Engine execution exited with unexpected exception
Traceback (most recent call last):
  File ""/Users/rowdy/Projects/support-311/.venv/lib/python3.11/site-packages/prefect/flow_engine.py"", line 1515, in run_flow
    parameters=_flow_parameters(
               ^^^^^^^^^^^^^^^^^
  File ""/Users/rowdy/Projects/support-311/.venv/lib/python3.11/site-packages/prefect/flow_engine.py"", line 1555, in _flow_parameters
    call_args, call_kwargs = parameters_to_args_kwargs(flow.fn, parameters)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/rowdy/Projects/support-311/.venv/lib/python3.11/site-packages/prefect/utilities/callables.py"", line 190, in parameters_to_args_kwargs
    raise SignatureMismatchError.from_bad_params(
prefect.exceptions.SignatureMismatchError: Function expects parameters [] but was provided with parameters ['value', '__prefect_kind']
08:09:57 AM
Error
Process for flow run 'dashing-dingo' exited with status code: 1
08:09:57 AM
Error
Reported flow run '2d5d9505-2d78-4a58-8181-3b330d85ab7d' as crashed: Flow run process exited with non-zero status code 1.
```

### Version info

```Text
Version:             3.2.9
API version:         0.8.4
Python version:      3.11.11
Git commit:          27eb408c
Built:               Fri, Feb 28, 2025 8:12 PM
OS/Arch:             darwin/arm64
Profile:             local
Server type:         cloud
Pydantic version:    2.11.1
```

### Additional context

note that 'Parameters' shows {}
![Image](https://github.com/user-attachments/assets/36b3c105-3454-419c-9b71-b27e68eb283b)

future scheduled runs show two parameters after updating the schedule
![Image](https://github.com/user-attachments/assets/317a0c9c-c22d-4b0d-b391-b3f9ee2233ee)

the additional parameters from a crashed flow run
![Image](https://github.com/user-attachments/assets/9c45057f-fbb5-4b44-b7a0-7d443cfbf1cf)
",cicdw,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17695/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17695
17689,Parsing of version in windows leads to error 'ValueError: Invalid format string',closed,completed,2025-04-02T11:01:40Z,2025-04-02T23:41:18Z,2025-04-02T23:41:18Z,1,['bug'],freekmenger,,NONE,"### Bug summary

Running 'prefect version' leads to the following error:
  File ""\Lib\site-packages\prefect\cli\root.py"", line 115, in version
    ""Built"": parse_datetime(prefect.__version_info__[""date""]).strftime(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: Invalid format string

Erronous code (line 115-117):
        ""Built"": parse_datetime(prefect.__version_info__[""date""]).strftime(
            ""%a, %b %d, %Y %-I:%M %p""
        ),

This code probably works fine in Linux/Unix based systems, but not on windows. 

Possible fix:
        ""Built"": parse_datetime(prefect.__version_info__[""date""]).strftime(
            ""%a, %b %d, %Y %I:%M %p""
        ),


### Version info

```Text
Version:             3.3.1
API version:         0.8.4
Python version:      3.12.8
Git commit:          6a164620
Built:               Tue, Apr 01, 2025 02:39 AM
OS/Arch:             win32/AMD64
Profile:             ephemeral
Server type:         cloud
Pydantic version:    2.11.1
Integrations:
  prefect-azure:     0.4.3
  prefect-dbt:       0.6.6
  prefect-docker:    0.6.2
  prefect-shell:     0.3.1
```

### Additional context

_No response_",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17689/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17689
17687,Events endpoints don't require auth when PREFECT_SERVER_API_AUTH_STRING is set,closed,completed,2025-04-02T01:25:01Z,2025-04-15T20:39:13Z,2025-04-15T20:39:12Z,1,['bug'],willhcr,,NONE,"### Bug summary

Steps:

1. Set PREFECT_SERVER_API_AUTH_STRING
2. Run prefect server: `prefect server start`
3. Confirm credentials are required to view the UI or access the API
4. Run `prefect events stream`

Expected outcome:

Without setting PREFECT_API_AUTH_STRING I expect some kind of 401 error.

Actual outcome:

Displays events from the running server without authentication.

### Version info

```Text
Version:             3.2.14
API version:         0.8.4
Python version:      3.12.9
Git commit:          efcde6dc
Built:               Fri, Mar 21, 2025 5:28 PM
OS/Arch:             linux/x86_64
Profile:             ephemeral
Server type:         server
Pydantic version:    2.10.6
Integrations:
  prefect-azure:     0.4.2
```

### Additional context

It appears the API auth_string middleware only affects http and not websockets.",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17687/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17687
17686,Tag Concurrency Limits Break for Submitted Tasks from 3.2.14 -> 3.2.15,closed,completed,2025-04-01T23:40:57Z,2025-04-30T17:16:27Z,2025-04-30T17:13:59Z,8,['bug'],jonahduffin,,NONE,"### Bug summary

When upgrading from Prefect 3.2.14 to 3.2.15 and above (including the latest 3.3.1), we observed that task tag concurrency limits broke. Submitted tasks that have not yet starting executing (as they're waiting for dependent tasks defined in the `wait_for` parameter to finish) immediately consume a concurrency slot after being submitted but before beginning execution. 

This is very bad-- sometimes the concurrency slots can be filled 100% by submitted tasks that are waiting on other tasks to finish before executing, which deadlocks all tasks, as the tasks the pending ones depend on will never get a slot to execute themselves. Even if tasks can trickle through, they're throttled much more than the concurrency limit should throttle them.

MRE:
```python
import asyncio
import time

from prefect import flow, task, get_client


async def set_task_concurrency_limits_async(task_limits: dict[str, int]) -> None:
    async with get_client() as client:
        for task_tag, limit in task_limits.items():
            await client.create_concurrency_limit(tag=task_tag, concurrency_limit=limit)


@task(tags=[""mre_concurrency_limit""])
def concurrently_limited_task(seconds: int):
    time.sleep(seconds)


@flow
def concurrency_mre():
    asyncio.run(set_task_concurrency_limits_async({""mre_concurrency_limit"": 10}))

    futures = []

    prev_future = None
    for i in range(20):
        current_future = concurrently_limited_task.submit(seconds=5, wait_for=prev_future)
        futures.append(current_future)
        prev_future = current_future

    [f.wait() for f in futures]


if __name__ == ""__main__"":
    concurrency_mre()
```

This issue is not present in Prefect 3.2.14 or earlier. Upon upgrading the client (and server, but I believe the issue is client-side) to 3.2.15, this issue is produced, so I figure the issue is somewhere in here:

https://github.com/PrefectHQ/prefect/compare/3.2.14...3.2.15

### Version info

```Text
Version:             3.2.15
API version:         0.8.4
Python version:      3.10.16
Git commit:          0f5a3081
Built:               Fri, Mar 28, 2025 3:28 PM
OS/Arch:             darwin/arm64
Profile:             local
Server type:         server
Pydantic version:    2.11.0b1
Integrations:
  prefect-aws:       0.5.9
```

### Additional context

As you can see, pending tasks occupy concurrency slots for the above MRE. This is new behavior in 3.2.15 and very bad for us. We would expect to see only Running tasks in here (or Retrying, etc).

![Image](https://github.com/user-attachments/assets/43d85f4b-d647-4f2a-bd33-00ab2024f3a0)

Since tasks should execute sequentially in this MRE as seen in this dependency chart, there should only be one task occupying a concurrency slot at once.
![Image](https://github.com/user-attachments/assets/a1c8fa1f-4e64-444f-bbbd-991ffd5913cc)

In this particularly bad case, all concurrency slots were filled by pending tasks, so the tasks they depend on never got a slot to execute and all tasks with this tag were deadlocked.
![Image](https://github.com/user-attachments/assets/6a49071b-fd29-4145-9a6d-09df7278e19b)

Note that the task execution has stopped after 5 tasks, with 15 more to go, due to this deadlock
![Image](https://github.com/user-attachments/assets/466b224e-2d5b-4513-b46d-7934504abbf8)",zzstoatzz,1,https://api.github.com/repos/PrefectHQ/prefect/issues/17686/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17686
17685,"Proactive trigger ""within"" window not behaving as expected when part of compound automation",open,,2025-04-01T20:34:59Z,2025-04-01T20:43:30Z,,0,['bug'],armalite,,NONE,"### Bug summary

**Issue Summary:**

We are seeing unexpected behaviour when using a **Proactive** trigger alongside a **Reactive** trigger in a compound automation. Specifically, the **Proactive trigger's `within` window (e.g. 600s)** appears to be **enforced longer than intended**, and/or its evaluation is **inconsistent** across repeated triggering scenarios.

* * * * *

**Context:**

We emit custom events (`xos.edo.event.received`) into the Prefect event feed when specific deployments complete. Each event contains a unique `eventSourceURN` that identifies the source deployment.

We then use a compound automation to:

-   **IF** job A and job B have completed in the last 6 hours (Reactive triggers),

-   **AND** job C has *not* completed in the last 10 minutes (Proactive trigger),

-   **THEN** run job C (the automation action).

âœ… The intent of the Proactive trigger is to **suppress the automation if job C has run recently**.

See image below showing how we are expecting the automation definition to translate to the above trigger conditions and actions.

![Image](https://github.com/user-attachments/assets/36f932ba-6d75-4da8-8e39-99f0cf79e4e5)


* * * * *

**Automation Definition (simplified - contains only 1 upstream dependency):**

```json

{
  ""type"": ""compound"",
  ""triggers"": [
    {
      ""type"": ""compound"",
      ""triggers"": [
        {
          ""type"": ""event"",
          ""match"": { ""eventSourceURN"": ""urn:...:job:main-test"" },
          ""expect"": [""xos.edo.event.received""],
          ""posture"": ""Reactive"",
          ""threshold"": 1,
          ""within"": 0,
          ""for_each"": []
        }
      ],
      ""require"": ""all"",
      ""within"": 21600
    },
    {
      ""type"": ""event"",
      ""match"": { ""eventSourceURN"": ""urn:...:job:edo-test-single-dependency"" },
      ""expect"": [""xos.edo.event.received""],
      ""posture"": ""Proactive"",
      ""threshold"": 1,
      ""within"": 600
    }
  ],
  ""require"": ""all"",
  ""within"": 600
}
```

* * * * *

**Observed Behaviour:**

-   âœ… **Initial trigger works** as expected: the automation fires and runs job C after job A completes.

-   âœ… **Subsequent triggers within the 10-minute Proactive window are correctly suppressed**.

-   âŒ **Triggers beyond the 10-minute window sometimes do not fire**, even though all conditions are satisfied.

-   âŒ **Delays** of 5--10+ minutes occur between the upstream Reactive event and the automation firing, even when the Proactive trigger window has expired.

-   âŒ In some cases, it takes **20--30 minutes** before the automation retriggers, even though the Proactive `within` value is set to 600 seconds.

* * * * *

**Example Test Steps and Timeline:**
We see variation in behaviour in different testing scenarios, so we'll provide a couple examples below. Ultimately we still believe it is the proactive trigger's time bucket that is preventing the automation action being triggered, even when all criteria are met. Note there are no differences to the automation between these observation scenarios (i.e. the simplified definition shown above)

**Observation Scenario 1**
| Step | Upstream Job Run | Expected | Observed |
| --- | --- | --- | --- |
| 1 | Initial | Should run Job C | âœ… Works |
| 2 | Within 10m | Automation should be suppressed | âœ… Suppressed |
| 3 | After 10m | Should run Job C | âŒ Did **not** trigger |
| 4 | Another run after 10m | Should run Job C | âœ… ran but delayed |
| 5 | After 10m from step 4 | Should run Job C | âŒ Did **not** trigger |
| 6 | Waited and retried (>20m since last job C) | Should run Job C | âŒ Did **not** trigger |
| 7 | Waited and retried (>30m since last job C run) | Should run Job C | âœ… Job C ran |

**Observation Scenario 2**
| Step | Upstream Job Run | Expected | Observed |
| --- | --- | --- | --- |
| 1 | Initial | Should run Job C | âœ… Works |
| 2 | Within 10m | Should be suppressed | âœ… Suppressed |
| 3 | After 10m | Should run Job C | âœ… But delayed |
| 4 | Within new 10m | Should be suppressed | âœ… Suppressed |
| 5 | After 10m again | Should run Job C | âŒ Did **not** trigger |
| 6 | Waited and retried | Should run Job C | âœ… Finally triggered after further delay |

Below is a diagram showing expected behavior vs. actual behavior. It illustrates the behavior outlined in Observation 1.

![Image](https://github.com/user-attachments/assets/b446113c-7716-440b-96a6-9a2112e6d537)

* * * * *

**Suspected Cause:**

-   The Proactive trigger's `within` time may be evaluated using **time buckets** or other internal timing semantics that cause the actual enforcement window to **exceed the defined limit** (e.g. `within: 600`).

-   This leads to **false negatives**, where events outside the intended window still prevent the automation.

-   The delay in evaluation could also be due to **internal queueing or latency** in the automation processing engine, but the alignment with the Proactive window hints at a possible **implementation bug** in how Proactive triggers are evaluated.

* * * * *

**Expected Behaviour:**

-   If a Proactive trigger is configured with `within: 600`, it should only suppress the automation if a matching event occurred **within the last 600 seconds** from the evaluation time.

-   Beyond that, the trigger should be considered **satisfied**, and the automation should fire as long as all other conditions are met.

Note: The custom events are emitted whenever a flow-run of our deployments complete, and this is true regardless of how these flow-runs are started (i.e. via automation, UI, API, schedule etc.). We still expect these events to be evaluated as per the automation definition

* * * * *

Let me know if there's any additional debug output, logs, or experiments I can run to help reproduce or isolate this further. Thanks!

### Version info

```Text
Version:             2.20.16
API version:         0.8.4
Python version:      3.11.5
Git commit:          b5047953
Built:               Thu, Dec 19, 2024 10:55 AM
OS/Arch:             darwin/x86_64
Profile:             default
Server type:         cloud
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17685/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17685
17682,orion docs blocks page links redirect to v3 homepage,closed,completed,2025-04-01T18:37:09Z,2025-04-01T20:15:37Z,2025-04-01T20:15:35Z,1,['bug'],rcash,,CONTRIBUTOR,"### Bug summary

All of the 'Block'  links in the 'Blocks in Prefect integration libraries' section of https://orion-docs.prefect.io/latest/concepts/blocks/#blocks-in-prefect-integration-libraries redirect to the v3 getting started page instead of the integrations' block references for each block type. This does not appear to be an issue on https://docs-2.prefect.io/latest/concepts/blocks/#blocks-in-prefect-integration-libraries.

### Version info

```Text
N/A - latest version of orion-docs.prefect.io
```

### Additional context

_No response_",rcash,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17682/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17682
17678,Calling result() on PrefectRayFuture results in error,closed,completed,2025-04-01T15:19:40Z,2025-04-01T16:45:41Z,2025-04-01T16:45:41Z,3,['bug'],nikhil-ramanan1,,NONE,"### Bug summary

result() method throws error when called on PrefectRayFuture (flow works when RayTaskRunner is swapped out for a different one)
Observed running prefect 3.3.1

Minimum reproducible:

```
from prefect import flow, task
from prefect_ray.task_runners import RayTaskRunner


@flow(task_runner=RayTaskRunner(init_kwargs={""num_cpus"": 4}))
def test_flow():
    for x in range(10):
        my_task.submit().result()


@task
def my_task() -> None:
    print(""Hello, world!"")

if __name__ == ""__main__"":
    test_flow()
```

Trace:
```
10:14:30.478 | INFO    | Flow run 'fortunate-lynx' - Finished in state Failed(""Flow run encountered an exception: TypeError: State.result() got an unexpected keyword argument 'fetch'"")
Traceback (most recent call last):
  File ""/Users/-/src/-/-/prefect/test.py"", line 22, in <module>
    test_flow()
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/-/lib/python3.11/site-packages/prefect/flows.py"", line 1670, in __call__
    return run_flow(
           ^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/-/lib/python3.11/site-packages/prefect/flow_engine.py"", line 1527, in run_flow
    ret_val = run_flow_sync(**kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/-/lib/python3.11/site-packages/prefect/flow_engine.py"", line 1372, in run_flow_sync
    return engine.state if return_type == ""state"" else engine.result()
                                                       ^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/-/lib/python3.11/site-packages/prefect/flow_engine.py"", line 350, in result
    raise self._raised
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/-/lib/python3.11/site-packages/prefect/flow_engine.py"", line 763, in run_context
    yield self
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/-/lib/python3.11/site-packages/prefect/flow_engine.py"", line 1370, in run_flow_sync
    engine.call_flow_fn()
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/-/lib/python3.11/site-packages/prefect/flow_engine.py"", line 783, in call_flow_fn
    result = call_with_parameters(self.flow.fn, self.parameters)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/-/lib/python3.11/site-packages/prefect/utilities/callables.py"", line 210, in call_with_parameters
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File ""/Users/-/src/-/-/prefect/test.py"", line 14, in test_flow
    my_task.submit().result()
                  ^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/-/lib/python3.11/site-packages/prefect_ray/task_runners.py"", line 144, in result
    _result = self._final_state.result(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/-/lib/python3.11/site-packages/prefect/_internal/compatibility/async_dispatch.py"", line 94, in wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
TypeError: State.result() got an unexpected keyword argument 'fetch'
```

### Version info

```Text
Version:             3.3.1
API version:         0.8.4
Python version:      3.11.11
Git commit:          6a164620
Built:               Tue, Apr 01, 2025 2:39 AM
OS/Arch:             darwin/arm64
Profile:             local
Server type:         ephemeral
Pydantic version:    2.10.6
Server:
  Database:          sqlite
  SQLite version:    3.45.3
Integrations:
  prefect-dask:      0.3.2
  prefect-ray:       0.4.3
```

### Additional context

_No response_",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17678/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17678
17676,`No lock held by` on transaction commit,closed,completed,2025-04-01T14:19:59Z,2025-04-04T09:11:59Z,2025-04-03T03:23:21Z,3,['bug'],acrrd,,NONE,"### Bug summary

With the following code I get
```
File ""/opt/conda/envs/prefect/lib/python3.12/contextlib.py"", line 144, in __exit__
  next(self.gen)
File ""/opt/conda/envs/prefect/lib/python3.12/site-packages/prefect/transactions.py"", line 461, in transaction
  with Transaction(
       ^^^^^^^^^^^^
File ""/opt/conda/envs/prefect/lib/python3.12/site-packages/prefect/transactions.py"", line 234, in __exit__
  self.commit()
File ""/opt/conda/envs/prefect/lib/python3.12/site-packages/prefect/transactions.py"", line 298, in commit
  self.store.release_lock(self.key)
File ""/opt/conda/envs/prefect/lib/python3.12/site-packages/prefect/results.py"", line 928, in release_lock
  return self.lock_manager.release_lock(key, holder)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
File ""/opt/conda/envs/prefect/lib/python3.12/site-packages/prefect_redis/locking.py"", line 134, in release_lock
  raise ValueError(f""No lock held by {holder} for transaction with key {key}"")
ValueError: No lock held by 60dfb6b1d1a5:105:140212168873664:RunSyncEventLoopThread for transaction with key pipeline
```
This happens when `can_fail` fails and then succeeds on a retry. If `can_fail` never fail the error doesn't present itself.

```python
@flow(log_prints=True)
async def pipeline():
    db_block = await RedisDatabase.load(""db"")
    lock_manager = RedisLockManager(
        **{
            k: v
            for (k, v) in db_block.as_connection_params().items()
            if not k.startswith(""_"")
        }
    )

    transaction_key = f""pipeline""
    with transaction(
        key=transaction_key,
        isolation_level=IsolationLevel.SERIALIZABLE,
        store=ResultStore(lock_manager=lock_manager),
    ) as txn:
        await can_fail()
@task(retries=10)
async def can_fail():
    import random
    if random.random() < 0.5:
        raise Exception(""Failed, please retry"")
```


### Version info

```Text
Version:             3.2.15
API version:         0.8.4
Python version:      3.13.2
Git commit:          0f5a3081
Built:               Fri, Mar 28, 2025 3:28 PM
OS/Arch:             linux/x86_64
Profile:             local
Server type:         server
Pydantic version:    2.11.0

Server and worker are running on prefecthq/prefect:3.2.15-python3.12-conda
```

### Additional context

_No response_",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17676/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17676
17674,PREFECT_LOGGING_LOGGERS_PREFECT_FLOW_RUNS_LEVEL not working,open,,2025-04-01T13:42:09Z,2025-04-03T14:56:40Z,,1,['bug'],abhisheksingh94,,NONE,"### Bug summary

As per https://docs-3.prefect.io/v3/develop/logging
prefect config set PREFECT_LOGGING_LOGGERS_PREFECT_FLOW_RUNS_LEVEL=""ERROR""

above should work but its giving me error :
Unknown setting name 'PREFECT_LOGGING_LOGGERS_PREFECT_FLOW_RUNS_LEVEL'.

### Version info

```Text
Version:             3.3.1
API version:         0.8.4
Python version:      3.9.21
Git commit:          6a164620
Built:               Tue, Apr 01, 2025 2:39 AM
OS/Arch:             linux/x86_64
Profile:             ephemeral
Server type:         server
Pydantic version:    2.11.0
Integrations:
  prefect-aws:       0.5.9
  prefect-slack:     0.3.1
  prefect-shell:     0.3.1
  prefect-github:    0.3.1
  prefect-docker:    0.6.2
  prefect-sqlalchemy: 0.5.2
  prefect-email:     0.4.1
  prefect-gcp:       0.6.5
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17674/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17674
17673,With DaskTaskRunner a CommClosedError is thrown at end of flow,open,,2025-04-01T09:01:32Z,2025-04-07T12:26:02Z,,2,['bug'],derkjan12,,NONE,"### Bug summary

When using the DaskTaskRunner I often (but not always) get a CommClosedError at the end of a flow run even though the whole flow itself run well. Using the ThreadPoolTaskRunner the error does not occur. 

```python
import time
from pathlib import Path
from prefect import flow, task
from prefect.futures import wait
from prefect.task_runners import ThreadPoolTaskRunner
from prefect_dask import DaskTaskRunner



@task()
def load_first(data_path: Path):
    a = 1 + 2


@task()
def load_second(data_path: Path):
    b = 2 + 3


@task()
def load_third():
    time.sleep(10)



@task()
def combine(data_path: Path) -> bool:
    return False


@task()
def other_task(a: int) -> int:
    return a+8


@flow(name='main_flow', log_prints=True,
      task_runner=DaskTaskRunner(cluster_kwargs={'n_workers': 6})) #ThreadPoolTaskRunner(max_workers=3)
def main_flow2(
        data_path: Path,
):
    first_result = load_first.submit(data_path)
    second_result = load_second.submit(data_path, wait_for=[first_result])
    third_result = load_third.submit(wait_for=[first_result])
    combine_result = combine.submit(data_path, wait_for=[second_result, third_result])

    other_result = other_task.submit(8, wait_for=[second_result])
    wait([first_result, second_result, third_result, other_result, combine_result])


if __name__ == '__main__':
    data_path = Path('.')
    main_flow2(data_path)
```

Generates the error at the end of the flow:

```
Traceback (most recent call last):
  File ""C:\Users\Derk-Jan\_virtualenvs\kenmerkenmodel\Lib\site-packages\distributed\batched.py"", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File ""C:\Users\Derk-Jan\_virtualenvs\kenmerkenmodel\Lib\site-packages\tornado\gen.py"", line 766, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File ""C:\Users\Derk-Jan\_virtualenvs\kenmerkenmodel\Lib\site-packages\distributed\comm\tcp.py"", line 262, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
```

### Version info

```Text
Version:             3.2.15
API version:         0.8.4
Python version:      3.12.7
Git commit:          0f5a3081
Built:               Fri, Mar 28, 2025 3:28 PM
OS/Arch:             win32/AMD64
Profile:             ephemeral
Server type:         server
Pydantic version:    2.11.1
Integrations:
  prefect-dask:      0.3.3
  prefect-sqlalchemy: 0.5.1
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17673/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17673
17672,Wrong default value for day_or parameter in Cron schedule.,closed,completed,2025-04-01T08:18:18Z,2025-04-02T13:21:40Z,2025-04-02T13:21:40Z,0,['bug'],vyagubov,desertaxle,CONTRIBUTOR,"### Bug summary

Documentation says:
```text
Cron properties include:

Property	Description
cron	A valid cron string. (Required)
day_or	Boolean indicating how croniter handles day and day_of_week entries. Default is True.
timezone	String name of a time zone. (See the IANA Time Zone Database for valid time zones.)
```
important here is `Default is True.`

Then if we look at 
https://github.com/PrefectHQ/prefect/blob/main/src/prefect/schedules.py line 76 we can see:
```python
def Cron(
    cron: str,
    /,
    timezone: str | None = None,
    day_or: bool = False,
    active: bool = True,
    parameters: dict[str, Any] | None = None,
    slug: str | None = None,
) -> Schedule:
```
It does opposite in the code, day_or has False as default value. That is why, for instance, ""00 15 1 * 1"" will not run as expected.
By default, croniter also has day_or = True as default:
```
$ pip freeze | grep croniter
croniter==6.0.0
$ python
Python 3.10.7 (main, Dec  6 2024, 12:32:27) [Clang 16.0.0 (clang-1600.0.26.4)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> from croniter import croniter
>>> from datetime import datetime
>>> 
>>> # Problematic cron expression
>>> cron_expression = ""00 15 1 * 1""
>>> base_time = datetime(2025, 3, 31, 15, 0)  # Base time: Monday, March 31, 2025
>>> 
>>> # Get the next 5 occurrences
>>> cron = croniter(cron_expression, base_time)
>>> next_runs = [cron.get_next(datetime) for _ in range(5)]
>>> 
>>> print(next_runs)
[datetime.datetime(2025, 4, 1, 15, 0), datetime.datetime(2025, 4, 7, 15, 0), datetime.datetime(2025, 4, 14, 15, 0), datetime.datetime(2025, 4, 21, 15, 0), datetime.datetime(2025, 4, 28, 15, 0)]
```

Of course, we can overwrite that parameter and everything will work as we expect. That is why the issue is not critical. However, I spent 1 hour to find a reason why one of my Flows didn't start at the expected time (so good that we noticed the issue).

### Version info

```Text
Version: 3.2.7
```

### Additional context

_No response_",desertaxle,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17672/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17672
17656,`on_rollback` runs in async context if failing task is async,open,,2025-03-31T11:11:44Z,2025-03-31T13:06:54Z,,1,['bug'],acrrd,,NONE,"### Bug summary

In the following code, in the `del_file` function, the `RedisDatabase.load` resolves to a corountine even if the function is not async.
Error:
```
     db = db_block.get_client()
          ^^^^^^^^^^^^^^^^^^^
AttributeError: 'coroutine' object has no attribute 'get_client'
```

This seems to depend on task that failed. If you modify `quality_test` to be sync than `del_file` executes correctly.
The behaviour had the surprising side effect that the rollback is working  when sync `quality_test` was used to make the flow fail, while it's failing if you inline the code of `quality_test` in the flow itself because `pipeline` is async.

```python
@task
def write_file(contents: str):
     print(""Writes to a file."")
     with open(""side-effect.txt"", ""w"") as f:
         f.write(contents)

@write_file.on_rollback
def del_file(transaction):
     print(""Deletes file."")
     db_block = RedisDatabase.load(""valkey-db-main"")
     db = db_block.get_client()
     db.incr(""ON_ROLLBACK_DEL_FILE"")

     os.unlink(""side-effect.txt"")

@task
async def quality_test():
     print(""Checks contents of file."")
     with open(""side-effect.txt"", ""r"") as f:
         data = f.readlines()

     if len(data) < 2:
         raise ValueError(""Not enough data!"")


@flow(log_prints=True)
async def pipeline(contents: str):
     with transaction():
         write_file(contents)
         sleep(2)  # sleeping to give you a chance to see the file
         await quality_test()
```

### Version info

```Text
Version:             3.2.15
API version:         0.8.4
Python version:      3.13.2
Git commit:          0f5a3081
Built:               Fri, Mar 28, 2025 3:28 PM
OS/Arch:             linux/x86_64
Profile:             local
Server type:         server
Pydantic version:    2.11.0

Server and worker are running on prefecthq/prefect:3.2.15-python3.12-conda
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17656/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17656
17649,Regression: parameter inspection for method as task fails when called more than once in DaskTaskRunner,closed,completed,2025-03-30T10:45:38Z,2025-03-31T15:48:12Z,2025-03-31T15:32:34Z,4,['bug'],athrpf,desertaxle,NONE,"### Bug summary

Minimum reproducing example:
```
from prefect import task, flow
from prefect_dask.task_runners import DaskTaskRunner
from prefect.task_runners import ConcurrentTaskRunner


class FlowData:
    def __init__(self, d: dict[str, str]):
        self.d = d

    @task()
    def my_task(self, key: str):
        return self.d[key]


def my_flow():
    d = {""a"": ""b"", 'c': 'd'}
    fd = FlowData(d)
    f1 = fd.my_task.submit(""a"")
    f2 = fd.my_task.submit(""c"")
    f1.wait()
    f2.wait()


my_sequential_flow = flow()(my_flow)
my_concurrent_flow = flow(task_runner=ConcurrentTaskRunner())(my_flow)
my_dask_flow = flow(task_runner=DaskTaskRunner(cluster_kwargs={""n_workers"": 1}))(my_flow)

if __name__ == ""__main__"":
    my_sequential_flow()  # works
    my_concurrent_flow()  # works
    my_dask_flow()  # fails
```
Running on `main`, this fails with
```
prefect.exceptions.ParameterBindError: Error binding parameters for function 'my_task': too many positional arguments.
Function 'my_task' has signature 'self, key: str' but received args: (<class '__main__.FlowData'>, <__main__.FlowData object at 0x7ff89df32610>, 'c') and kwargs: [].
```

but works on 3.2.9.

Note
- this only fails with the `DaskTaskRunner`, but works for `SequentialTaskRunner`, `ConcurrentTaskRunner`, and `RayTaskRunner`
- It only fails on the *second* run of the method, but not on the first

`git-bisect` tells me that the regression was introduced in 

```
commit 4a9dba70ca15f3b4b9006fd375db8bd2601d0a86
Author: Alex Streed <desertaxle@users.noreply.github.com>
Date:   Mon Mar 24 16:33:04 2025 -0500

    Fix `@classmethod` and `@staticmethod` flows and tasks for Python 3.13 (#17583)
```
which makes sense given what looks like an extra ` error message.


### Version info

```Text
Version:             3.2.9+159.g1ce81e123
API version:         0.8.4
Python version:      3.11.7
Git commit:          1ce81e12
Built:               Sun, Mar 30, 2025 10:18 AM
OS/Arch:             linux/x86_64
Profile:             prefect3
Server type:         server
Pydantic version:    2.11.1
Integrations:
  prefect-dask:      0.1.dev18895+g1ce81e1
```

### Additional context

_No response_",desertaxle,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17649/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17649
17646,"Trigger Form in Automations UI misbehaves when ""number of times"" is set to 1",open,,2025-03-29T22:38:56Z,2025-04-03T14:52:49Z,,0,"['bug', 'ui']",Pushpavel,,NONE,"### Bug summary

In custom trigger template of Automations page, when I set number of times to 1, the form suddenly resets to ""Flow run state"" trigger template and also could not select custom trigger template from the dropdown again.

### Version info

```Text
Version:             3.2.15
API version:         0.8.4
Python version:      3.12.9
Git commit:          0f5a3081
Built:               Fri, Mar 28, 2025 3:28 PM
OS/Arch:             linux/x86_64
Profile:             local
Server type:         server
Pydantic version:    2.11.1
```

### Additional context

https://github.com/user-attachments/assets/638f0eb2-7fbf-4f25-857e-5aea9804ba5a",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17646/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17646
17645,Ui files need to be writeable,closed,completed,2025-03-29T12:59:57Z,2025-03-31T14:14:07Z,2025-03-31T14:14:07Z,0,['bug'],happysalada,,CONTRIBUTOR,"### Bug summary

The ui files copied over need to be writeable not only readable.
The file permissions are correctly changed, but only to readable.
The code includes a rmtree which means the files need to be writeable.

### Version info

```Text
3.2.14
```

### Additional context

This is encountered in the packaging of prefect for nixos

the exact log output is

```
{""_SYSTEMD_UNIT"":""prefect-server.service"",""level"":""info"",""message"":""An exception occurred.""}
	
	
2025-03-29 08:34:35.404	
{""_SYSTEMD_UNIT"":""prefect-server.service"",""level"":""info"",""message"":""  File \""/nix/store/bq3v0vgi1z0yjkdbci7n6hj31l1syvr2-prefect-3.2.14/lib/python3.12/site-packages/prefect/server/api/server.py\"", line 251, in copy_directory""}
	
	
2025-03-29 08:34:35.404	
{""_SYSTEMD_UNIT"":""prefect-server.service"",""level"":""info"",""message"":""PermissionError: [Errno 13] Permission denied: '/var/lib/prefect-server/ico'""}
	
	
2025-03-29 08:34:35.404	
{""_SYSTEMD_UNIT"":""prefect-server.service"",""level"":""info"",""message"":""    os.unlink(entry.name, dir_fd=topfd)""}
	
	
2025-03-29 08:34:35.404	
{""_SYSTEMD_UNIT"":""prefect-server.service"",""level"":""info"",""message"":""  File \""/nix/store/f2krmq3iv5nibcvn4rw7nrnrciqprdkh-python3-3.12.9/lib/python3.12/shutil.py\"", line 698, in _rmtree_safe_fd""}
	
	
2025-03-29 08:34:35.404	
{""_SYSTEMD_UNIT"":""prefect-server.service"",""level"":""info"",""message"":""  File \""/nix/store/f2krmq3iv5nibcvn4rw7nrnrciqprdkh-python3-3.12.9/lib/python3.12/shutil.py\"", line 700, in _rmtree_safe_fd""}
	
	
2025-03-29 08:34:35.404	
{""_SYSTEMD_UNIT"":""prefect-server.service"",""level"":""info"",""message"":""  File \""/nix/store/f2krmq3iv5nibcvn4rw7nrnrciqprdkh-python3-3.12.9/lib/python3.12/shutil.py\"", line 703, in _rmtree_safe_fd""}
	
	
2025-03-29 08:34:35.404	
{""_SYSTEMD_UNIT"":""prefect-server.service"",""level"":""info"",""message"":""    _rmtree_safe_fd(stack, onexc)""}
	
	
2025-03-29 08:34:35.404	
{""_SYSTEMD_UNIT"":""prefect-server.service"",""level"":""info"",""message"":""  File \""/nix/store/f2krmq3iv5nibcvn4rw7nrnrciqprdkh-python3-3.12.9/lib/python3.12/shutil.py\"", line 759, in rmtree""}
	
	
2025-03-29 08:34:35.404	
{""_SYSTEMD_UNIT"":""prefect-server.service"",""level"":""info"",""message"":""    shutil.rmtree(destination)""}
	
	
2025-03-29 08:34:35.404	
{""_SYSTEMD_UNIT"":""prefect-server.service"",""level"":""info"",""message"":""    onexc(func, path, err)""}
	
	
2025-03-29 08:34:35.404	
{""_SYSTEMD_UNIT"":""prefect-server.service"",""level"":""info"",""message"":""    onexc(os.unlink, fullname, err)""}
	
	
2025-03-29 08:34:35.404	
{""_SYSTEMD_UNIT"":""prefect-server.service"",""level"":""info"",""message"":""           ^^^^^^^^^^^^^^^^^^^""}
	
	
2025-03-29 08:34:35.404	
{""_SYSTEMD_UNIT"":""prefect-server.service"",""level"":""info"",""message"":""  File \""/nix/store/bq3v0vgi1z0yjkdbci7n6hj31l1syvr2-prefect-3.2.14/lib/python3.12/site-packages/prefect/server/api/server.py\"", line 454, in create_ui_static_subpath""}
	
	
2025-03-29 08:34:35.404	
{""_SYSTEMD_UNIT"":""prefect-server.service"",""level"":""info"",""message"":""    create_ui_static_subpath()""}
	
	
2025-03-29 08:34:35.404	
{""_SYSTEMD_UNIT"":""prefect-server.service"",""level"":""info"",""message"":""  File \""/nix/store/bq3v0vgi1z0yjkdbci7n6hj31l1syvr2-prefect-3.2.14/lib/python3.12/site-packages/prefect/server/api/server.py\"", line 477, in create_ui_app""}
	
	
2025-03-29 08:34:35.404	
{""_SYSTEMD_UNIT"":""prefect-server.service"",""level"":""info"",""message"":""             ^^^^^^^^^^^^^^^^^^^^^^^^""}
	
	
2025-03-29 08:34:35.404	
{""_SYSTEMD_UNIT"":""prefect-server.service"",""level"":""info"",""message"":""  File \""/nix/store/bq3v0vgi1z0yjkdbci7n6hj31l1syvr2-prefect-3.2.14/lib/python3.12/site-packages/prefect/cli/_utilities.py\"", line 44, in wrapper""}
	
	
2025-03-29 08:34:35.404	
{""_SYSTEMD_UNIT"":""prefect-server.service"",""level"":""info"",""message"":""    return fn(*args, **kwargs)""}
	
	
2025-03-29 08:34:35.404	
{""_SYSTEMD_UNIT"":""prefect-server.service"",""level"":""info"",""message"":""        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^""}
	
	
2025-03-29 08:34:35.404	
{""_SYSTEMD_UNIT"":""prefect-server.service"",""level"":""info"",""message"":""    app=create_app(final=True, webserver_only=no_services),""}
```",cicdw,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17645/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17645
17643,Pydantic version no longer compatible...,closed,not_planned,2025-03-29T00:46:21Z,2025-03-31T16:01:05Z,2025-03-31T16:00:38Z,4,['bug'],Bryan-Meier,,NONE,"### Bug summary

Pydantic just released version 2.11.1, which from what I can tell breaks every version of Prefect since at least 3.0. This appears to be caused by the Prefect package not pinning the Pydantic version and leaving a range to include any new version up to 3.0 which many of those have not even been released yet. This leaves Prefect vulnerable to Pydantic breaking changes and this appears to be the issue.

You can replicate this by installing any version of Prefect 3.x and trying to run a simple flow.

The error when upon running a flow is this:
```
Traceback (most recent call last):
  File ""c:\src\Python\Prefect\dw_prefect_mainframestaging\main.py"", line 1, in <module>
    from prefect import flow, task
  File ""<frozen importlib._bootstrap>"", line 1229, in _handle_fromlist
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\prefect\__init__.py"", line 113, in __getattr__
    module = importlib.import_module(mname, package=package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\apps\Python3.11.7\Lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\prefect\main.py"", line 34, in <module>
    prefect.context.FlowRunContext.model_rebuild(_types_namespace=_types)
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\main.py"", line 650, in model_rebuild
    return _model_construction.complete_model_class(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_model_construction.py"", line 597, in complete_model_class
    schema = gen_schema.generate_schema(cls)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 699, in generate_schema
    schema = self._generate_schema_inner(obj)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 977, in _generate_schema_inner
    return self._model_schema(obj)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 810, in _model_schema
    {k: self._generate_md_field_schema(k, v, decorators) for k, v in fields.items()},
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 810, in <dictcomp>
    {k: self._generate_md_field_schema(k, v, decorators) for k, v in fields.items()},
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 1179, in _generate_md_field_schema
    common_field = self._common_field_schema(name, field_info, decorators)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 1345, in _common_field_schema
    schema = self._apply_annotations(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 2257, in _apply_annotations
    schema = get_inner_schema(source_type)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_schema_generation_shared.py"", line 83, in __call__
    schema = self._handler(source_type)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 2239, in inner_handler
    schema = self._generate_schema_inner(obj)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 982, in _generate_schema_inner
    return self.match_type(obj)
           ^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 1096, in match_type
    return self._match_generic_type(obj, origin)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 1119, in _match_generic_type
    return self._union_schema(obj)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 1407, in _union_schema
    choices.append(self.generate_schema(arg))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 699, in generate_schema
    schema = self._generate_schema_inner(obj)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 977, in _generate_schema_inner
    return self._model_schema(obj)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 810, in _model_schema
    {k: self._generate_md_field_schema(k, v, decorators) for k, v in fields.items()},
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 810, in <dictcomp>
    {k: self._generate_md_field_schema(k, v, decorators) for k, v in fields.items()},
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 1179, in _generate_md_field_schema
    common_field = self._common_field_schema(name, field_info, decorators)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 1345, in _common_field_schema
    schema = self._apply_annotations(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 2257, in _apply_annotations
    schema = get_inner_schema(source_type)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_schema_generation_shared.py"", line 83, in __call__
    schema = self._handler(source_type)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 2239, in inner_handler
    schema = self._generate_schema_inner(obj)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 982, in _generate_schema_inner
    return self.match_type(obj)
           ^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 1096, in match_type
    return self._match_generic_type(obj, origin)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 1119, in _match_generic_type
    return self._union_schema(obj)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 1407, in _union_schema
    choices.append(self.generate_schema(arg))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 699, in generate_schema
    schema = self._generate_schema_inner(obj)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 977, in _generate_schema_inner
    return self._model_schema(obj)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 810, in _model_schema
    {k: self._generate_md_field_schema(k, v, decorators) for k, v in fields.items()},
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 810, in <dictcomp>
    {k: self._generate_md_field_schema(k, v, decorators) for k, v in fields.items()},
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 1179, in _generate_md_field_schema
    common_field = self._common_field_schema(name, field_info, decorators)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 1345, in _common_field_schema
    schema = self._apply_annotations(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 2257, in _apply_annotations
    schema = get_inner_schema(source_type)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_schema_generation_shared.py"", line 83, in __call__
    schema = self._handler(source_type)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\_internal\_generate_schema.py"", line 2331, in new_handler
    schema = annotation_get_schema(source, get_inner_schema)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\types.py"", line 3077, in __get_pydantic_core_schema__
    return self._convert_schema(original_schema)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\src\Python\Prefect\dw_prefect_mainframestaging\.env\Lib\site-packages\pydantic\types.py"", line 3096, in _convert_schema
    raise PydanticUserError(
pydantic.errors.PydanticUserError: `Tag` not provided for choice {'type': 'tagged-union', 'choices': {'ResultRecordMetadata': {'type': 'definition-ref', 'schema_ref': 'prefect.results.ResultRecordMetadata:2619901542688', 'metadata': {'pydantic_internal_union_tag_key': 'ResultRecordMetadata'}}, 'Any': {'type': 'any', 'metadata': {'pydantic_internal_union_tag_key': 'Any'}}}, 'discriminator': <function data_discriminator at 0x00000261FE099620>} used with `Discriminator`

For further information visit https://errors.pydantic.dev/2.11/u/callable-discriminator-no-tag
```

### Version info

```Text
Prefect 3.1.15
Python 3.11.7
```

### Additional context

_No response_",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17643/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17643
17637,async `on_rollback` is not supported,closed,completed,2025-03-28T17:21:49Z,2025-04-14T22:34:07Z,2025-04-14T22:32:02Z,4,['enhancement'],acrrd,,NONE,"### Bug summary

If I have an async rollback hook for a function it is not called when the transaction fails.

```python
@task
async def write_file(contents: str):
    print(""Writes to a file."")
    with open(""side-effect.txt"", ""w"") as f:
        f.write(contents)


@write_file.on_rollback
async def del_file(transaction):
    print(""Deletes file."")
    # write to redis here
    os.unlink(""side-effect.txt"")


@task
async def quality_test():
    ""Checks contents of file.""
    with open(""side-effect.txt"", ""r"") as f:
        data = f.readlines()

    if len(data) < 2:
        raise ValueError(""Not enough data!"")


@flow
async def pipeline(contents: str):
    with transaction():
        await write_file(contents)
        sleep(2) # sleeping to give you a chance to see the file
        await quality_test()
```

I also verified this by inserting a write to a redis server. Nothing is written.
Are async hook not supported or I need to use something else to make it work?

(edited by maintainer): we can eventually add support for this

### Version info

```Text
Version:             3.2.15
API version:         0.8.4
Python version:      3.13.2
Git commit:          0f5a3081
Built:               Fri, Mar 28, 2025 3:28 PM
OS/Arch:             linux/x86_64
Profile:             local
Server type:         server
Pydantic version:    2.11.0

Server and worker are running on prefecthq/prefect:3.2.15-python3.12-conda
```

### Additional context

_No response_",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17637/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17637
17634,prefect-dbt run_dbt_cloud_job fails when targeted_retries is set to zero,closed,completed,2025-03-28T17:05:38Z,2025-03-31T17:22:22Z,2025-03-31T17:22:22Z,0,['bug'],rcash,,CONTRIBUTOR,"### Bug summary

When using `prefect-dbt`'s `run_dbt_cloud_job` with targeted_retries set to 0, the method immediately fails instead of awaiting for the cloud job run to complete. relevant code snippet: https://github.com/PrefectHQ/prefect/blob/main/src/integrations/prefect-dbt/prefect_dbt/cloud/jobs.py#L1124

MRE:
```
from prefect import flow, task
from prefect.logging import get_run_logger

from prefect_dbt.cloud import DbtCloudJob
from prefect_dbt.cloud.jobs import run_dbt_cloud_job

@task(retries=1, retry_delay_seconds=30)
async def trigger_dbt_job(dbt_job_block_name: str, retries: int = 1):

    logger = get_run_logger()
    try:
        result = await run_dbt_cloud_job(
            dbt_cloud_job = await DbtCloudJob.load(dbt_job_block_name),
            targeted_retries=0
        )

 

        return result
    except Exception as e:
        logger.error(f""dbt Cloud job execution failed: {e}"")
        raise
```

exception:
```
08:17:59.393 | ERROR   | Flow run 'elated-nyala' - Encountered exception during execution: DbtCloudJobRunFailed('dbt Cloud job 15880233 failed after 0 retries.')       
Traceback (most recent call last):
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1335, in run_context
    yield self
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1397, in run_flow_async
    await engine.call_flow_fn()
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1349, in call_flow_fn
    result = await call_with_parameters(self.flow.fn, self.parameters)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect_dbt\cloud\jobs.py"", line 1135, in run_dbt_cloud_job
    raise DbtCloudJobRunFailed(
prefect_dbt.cloud.exceptions.DbtCloudJobRunFailed: dbt Cloud job 15880233 failed after 0 retries.
08:17:59.656 | ERROR   | Flow run 'elated-nyala' - Finished in state Failed('Flow run encountered an exception: DbtCloudJobRunFailed: dbt Cloud job 15880233 failed after 0 retries.')
08:17:59.656 | ERROR   | Flow run 'carmine-jackdaw' - dbt Cloud job execution failed: dbt Cloud job 15880233 failed after 0 retries.
08:17:59.656 | ERROR   | Flow run 'carmine-jackdaw' - Encountered exception during execution: DbtCloudJobRunFailed('dbt Cloud job 15880233 failed after 0 retries.')    
Traceback (most recent call last):
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1335, in run_context
    yield self
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1397, in run_flow_async
    await engine.call_flow_fn()
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1349, in call_flow_fn
    result = await call_with_parameters(self.flow.fn, self.parameters)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\mahorg6\Documents\misc\prefect\easy_flow.py"", line 94, in trigger_dbt_job
    result = await run_dbt_cloud_job(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1399, in run_flow_async
    return engine.state if return_type == ""state"" else await engine.result()        
                                                       ^^^^^^^^^^^^^^^^^^^^^        
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 917, in result
    raise self._raised
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1335, in run_context
    yield self
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1397, in run_flow_async
    await engine.call_flow_fn()
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1349, in call_flow_fn
    result = await call_with_parameters(self.flow.fn, self.parameters)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect_dbt\cloud\jobs.py"", line 1135, in run_dbt_cloud_job
    raise DbtCloudJobRunFailed(
prefect_dbt.cloud.exceptions.DbtCloudJobRunFailed: dbt Cloud job 15880233 failed after 0 retries.
08:17:59.910 | ERROR   | Flow run 'carmine-jackdaw' - Finished in state Failed('Flow run encountered an exception: DbtCloudJobRunFailed: dbt Cloud job 15880233 failed after 0 retries.')
08:17:59.912 | ERROR   | Flow run 'cinnamon-mink' - Encountered exception during execution: DbtCloudJobRunFailed('dbt Cloud job 15880233 failed after 0 retries.')      
Traceback (most recent call last):
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1335, in run_context
    yield self
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1397, in run_flow_async
    await engine.call_flow_fn()
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1349, in call_flow_fn
    result = await call_with_parameters(self.flow.fn, self.parameters)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\mahorg6\Documents\misc\prefect\easy_flow.py"", line 120, in easy_flow
    dbt_result = await trigger_dbt_job(dbt_job_block_name=config[""dbt_job_block_name""])
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1399, in run_flow_async
    return engine.state if return_type == ""state"" else await engine.result()        
                                                       ^^^^^^^^^^^^^^^^^^^^^        
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 917, in result
    raise self._raised
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1335, in run_context
    yield self
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1397, in run_flow_async
    await engine.call_flow_fn()
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1349, in call_flow_fn
    result = await call_with_parameters(self.flow.fn, self.parameters)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\mahorg6\Documents\misc\prefect\easy_flow.py"", line 94, in trigger_dbt_job
    result = await run_dbt_cloud_job(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1399, in run_flow_async
    return engine.state if return_type == ""state"" else await engine.result()        
                                                       ^^^^^^^^^^^^^^^^^^^^^        
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 917, in result
    raise self._raised
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1335, in run_context
    yield self
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1397, in run_flow_async
    await engine.call_flow_fn()
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1349, in call_flow_fn
    result = await call_with_parameters(self.flow.fn, self.parameters)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect_dbt\cloud\jobs.py"", line 1135, in run_dbt_cloud_job
    raise DbtCloudJobRunFailed(
prefect_dbt.cloud.exceptions.DbtCloudJobRunFailed: dbt Cloud job 15880233 failed after 0 retries.
08:18:00.941 | ERROR   | Flow run 'cinnamon-mink' - Finished in state Failed('Flow run encountered an exception: DbtCloudJobRunFailed: dbt Cloud job 15880233 failed after 0 retries.')
Traceback (most recent call last):
  File ""C:\Users\mahorg6\Documents\misc\prefect\easy_flow.py"", line 134, in <module>
    asyncio.run(easy_flow(config))
  File ""C:\Users\mahorg6\AppData\Local\Programs\Python\Python311\Lib\asyncio\runners.py"", line 190, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File ""C:\Users\mahorg6\AppData\Local\Programs\Python\Python311\Lib\asyncio\runners.py"", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\mahorg6\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py"", line 650, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1399, in run_flow_async
    return engine.state if return_type == ""state"" else await engine.result()        
                                                       ^^^^^^^^^^^^^^^^^^^^^        
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 917, in result
    raise self._raised
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1335, in run_context
    yield self
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1397, in run_flow_async
    await engine.call_flow_fn()
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1349, in call_flow_fn
    result = await call_with_parameters(self.flow.fn, self.parameters)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\mahorg6\Documents\misc\prefect\easy_flow.py"", line 120, in easy_flow
    dbt_result = await trigger_dbt_job(dbt_job_block_name=config[""dbt_job_block_name""])
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1399, in run_flow_async
    return engine.state if return_type == ""state"" else await engine.result()        
                                                       ^^^^^^^^^^^^^^^^^^^^^        
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 917, in result
    raise self._raised
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1335, in run_context
    yield self
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1397, in run_flow_async
    await engine.call_flow_fn()
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1349, in call_flow_fn
    result = await call_with_parameters(self.flow.fn, self.parameters)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\mahorg6\Documents\misc\prefect\easy_flow.py"", line 94, in trigger_dbt_job
    result = await run_dbt_cloud_job(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1399, in run_flow_async
    return engine.state if return_type == ""state"" else await engine.result()        
                                                       ^^^^^^^^^^^^^^^^^^^^^        
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 917, in result
    raise self._raised
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1335, in run_context
    yield self
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1397, in run_flow_async
    await engine.call_flow_fn()
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect\flow_engine.py"", line 1349, in call_flow_fn
    result = await call_with_parameters(self.flow.fn, self.parameters)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect_dbt\cloud\jobs.py"", line 1135, in run_dbt_cloud_job
    raise DbtCloudJobRunFailed(
prefect_dbt.cloud.exceptions.DbtCloudJobRunFailed: dbt Cloud job 15880233 failed after 0 retries.
```


### Version info

```Text
prefect-dbt 0.6.6
prefect 3.2.13
```

### Additional context

_No response_",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17634/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17634
17633,"python path does not include ""/app"" in the on_cancellation callback",open,,2025-03-28T16:56:23Z,2025-03-28T17:51:34Z,,2,['bug'],yesheneve,,NONE,"### Bug summary

Our Prefect is hosted on ECS. There is a base image for the Prefect Infrastructure. When we build service, the service image will be built by first pulling the base image. Everything is working well, but when the on_cancellation hook is triggered, it complains that the code from the base image cannot be found. Our work around is to add this line to the base image Dockerfile `ENV PYTHONPATH=""${PYTHONPATH:-}/app""`.

We could verify that the path does not include ""/app"" in the callback.  it looks like prefect starts a new python thread with a different entrypoint so it has no idea about app folder.

### Version info

```Text
Version:             3.2.12
API version:         0.8.4
Python version:      3.11.11
Git commit:          826eb1a7
Built:               Mon, Mar 10, 2025 4:36 PM
OS/Arch:             linux/x86_64
Profile:             ephemeral
Server type:         ephemeral
Pydantic version:    2.10.6
Server:
  Database:          sqlite
  SQLite version:    3.40.0
Integrations:
  prefect-aws:       0.5.6
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17633/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17633
17631,Unnecessary `getattr` call in `utilities.collections::visit_collection` fails when a `BaseModel` overloads `__getattribute__`,closed,completed,2025-03-28T14:24:52Z,2025-03-28T17:43:22Z,2025-03-28T17:42:28Z,2,"['bug', 'great writeup']",athrpf,,NONE,"### Bug summary

The Issue
-----

I am passing around `pydantic.BaseModel` objects between my tasks. These basemodels hide a lazily evaluated object behind a `__getattribute__` call. If I pass them around this fails in a very unpredictable way.

A minimal example to reproduce the problem:

```
import numpy as np
from prefect import task, flow
from pydantic import BaseModel

shape = (1000, 1000)

class Lazy(BaseModel):
    key: str

    def data(self):
        return np.random.randn(*shape)
    

class Data(BaseModel):
    data: Lazy

    def __getattribute__(self, item):
        if item == ""data"":
            return super().__getattribute__(item).data()
        return super().__getattribute__(item)
    

@task
def build_data(key) -> Data:
    return Data(data=Lazy(key=key))


@task
def combine_data(data: Data) -> Data:
    return data.data


@flow
def my_flow():
    data = build_data('foo')
    combined = combine_data(data)
    return combined


if __name__ == ""__main__"":
    my_flow()
```

This fails with `TypeError: 'memoryview' object is not callable`, because inside `combine_data`, `data.data` is suddenly no longer a `Lazy` object, but instead the output of `Lazy.data()`

How is that even possible
-------------
This is very surprising, since 
1. I don't change `data` anywhere
2. `data` is a `pydantic.BaseModel`, and the object as it appears does not pass validation

The reason is that `prefect.utilities.visit_collection` calls `getattr` in a loop over all model attributes of every `BaseModel`, and then reconstructs the object using `BaseModel.model_construct` which circumvents the validation.

How can this be fixed?
--------
The simple fix would be to replace the current

```
model_fields = expr.model_fields_set.union(expr.model_fields.keys())
updated_data = {
     field: visit_nested(getattr(expr, field)) for field in model_fields
}
```
with
```
updated_data = {field: visit_nested(value) for field, value in dict(expr)}
```
This works because
- `dict(expr)` and `expr.model_fields_set.union(expr.model_fields.keys())` yield the same results for all edge cases I could think of (see ""additional context"")
- `dict(expr)` circumvents `getattr` calls and returns the ""true"" raw values of the `BaseModel`


### Version info

```Text
Version:             3.2.9
API version:         0.8.4
Python version:      3.11.9
Git commit:          27eb408c
Built:               Fri, Feb 28, 2025 8:12 PM
OS/Arch:             linux/x86_64
Profile:             prefect3
Server type:         server
Pydantic version:    2.9.2
Integrations:
  prefect-dask:      0.3.3
  prefect-ray:       0.4.3
```

### Additional context

Appendix: dict vs model_fields
------------
```
class MyModel(BaseModel):
    model_config = ConfigDict(extra='allow')

    foo: str = 'bar'
    bar: int  | None = None
    c: str = Field(exclude=True, default='foobar')
    _private: str = 'zz'

m = MyModel(x=1)

print(dict(m).keys())

print(m.model_fields_set.union(m.model_fields.keys()))
```
prints
```
dict_keys(['foo', 'bar', 'c', 'x'])
{'foo', 'bar', 'x', 'c'}
```",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17631/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17631
17630,Failure in emitting events should not fail the whole function,closed,completed,2025-03-28T10:11:00Z,2025-03-31T13:57:20Z,2025-03-31T13:57:20Z,1,['bug'],lelouvincx,,CONTRIBUTOR,"### Bug summary

The utility function `emit_event` is used widely across our codebase to emit related events.

https://github.com/PrefectHQ/prefect/blob/d7dc1c803efcb874eb57761c107f7107e27a1e07/src/prefect/events/utilities.py#L21-L91

However, if (for any reason) `emit_events` fails, the whole function that is related to emitting that kind of event also fails. This is not the right behavior.

### Trigger

I got an error when trying to emit a read-block-document event.

https://github.com/PrefectHQ/prefect/blob/d7dc1c803efcb874eb57761c107f7107e27a1e07/src/prefect/blocks/core.py#L740-L746

This method's main functionality is to read a value from a block document. However, if it fails to emit an event (I don't know why, but it's complex to debug, ref #14629 ), the whole function fails.

### Suggested behavior

`emit_event` should be wrapped inside a try-except statement, and just do the error log instead of making the whole function fail.

### Version info

```Text
âžœ uv run prefect version
17:06:03.390 | DEBUG   | prefect.profiles - Using profile 'ephemeral'
Version:             3.2.14
API version:         0.8.4
Python version:      3.11.10
Git commit:          efcde6dc
Built:               Fri, Mar 21, 2025 5:28 PM
OS/Arch:             darwin/arm64
Profile:             ephemeral
Server type:         server
Pydantic version:    2.10.6
Integrations:
  prefect-dbt:       0.7.0rc1
  prefect-gcp:       0.6.4
  prefect-shell:     0.3.1
```

### Additional context

- Python version: 3.11.10
- Full log traceback:

```
Traceback (most recent call last):
File ""/opt/prefect/current/.venv/lib/python3.11/site-packages/prefect/server/services/flow_run_notifications.py"", line 98, in send_flow_run_notification
  block = Block._from_block_document(
  ^^^^^^^^^^^^^^^^^^^^^^^^^^^
File ""/opt/prefect/current/.venv/lib/python3.11/site-packages/prefect/blocks/core.py"", line 744, in _from_block_document
  emit_event(event=f""{kind}.loaded"", resource=resource, related=related)
File ""/opt/prefect/current/.venv/lib/python3.11/site-packages/prefect/events/utilities.py"", line 89, in emit_event
  worker_instance.send(event_obj)
File ""/opt/prefect/current/.venv/lib/python3.11/site-packages/prefect/_internal/concurrency/services.py"", line 293, in send
  raise RuntimeError(""Cannot put items in a stopped service instance."")
RuntimeError: Cannot put items in a stopped service instance.
```

- How to reproduce?
I got an error on production, but failed to reproduce it under my local development.",cicdw,1,https://api.github.com/repos/PrefectHQ/prefect/issues/17630/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17630
17628,"Flow run limit reached for worker even when nothing is ""Running"" and flows get accumulated in ""Late""",open,,2025-03-28T06:21:47Z,2025-04-25T11:00:47Z,,6,['bug'],steinskeeper,,NONE,"### Bug summary

## Problem
Worker shows `Flow run limit reached; 15 flow runs in progress` even when no flow is running and all the flows gets accumulated in `Late`.

## What fixes it temporarily
Only upon closing the worker and starting again do flows from `Late` start running.

## When is this behaviour triggred
Not sure, but haven't had this issue before. Seems recent.

## Additional details
- Worker is started using `prefect worker start -p ""my-pool"" -n ""dannylinux"" --limit 15`
- No concurrency limits are set anywhere else.


### Version info

```Text
prefect version
Version:             3.2.13
API version:         0.8.4
Python version:      3.13.2
Git commit:          12800297
Built:               Fri, Mar 14, 2025 8:37 PM
OS/Arch:             linux/x86_64
Profile:             local
Server type:         cloud
Pydantic version:    2.10.6
```

### Additional context

Not sure if it is relevant, but this is one error before the continuous loop of `Flow run limit reached`
```
 /usr/lib/python3.13/asyncio/selector_events.py:869: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=6 read=idle write=<idle, bufsize=0>>
0|run      |   _warn(f""unclosed transport {self!r}"", ResourceWarning, source=self)
0|run      | ResourceWarning: Enable tracemalloc to get the object allocation traceback
```",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17628/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17628
17627,Still error in marking flow run as cancelled,closed,completed,2025-03-28T05:17:53Z,2025-03-28T15:05:47Z,2025-03-28T15:05:47Z,0,['bug'],lelouvincx,,CONTRIBUTOR,"### Bug summary

The bug continues from #17536 

With error log:

![Image](https://github.com/user-attachments/assets/6af48811-fea7-4a26-b313-31a2a145010c)

The reason is that the key `type` is duplicated twice from the previous config.

```diff
async def _mark_flow_run_as_cancelled(
    self, flow_run: ""FlowRun"", state_updates: dict[str, Any] | None = None
) -> None:
    state_updates = state_updates or {}
    state_updates.setdefault(""name"", ""Cancelled"")
+   state_updates.setdefault(""type"", StateType.CANCELLED)

    if flow_run.state:
        state = flow_run.state.model_copy(update=state_updates)
    else:
        # Unexpectedly when flow run does not have a state, create a new one
-       state = Cancelled(**state_updates)
```

Parsing to `Cancelled()` at:

https://github.com/PrefectHQ/prefect/blob/d7dc1c803efcb874eb57761c107f7107e27a1e07/src/prefect/states.py#L717-L723

Then `_traced()`:

https://github.com/PrefectHQ/prefect/blob/d7dc1c803efcb874eb57761c107f7107e27a1e07/src/prefect/states.py#L641-L648

### Version info

```Text
âžœ uv run --frozen prefect version
12:16:43.989 | DEBUG   | prefect.profiles - Using profile 'ephemeral'
Version:             3.2.14
API version:         0.8.4
Python version:      3.11.10
Git commit:          efcde6dc
Built:               Fri, Mar 21, 2025 5:28 PM
OS/Arch:             darwin/arm64
Profile:             ephemeral
Server type:         server
Pydantic version:    2.10.6
Integrations:
  prefect-dbt:       0.7.0rc1
  prefect-gcp:       0.6.4
  prefect-shell:     0.3.1
```

### Additional context

- Previous fix at #17537 . However, still got error after the fix.
- Updated Prefect version to 3.2.14",cicdw,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17627/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17627
17623,Cancellation not injected into flow,open,,2025-03-27T18:38:06Z,2025-04-10T01:10:00Z,,2,['bug'],jm-positron,,NONE,"### Bug summary

If I run a flow locally, by just invoking the function, I can ctrl-c it and I get an asyncio CancelledError injected into my code, allowing me to use `try/finally` in ways that one would expect. In fact, from what little I can find from the docs about the cancellation process, this is what is supposed to happen when a flow is cancelled from anywhere.

But it doesn't happen when the flow is being executed by some other worker through a deployment. The flow does get marked as ""cancelling"" but the CancelledError is never seen by the primary code. Instead, the flow is terminated.

Here's an example script:

```
import asyncio

from prefect import flow, task


@task
async def run_internal_experiment():
    try:
        print(""Running internal experiment"")
        await asyncio.sleep(60)
    except asyncio.CancelledError:
        print(""Caught asyncio.CancelledError"")
    except Exception as e:
        print(f""Experiment failed: {e}"")
        raise


@flow(log_prints=True)
async def run_internal_experiment_flow():
    await run_internal_experiment()


if __name__ == ""__main__"":
    asyncio.run(run_internal_experiment_flow())

```

Here's some log output from running it locally:

```
11:22:35.891 | INFO    | Task run 'run_internal_experiment-954' - Running internal experiment
^C11:22:36.954 | INFO    | Task run 'run_internal_experiment-954' - Caught asyncio.CancelledError
11:22:36.956 | INFO    | Task run 'run_internal_experiment-954' - Finished in state Completed()
11:22:36.996 | INFO    | Flow run 'giga-scallop' - Finished in state Completed()
```

And some running it through the web UI:

```
Cancelled flow run 'chi3-nardol-shift'!
11:25:38 AM
prefect.flow_runs.runner

 > Running set_working_directory step...
11:25:38 AM
prefect.flow_runs

Loading flow to check for on_cancellation hooks
11:25:38 AM
prefect.flow_runs.runner

Process for flow run 'chi3-nardol-shift' exited with status code: -15; This indicates that the process exited due to a SIGTERM signal. Typically, this is caused by manual cancellation.
11:25:35 AM
prefect.flow_runs.runner

Running internal experiment
11:25:15 AM
run_internal_experiment-42a
prefect.task_runs

Beginning flow run 'chi3-nardol-shift' for flow 'run-internal-experiment-flow'
11:25:15 AM
prefect.flow_runs

 > Running set_working_directory step...
11:25:15 AM
prefect.flow_runs

Completed submission of flow run '930c2e8d-629d-46bc-9a6c-7c944de9db17'
11:25:14 AM
prefect.flow_runs.worker

Opening process...
11:25:13 AM
prefect.flow_runs.runner

Worker 'ProcessWorker fe6949f7-b712-4ba3-bd96-9602f0000464' submitting flow run '930c2e8d-629d-46bc-9a6c-7c944de9db17'
11:25:13 AM
prefect.flow_runs.worker
```

So the `CancelledError` is never injected, and thus never gives the running `Task`  a chance to clean up after itself.

### Version info

```Text
Version:             3.2.9
API version:         0.8.4
Python version:      3.12.8
Git commit:          27eb408c
Built:               Fri, Feb 28, 2025 8:12 PM
OS/Arch:             linux/x86_64
Profile:             ephemeral
Server type:         server
Pydantic version:    2.10.6
Integrations:
  prefect-docker:    0.6.2
```

### Additional context

Maybe a workaround would be to use `on_cancelled` but so far that has proven buggy. Also, there does not seem to be a straightforward way to register ""finalizers"" or some similar concept so that the cancellation function can be aware of what to actually clean up.",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17623/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17623
17621,"readiness_result is actually a Process value, not an int",closed,completed,2025-03-27T17:56:27Z,2025-04-08T15:09:10Z,2025-04-08T15:09:10Z,2,['bug'],jm-positron,,NONE,"### Bug summary

The flow's `process_map` is being polluted with malformed `ProcessMapEntry`s.
The type of `pid` for `ProcessMapEntry` is `int`, but instead it is being set to `Process` values.

This is trivial to repro.

1. Start a local deployment
2. Run some flow
3. Done

Here's a snippet of code you can put in to help highlight the issue:

```
        if ready_to_submit:
            print(f""DEBUG: Starting _submit_run_and_capture_errors for flow run {flow_run.id}"")
            readiness_result = await self._runs_task_group.start(
                partial(
                    self._submit_run_and_capture_errors,
                    flow_run=flow_run,
                    entrypoint=entrypoint,
                ),
            )
            print(f""DEBUG: readiness_result type: {type(readiness_result)}"")
            print(f""DEBUG: readiness_result value: {readiness_result}"")

            if readiness_result and not isinstance(readiness_result, Exception):
                async with self._flow_run_process_map_lock:
                    print(f""DEBUG: Creating ProcessMapEntry with readiness_result: {readiness_result} (type: {type(readiness_result)})"")
                    self._flow_run_process_map[flow_run.id] = ProcessMapEntry(
                        pid=readiness_result, flow_run=flow_run
                    )
```

This results in the following output:

```
DEBUG: Starting _submit_run_and_capture_errors for flow run b88b67cd-0f01-404c-af31-834b8dd01d83
DEBUG: Starting _run_process for flow run b88b67cd-0f01-404c-af31-834b8dd01d83
10:47:45.926 | INFO    | prefect.flow_runs.runner - Opening process...
DEBUG: readiness_result type: <class 'anyio._backends._asyncio.Process'>
DEBUG: readiness_result value: Process(_process=<Process 174965>, _stdin=StreamWriterWrapper(_stream=<StreamWriter transport=<_UnixWritePipeTransport fd=15 idle bufsize=0>>), _stdout=StreamReaderWrapper(_stream=<StreamReader transport=<_UnixReadPipeTransport fd=16 polling>>), _stderr=StreamReaderWrapper(_stream=<StreamReader transport=<_UnixReadPipeTransport fd=18 polling>>))
```

Looking through the code, it is not even clear to me how it's supposed to function in any case, since the return value of `_submit_run_and_capture_errors` is a status code for the process, not the PID.

### Version info

```Text
Version:             3.2.9
API version:         0.8.4
Python version:      3.12.8
Git commit:          27eb408c
Built:               Fri, Feb 28, 2025 8:12 PM
OS/Arch:             linux/x86_64
Profile:             ephemeral
Server type:         server
Pydantic version:    2.10.6
Integrations:
  prefect-docker:    0.6.2
```

### Additional context

_No response_",desertaxle,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17621/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17621
17619,dbt cloud job returning python error unrelated to dbt cloud failure,open,,2025-03-27T17:18:11Z,2025-03-27T17:18:11Z,,0,['bug'],rcash,,CONTRIBUTOR,"### Bug summary

when running a dbt cloud job that failed using the `prefect-dbt` library, the flow fails with a Python error unrelated to the dbt flow error directly.

Error message:
```
File ""C:\Users\mahorg6\Documents\misc\prefect\.venv\Lib\site-packages\prefect_dbt\cloud\jobs.py"", line 1136, in run_dbt_cloud_job

    f""dbt Cloud job {run.run_id} failed after {targeted_retries} retries.""

                     ^^^^^^^^^^

AttributeError: 'dict' object has no attribute 'run_id'
```

code to reproduce the issue
```python
from prefect import flow, task
from prefect.logging import get_run_logger

from prefect_dbt.cloud import DbtCloudJob
from prefect_dbt.cloud.jobs import run_dbt_cloud_job

@task(retries=1, retry_delay_seconds=30)
async def trigger_dbt_job(dbt_job_block_name: str, retries: int = 1):

    logger = get_run_logger()
    try:
        result = await run_dbt_cloud_job(
            dbt_cloud_job = await DbtCloudJob.load(dbt_job_block_name),
            targeted_retries=retries
        )

 

        return result
    except Exception as e:
        logger.error(f""dbt Cloud job execution failed: {e}"")
        raise
```


### Version info

```Text
`prefect-dbt`: 0.6.4 and 0.6.6
```

### Additional context

_No response_",,1,https://api.github.com/repos/PrefectHQ/prefect/issues/17619/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17619
17618,Large number of Dask clients created during flow run,closed,completed,2025-03-27T15:17:41Z,2025-03-31T15:54:46Z,2025-03-31T15:38:51Z,2,['bug'],bnaul,desertaxle,CONTRIBUTOR,"### Bug summary

#14829 added a reference to the flow's task runner within the task context to enable submission of tasks from within tasks. Seems like a very reasonable way to go about supporting that, but one side effect is that now a flow run with many tasks gets an additional Dask client connection for every task, regardless of whether any ""task from task"" pattern is used.

I can't be sure but I think this is contributing to some instability in our jobs, and intuitively it seems better to avoid these extra (potentially tens of thousands of) connections if possible. Maybe it's possible to make the reference to the task runner lazy, so that it's only fully reinstantiated if necessary?

cc @cicdw @desertaxle 

### Version info

```Text
Version:             3.2.15.dev3+1.g5cc9be16d
API version:         0.8.4
Python version:      3.10.16
Git commit:          5cc9be16
Built:               Tue, Mar 25, 2025 5:47 PM
OS/Arch:             darwin/arm64
Profile:             default
Server type:         cloud
Pydantic version:    2.9.2
Integrations:
  prefect-dask:      0.3.3
  prefect-gcp:       0.6.4
  prefect-kubernetes: 0.5.8
```

### Additional context

_No response_",desertaxle,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17618/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17618
17615,Prefect auto-generate docker file on deploy unstable,open,,2025-03-27T13:53:10Z,2025-03-31T16:41:25Z,,3,['bug'],omrihar,,NONE,"### Bug summary

When trying to use `flow.deploy` without specifying a docker file, it fails on Python 3.13 because there is no label for this combination of prefect and python versions.

For example (taken directly from the docs):
```python
from prefect import flow


@flow(log_prints=True)
def my_flow(name: str = ""world""):
    print(f""Hello, {name}!"")


if __name__ == ""__main__"":
    my_flow.deploy(
        name=""my-deployment"",
        work_pool_name=""my-work-pool"",
        image=""my-docker-image:dev"",
        push=False
    )

```
will fail to run on python 3.13, because there is no manifest for `prefecthq/prefect:3.2.14-python3.13`.

More specifically, the code [here](https://github.com/PrefectHQ/prefect/blob/b2043134bd624b92f9beee2fd50f757002e66c05/src/prefect/utilities/dockerutils.py#L41) does not bother to check whether the manifest actually exists or not, which seems very fragile to me.

### Version info

```Text
Version:             3.2.14
API version:         0.8.4
Python version:      3.13.2
Git commit:          efcde6dc
Built:               Fri, Mar 21, 2025 5:28 PM
OS/Arch:             darwin/arm64
Profile:             local
Server type:         server
Pydantic version:    2.10.6
Integrations:
  prefect-aws:       0.5.7
```

### Additional context

This bug was already ""fixed"" here: https://github.com/PrefectHQ/prefect/issues/11259 in the sense that the manifest was published which caused the immediate problem to be solved, but the mechanism remained untouched, which led to this happening again. See also here: https://linen.prefect.io/t/23185194/hello-everyone-i-m-trying-to-get-a-deployment-to-a-docker-wo ",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17615/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17615
17604,Yaml deployment doesn't use PREFECT_DEFAULT_DOCKER_BUILD_NAMESPACE for private repository name,closed,completed,2025-03-26T16:47:30Z,2025-03-27T03:33:58Z,2025-03-27T03:33:28Z,3,['bug'],jlwhelan28,,NONE,"### Bug summary

When creating a deployment from yaml definition, the build step does not pick up the config variable `PREFECT_DEFAULT_DOCKER_BUILD_NAMESPACE` to adjust the name of the build image. When using the python `flow.deploy()` method, the build image includes the namespace as intended. Referencing this portion of the docs: https://docs.prefect.io/v3/deploy/infrastructure-examples/docker#automatically-build-a-custom-docker-image-with-a-local-dockerfile

First
```
prefect config set PREFECT_DEFAULT_DOCKER_BUILD_NAMESPACE=my-private-repository.com
```

With a flow entrypoint of `flow.py:hello_world`

With yaml deployment:
```yaml
# build section allows you to manage and build docker images
build:
- prefect_docker.deployments.steps.build_docker_image:
    id: build_image
    requires: prefect-docker>=0.3.1
    image_name: 'test-image'
    tag: latest
    dockerfile: ""./Dockerfile""

# push section allows you to manage if and how this project is uploaded to remote locations
push:
- prefect_docker.deployments.steps.push_docker_image:
    requires: prefect-docker>=0.3.1
    image_name: '{{ build_image.image_name }}'
    tag: '{{ build_image.tag }}'

 # the deployments section allows you to provide configuration for deploying flows
deployments:
- name: sample_deployment
  version: '{{ build_image.tag }}'
  tags:
  - test
  description: Sample ECS deployment for unit testing
  entrypoint: flow.py:hello_world
  parameters: {}
  work_pool:
    name: my-work-pool
    job_variables:
      image: '{{ build_image.image }}'
    work_queue_name:
  schedules: []
  concurrency_limit:
pull:
- prefect.deployments.steps.set_working_directory:
    directory: /opt/prefect/sample_ecs_deployment
```

Running `prefect deploy flow.py:hello_world` should yield an image: `my-private-repository.com/test-image:latest`
Instead I get an image `test-image:latest`

When I use the python deploy method via

```python
flow.from_source(
    source = ""./"",
    entrypoint = ""flow.py:hello_world"",
).deploy(
    name=name,
    work_pool_name=""ecs-worker-pool"",
    image=DockerImage(
        name=""test-image"",
        tag=""latest"",
        dockerfile=""Dockerfile"",
    ),
)
```

I successfully get the output image `my-private-repository.com/test-image:latest` built locally and then pushed to my private repository. 

### Version info

```Text
Version:             3.2.9
API version:         0.8.4
Python version:      3.12.9
Git commit:          27eb408c
Built:               Fri, Feb 28, 2025 8:12 PM
OS/Arch:             linux/x86_64
Profile:             ephemeral
Server type:         server
Pydantic version:    2.10.6
```

### Additional context

The custom image built through the python deploy method has an error as without the `pull` step from the yaml deployment (seems to be no equivalent in the python method), the working directory of the deployed container inherits the local path context from the docker build... but this deserves a separate issue and is related to the discussion here: https://linen.prefect.io/t/16246009/ulva73b9p-is-it-possible-to-manually-set-a-working-directory

As a workaround I plan to adjust to build the images externally.",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17604/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17604
17603,Display flow and task run result and cache information in the UI,open,,2025-03-26T15:48:29Z,2025-03-27T03:34:19Z,,0,"['enhancement', 'ui']",robfreedy,,CONTRIBUTOR,"### Describe the current behavior

Currently, flow and task result and caching information are not displayed in the UI. 

### Describe the proposed behavior

Displaying information about result persistence configuration, results, and/or caching behavior in the UI for flow/task runs. 

This information was displayed in the Prefect 1 UI for reference. 

### Example Use

N/A, UI enhancement request

### Additional context

_No response_",,2,https://api.github.com/repos/PrefectHQ/prefect/issues/17603/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17603
17599,Publish a `prefecthq/prefect-client` image based on the `prefect-client` Python package,closed,completed,2025-03-25T18:29:45Z,2025-03-26T14:36:26Z,2025-03-26T14:36:26Z,0,['enhancement'],chrisguidry,chrisguidry,COLLABORATOR,"### Describe the current behavior

The current image is ~770MB and includes everything you'd need to run workers and a permanent Prefect server.

### Describe the proposed behavior

With a build just based on `prefect-client`, we can get down to ~310MB

### Example Use

The goal here would be an image that's a drop-in replacement for `prefecthq/prefect:3-...` for running flows against remote servers.

### Additional context

_No response_",chrisguidry,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17599/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17599
17593,Subflow subprocess not killed when cancelling a flow even with infrastructure_pid,open,,2025-03-25T13:17:06Z,2025-04-09T07:55:52Z,,2,['bug'],LukasJerabek,desertaxle,NONE,"### Bug summary
Hi,
the problem is reproducible on Linux (not on windows). When you run the example below and wait for the subflow to start, then click cancel in the UI, you can see that the main flow starts cancelling itself and after some time the process is killed, however the child flow process continues to output and is never terminated. It only is marked as cancelled in the UI later with a note ""The parent flow run was cancelled.""
 
```
import os
import time
import prefect.flow_engine
import prefect.runtime.flow_run
import prefect.states

@prefect.flow(log_prints=True, flow_run_name=""Child Flow"")
async def child_flow():
    client = prefect.get_client()
    print(f""Child flow pid is: {os.getpid()}"")
    await client.update_flow_run(
        flow_run_id=prefect.runtime.flow_run.id,
        infrastructure_pid=str(os.getpid())
    )
    while True:
        run_state = await client.read_flow_run(prefect.runtime.flow_run.id)
        print(f""Child flow is running, state: {run_state.state}"")
        time.sleep(1)

@prefect.flow(log_prints=True, flow_run_name=""Main Flow"")
async def main_flow():
    client = prefect.get_client()
    print(f""Main flow pid is: {os.getpid()}"")
    prefect.flow_engine.run_flow_in_subprocess(
        child_flow
    )
    while True:
        run_state = await client.read_flow_run(prefect.runtime.flow_run.id)
        print(f""Main flow is running, its state: {run_state.state}"")
        time.sleep(1)

if __name__ == ""__main__"":
    main_flow.serve()
```

### Version info

```Text
Version:             3.2.14
API version:         0.8.4
Python version:      3.13.1
Git commit:          efcde6dc
Built:               Fri, Mar 21, 2025 5:28 PM
OS/Arch:             linux/x86_64
Profile:             local
Server type:         server
Pydantic version:    2.10.4
Integrations:
  prefect-docker:    0.6.2
```

### Additional context

1) This happens when using .serve() and also when using .deploy(). 
2) This happens creating the process with run_flow_in_subprocess method and also when using prefect.workers.process.ProcessWorker's run method to run flow in subprocess.
3) On windows this problem doesnt arise and subflow process is terminated.
4) It would also be nice to be able to pass arbitrary context to on_cancellation method to work with.
5) We are also curious if we can rely on flows being run in the main thread and with the main interpreter, since those are conditions for signal handling with signal library, in case we would like to handle the signals in our subprocess subflow runs ourselves.
",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17593/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17593
17588,Resource request overrides not applied when using kubernetes,open,,2025-03-24T22:11:46Z,2025-03-25T17:13:08Z,,3,['bug'],brian-swantide,,NONE,"### Bug summary

Previously I was able to specify memory and cpu requests for my prefect jobs running in GKE by adding job_spec to job_variables in my yaml file, following this answer:

https://linen.prefect.io/t/18860233/ulva73b9p-how-to-override-resource-requirements-job-variable

This is no longer working. We're on worker version 3.2.7

Specifying memory request
![Image](https://github.com/user-attachments/assets/4807a7ef-07e4-4cbd-b760-5fc768aae9df)

Only includes cpu request (from base job template)
![Image](https://github.com/user-attachments/assets/c1ca42d7-1213-466d-8d9c-3aabefdb3a3a)

### Version info

```Text
Version:             2.20.16
API version:         0.8.4
Python version:      3.12.3
Git commit:          b5047953
Built:               Thu, Dec 19, 2024 10:55 AM
OS/Arch:             darwin/arm64
Profile:             default
Server type:         cloud
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17588/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17588
17585,Process workers dying processing on crashed hooks on Windows,open,,2025-03-24T20:31:14Z,2025-04-06T20:43:00Z,,3,"['bug', 'arch:windows']",carettines,,NONE,"### Bug summary

I am able to reliably cause process workers to die on Windows by messing with an individual flow. I would expect the central worker process to be robust against any problems with individual flows:

0. Using Process Workers in a Windows context.
1. Running Prefect 3.2.14 in our python environment.
2. We have a base python runtime with 3rd party libraries (pandas, numpy, etc) and add internal libraries via manipulating PYTHONPATH in the worker.
3. I have set up the work pool with run command ""prefect flow-run execute"" as suggested by prefect support.
4. I introduce a syntax error in a specific flow file in the name of one of the state handlers (referencing a function that doesn't exist).
5. I run the flow via the Prefect UI. The flow crashes as expected, and shortly thereafter, the worker process itself crashes and closes. Interestingly, if I instead introduce an artificial generic Exception in the top level of the flow instead of a syntax error in the flow, the flow crashes (as expected), but the worker does *not* die.

Here is a full stacktrace, with debugging on:

<details>

```bash
16:19:23.676 | DEBUG   | prefect.profiles - Using profile 'ephemeral'
16:19:26.710 | DEBUG   | prefect.client - Connecting to API at https://api.prefect.cloud/api/accounts/<redacted>
16:19:26.905 | DEBUG   | prefect.client - Connecting to API at https://api.prefect.cloud/api/accounts/<redacted>
16:19:28.178 | DEBUG   | prefect.workers.process.processworker 6a716f79-bcc0-43cc-8471-81673871b6c2 - Entering worker context...
16:19:28.178 | DEBUG   | prefect.workers.process.processworker 6a716f79-bcc0-43cc-8471-81673871b6c2 - Setting up worker...
16:19:28.210 | DEBUG   | prefect.client - Connecting to API at https://api.prefect.cloud/api/accounts/<redacted>
16:19:29.562 | DEBUG   | prefect.workers.process.processworker 6a716f79-bcc0-43cc-8471-81673871b6c2 - Worker synchronized with the Prefect API server. Remote ID: 3e0661da-5923-4d1e-95cd-e5c53ffdce1f
16:19:29.593 | DEBUG   | prefect.client - Connecting to API at https://api.prefect.cloud/api/accounts/<redacted>
16:19:29.609 | DEBUG   | prefect.runner - Starting runner...
16:19:29.625 | DEBUG   | prefect.client - Connecting to API at https://api.prefect.cloud/api/accounts/<redacted>
16:19:29.838 | DEBUG   | prefect.workers.process.processworker 6a716f79-bcc0-43cc-8471-81673871b6c2 - Worker synchronized with the Prefect API server. Remote ID: 3e0661da-5923-4d1e-95cd-e5c53ffdce1f
Worker 'ProcessWorker 6a716f79-bcc0-43cc-8471-81673871b6c2' started!
16:19:29.853 | DEBUG   | prefect.utilities.services.critical_service_loop - Starting run of 'get_and_submit_flow_runs'
16:19:29.853 | DEBUG   | prefect.workers.process.processworker 6a716f79-bcc0-43cc-8471-81673871b6c2 - Querying for flow runs scheduled before 2025-03-24 20:19:39.853776+00:00
16:19:29.853 | DEBUG   | prefect.utilities.services.critical_service_loop - Starting run of 'sync_with_backend'
16:19:29.900 | DEBUG   | prefect.events.clients - Reconnecting websocket connection.
16:19:29.916 | DEBUG   | prefect.events.clients - Opening websocket connection.
16:19:30.000 | DEBUG   | prefect.events.clients - Pinging to ensure websocket connected.
16:19:30.000 | DEBUG   | prefect.workers.process.processworker 6a716f79-bcc0-43cc-8471-81673871b6c2 - Discovered 0 scheduled_flow_runs
16:19:30.031 | DEBUG   | prefect.events.clients - Pong received. Websocket connected.
16:19:30.031 | DEBUG   | prefect.events.clients - Resending 0 unconfirmed events.
16:19:30.031 | DEBUG   | prefect.events.clients - Finished resending unconfirmed events.
16:19:30.031 | DEBUG   | prefect.client - Connecting to API at https://api.prefect.cloud/api/accounts/<redacted>
16:19:30.050 | DEBUG   | prefect.events.clients - EventsClient(id=1903706473472): Emitting event id=60af55b2-f79d-4d05-8d70-042b2bcae9d0.
16:19:30.051 | DEBUG   | prefect.events.clients - Added event id=60af55b2-f79d-4d05-8d70-042b2bcae9d0 to unconfirmed events list. There are now 1 unconfirmed events.
16:19:30.051 | DEBUG   | prefect.events.clients - EventsClient(id=1903706473472): Emit reconnection attempt 0.
16:19:30.051 | DEBUG   | prefect.events.clients - EventsClient(id=1903706473472): Sending event id=60af55b2-f79d-4d05-8d70-042b2bcae9d0.
16:19:30.051 | DEBUG   | prefect.events.clients - EventsClient(id=1903706473472): Checkpointing event id=60af55b2-f79d-4d05-8d70-042b2bcae9d0.
16:19:30.168 | DEBUG   | prefect.workers.process.processworker 6a716f79-bcc0-43cc-8471-81673871b6c2 - Worker synchronized with the Prefect API server. Remote ID: 3e0661da-5923-4d1e-95cd-e5c53ffdce1f
16:19:41.591 | DEBUG   | prefect.utilities.services.critical_service_loop - Starting run of 'get_and_submit_flow_runs'
16:19:41.591 | DEBUG   | prefect.workers.process.processworker 6a716f79-bcc0-43cc-8471-81673871b6c2 - Querying for flow runs scheduled before 2025-03-24 20:19:51.591222+00:00
16:19:42.718 | DEBUG   | prefect.workers.process.processworker 6a716f79-bcc0-43cc-8471-81673871b6c2 - Discovered 0 scheduled_flow_runs
16:19:52.450 | DEBUG   | prefect.utilities.services.critical_service_loop - Starting run of 'get_and_submit_flow_runs'
16:19:52.450 | DEBUG   | prefect.workers.process.processworker 6a716f79-bcc0-43cc-8471-81673871b6c2 - Querying for flow runs scheduled before 2025-03-24 20:20:02.450701+00:00
16:19:52.561 | DEBUG   | prefect.workers.process.processworker 6a716f79-bcc0-43cc-8471-81673871b6c2 - Discovered 0 scheduled_flow_runs
16:19:53.452 | DEBUG   | prefect.utilities.services.critical_service_loop - Starting run of 'sync_with_backend'
16:19:53.609 | DEBUG   | prefect.workers.process.processworker 6a716f79-bcc0-43cc-8471-81673871b6c2 - Worker synchronized with the Prefect API server. Remote ID: 3e0661da-5923-4d1e-95cd-e5c53ffdce1f
16:20:03.039 | DEBUG   | prefect.utilities.services.critical_service_loop - Starting run of 'get_and_submit_flow_runs'
16:20:03.039 | DEBUG   | prefect.workers.process.processworker 6a716f79-bcc0-43cc-8471-81673871b6c2 - Querying for flow runs scheduled before 2025-03-24 20:20:13.039436+00:00
16:20:03.195 | DEBUG   | prefect.workers.process.processworker 6a716f79-bcc0-43cc-8471-81673871b6c2 - Discovered 1 scheduled_flow_runs
16:20:03.195 | INFO    | prefect.flow_runs.worker - Worker 'ProcessWorker 6a716f79-bcc0-43cc-8471-81673871b6c2' submitting flow run 'd905dca4-fb5f-49eb-9555-8791e1a8953a'
16:20:03.195 | INFO    | prefect.flow_runs.worker - Running on worker id: 3e0661da-5923-4d1e-95cd-e5c53ffdce1f. See worker logs here: https://app.prefect.cloud/account/7c9df72d-bbfe-46d7-a1f7-2ef63e929412/workspace/61c98b22-d732-41c0-b59e-d0d230b0706e/work-pools/work-pool/Data Research Prod/worker/3e0661da-5923-4d1e-95cd-e5c53ffdce1f
16:20:03.679 | DEBUG   | prefect.workers.process.processworker 6a716f79-bcc0-43cc-8471-81673871b6c2 - Ready to submit d905dca4-fb5f-49eb-9555-8791e1a8953a: True
16:20:03.841 | DEBUG   | prefect.events.clients - EventsClient(id=1903706473472): Emitting event id=f995ba49-ddb9-4c23-aa41-7406e090180d.
16:20:03.841 | DEBUG   | prefect.events.clients - Added event id=f995ba49-ddb9-4c23-aa41-7406e090180d to unconfirmed events list. There are now 2 unconfirmed events.
16:20:03.841 | DEBUG   | prefect.events.clients - EventsClient(id=1903706473472): Emit reconnection attempt 0.
16:20:03.856 | DEBUG   | prefect.events.clients - EventsClient(id=1903706473472): Sending event id=f995ba49-ddb9-4c23-aa41-7406e090180d.
16:20:03.856 | DEBUG   | prefect.events.clients - EventsClient(id=1903706473472): Checkpointing event id=f995ba49-ddb9-4c23-aa41-7406e090180d.
16:20:04.113 | INFO    | prefect.flow_runs.runner - Opening process...
16:20:04.150 | DEBUG   | prefect.utilities.services.critical_service_loop - Starting run of functools.partial(<bound method Runner._check_for_cancelled_flow_runs of Runner(name='runner-3a08f2ef-7cd8-4ad1-9385-8071478a9c9e')>, should_stop=<function Runner.execute_flow_run.<locals>.<lambda> at 0x000001BB3DD561F0>, on_stop=<bound method CancelScope.cancel of <anyio._backends._asyncio.CancelScope object at 0x000001BB3DC25190>>)
16:20:04.150 | DEBUG   | prefect.runner - Checking for cancelled flow runs...
16:20:04.290 | INFO    | prefect.flow_runs.worker - Completed submission of flow run 'd905dca4-fb5f-49eb-9555-8791e1a8953a'
16:20:10.603 | DEBUG   | prefect.profiles - Using profile 'ephemeral'

16:20:12.037 | DEBUG   | prefect.utilities.services.critical_service_loop - Starting run of 'get_and_submit_flow_runs'
16:20:12.037 | DEBUG   | prefect.workers.process.processworker 6a716f79-bcc0-43cc-8471-81673871b6c2 - Querying for flow runs scheduled before 2025-03-24 20:20:22.037851+00:00
16:20:12.746 | DEBUG   | prefect.workers.process.processworker 6a716f79-bcc0-43cc-8471-81673871b6c2 - Discovered 0 scheduled_flow_runs
16:20:13.374 | DEBUG   | prefect.runner - Starting runner...

16:20:13.422 | DEBUG   | prefect.client - Connecting to API at https://api.prefect.cloud/api/accounts/<redacted>

16:20:13.422 | DEBUG   | prefect.runner - Limit slot acquired for flow run 'd905dca4-fb5f-49eb-9555-8791e1a8953a'

16:20:13.610 | INFO    | prefect.flow_runs.runner - Opening process...

16:20:13.641 | DEBUG   | prefect.client - Connecting to API at https://api.prefect.cloud/api/accounts/<redacted>

16:20:13.673 | DEBUG   | prefect.utilities.services.critical_service_loop - Starting run of functools.partial(<bound method Runner._check_for_cancelled_flow_runs of Runner(name='runner-1d21cae0-a044-484a-9c2f-53f4d8235404')>, should_stop=<function Runner.execute_flow_run.<locals>.<lambda> at 0x0000021FDDCAD4C0>, on_stop=<bound method CancelScope.cancel of <anyio._backends._asyncio.CancelScope object at 0x0000021FDFB5F8E0>>)

16:20:13.673 | DEBUG   | prefect.runner - Checking for cancelled flow runs...

16:20:16.867 | DEBUG   | prefect.utilities.services.critical_service_loop - Starting run of functools.partial(<bound method Runner._check_for_cancelled_flow_runs of Runner(name='runner-3a08f2ef-7cd8-4ad1-9385-8071478a9c9e')>, should_stop=<function Runner.execute_flow_run.<locals>.<lambda> at 0x000001BB3DD561F0>, on_stop=<bound method CancelScope.cancel of <anyio._backends._asyncio.CancelScope object at 0x000001BB3DC25190>>)
16:20:16.867 | DEBUG   | prefect.runner - Checking for cancelled flow runs...
16:20:19.490 | DEBUG   | prefect.profiles - Using profile 'ephemeral'


16:20:20.243 | DEBUG   | Flow run 'powerful-kakapo' - Running 1 deployment pull step(s)


16:20:20.274 | DEBUG   | prefect.client - Connecting to API at https://api.prefect.cloud/api/accounts/<redacted>


16:20:20.289 | INFO    | Flow run 'powerful-kakapo' -  > Running set_working_directory step...


16:20:20.321 | DEBUG   | prefect.client - Connecting to API at https://api.prefect.cloud/api/accounts/<redacted>


16:20:20.336 | DEBUG   | prefect.client - Connecting to API at https://api.prefect.cloud/api/accounts/<redacted>


16:20:20.336 | DEBUG   | Flow run 'powerful-kakapo' - Changing working directory to '\\\\junto.corp\\dfs\\QR_Deployments\\QRDeployments\\prod\\data_research\\juntodata'


16:20:20.336 | DEBUG   | Flow run 'powerful-kakapo' - Importing flow code from 'flows\DataLoading\webscrape\some_data_load.py:some_flow'


16:20:24.978 | DEBUG   | prefect.utilities.services.critical_service_loop - Starting run of 'get_and_submit_flow_runs'
16:20:24.978 | DEBUG   | prefect.workers.process.processworker 6a716f79-bcc0-43cc-8471-81673871b6c2 - Querying for flow runs scheduled before 2025-03-24 20:20:34.978769+00:00
16:20:25.056 | DEBUG   | prefect.workers.process.processworker 6a716f79-bcc0-43cc-8471-81673871b6c2 - Discovered 0 scheduled_flow_runs
16:20:25.228 | DEBUG   | prefect.utilities.services.critical_service_loop - Starting run of functools.partial(<bound method Runner._check_for_cancelled_flow_runs of Runner(name='runner-1d21cae0-a044-484a-9c2f-53f4d8235404')>, should_stop=<function Runner.execute_flow_run.<locals>.<lambda> at 0x0000021FDDCAD4C0>, on_stop=<bound method CancelScope.cancel of <anyio._backends._asyncio.CancelScope object at 0x0000021FDFB5F8E0>>)

16:20:25.228 | DEBUG   | prefect.runner - Checking for cancelled flow runs...



16:20:26.982 | ERROR   | prefect.flow_runs.runner - Process for flow run 'powerful-kakapo' exited with status code: 1

16:20:26.998 | DEBUG   | prefect.runner - Limit slot released for flow run 'd905dca4-fb5f-49eb-9555-8791e1a8953a'

16:20:27.132 | INFO    | prefect.flow_runs.runner - Reported flow run 'd905dca4-fb5f-49eb-9555-8791e1a8953a' as crashed: Flow run process exited with non-zero status code 1.

16:20:27.226 | INFO    | prefect.flow_runs.runner - Loading flow to check for on_crashed hooks

16:20:27.556 | DEBUG   | Flow run 'powerful-kakapo' - Running 1 deployment pull step(s)

16:20:27.572 | INFO    | Flow run 'powerful-kakapo' -  > Running set_working_directory step...

16:20:27.587 | DEBUG   | prefect.client - Connecting to API at https://api.prefect.cloud/api/accounts/<redacted>

16:20:27.603 | DEBUG   | prefect.client - Connecting to API at https://api.prefect.cloud/api/accounts/<redacted>

16:20:27.619 | DEBUG   | Flow run 'powerful-kakapo' - Changing working directory to '\\\\junto.corp\\dfs\\QR_Deployments\\QRDeployments\\prod\\data_research\\juntodata'

16:20:27.619 | DEBUG   | Flow run 'powerful-kakapo' - Importing flow code from 'flows\DataLoading\webscrape\some_data_load.py:some_flow'

16:20:28.878 | DEBUG   | prefect.utilities.services.critical_service_loop - Starting run of functools.partial(<bound method Runner._check_for_cancelled_flow_runs of Runner(name='runner-3a08f2ef-7cd8-4ad1-9385-8071478a9c9e')>, should_stop=<function Runner.execute_flow_run.<locals>.<lambda> at 0x000001BB3DD561F0>, on_stop=<bound method CancelScope.cancel of <anyio._backends._asyncio.CancelScope object at 0x000001BB3DC25190>>)
16:20:28.878 | DEBUG   | prefect.runner - Checking for cancelled flow runs...
16:20:29.237 | DEBUG   | prefect.utilities.services.critical_service_loop - Starting run of 'sync_with_backend'
16:20:29.606 | DEBUG   | prefect.workers.process.processworker 6a716f79-bcc0-43cc-8471-81673871b6c2 - Worker synchronized with the Prefect API server. Remote ID: 3e0661da-5923-4d1e-95cd-e5c53ffdce1f
Traceback (most recent call last):

  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\site-packages\prefect\runner\runner.py"", line 637, in execute_flow_run

    return process

  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\site-packages\anyio\_backends\_asyncio.py"", line 767, in __aexit__

    raise exc_val

  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\site-packages\anyio\_backends\_asyncio.py"", line 741, in __aexit__

    await _wait(self._tasks)

  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\site-packages\anyio\_backends\_asyncio.py"", line 706, in _wait

    await waiter

asyncio.exceptions.CancelledError: Cancelled by cancel scope 21fdfb46ca0



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\site-packages\prefect\cli\_utilities.py"", line 44, in wrapper

    return fn(*args, **kwargs)

  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\site-packages\prefect\cli\_types.py"", line 155, in sync_fn

    return asyncio.run(async_fn(*args, **kwargs))

  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\asyncio\runners.py"", line 44, in run

    return loop.run_until_complete(main)

  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\asyncio\base_events.py"", line 642, in run_until_complete

    return future.result()

  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\site-packages\prefect\cli\flow_run.py"", line 375, in execute

    await runner.execute_flow_run(id)

  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\site-packages\prefect\runner\runner.py"", line 637, in execute_flow_run

    return process

  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\site-packages\prefect\runner\runner.py"", line 1688, in __aexit__

    await self._runs_task_group.__aexit__(*exc_info)

  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\site-packages\anyio\_backends\_asyncio.py"", line 763, in __aexit__

    raise BaseExceptionGroup(


An exception occurred.

exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)

16:20:33.304 | ERROR   | prefect.flow_runs.runner - Process for flow run 'powerful-kakapo' exited with status code: 1
16:20:33.547 | INFO    | prefect.flow_runs.runner - Loading flow to check for on_crashed hooks
16:20:33.673 | DEBUG   | Flow run 'powerful-kakapo' - Running 1 deployment pull step(s)
16:20:33.689 | INFO    | Flow run 'powerful-kakapo' -  > Running set_working_directory step...
16:20:33.704 | DEBUG   | prefect.client - Connecting to API at https://api.prefect.cloud/api/accounts/<redacted>
16:20:33.720 | DEBUG   | prefect.client - Connecting to API at https://api.prefect.cloud/api/accounts/<redacted>
16:20:33.741 | DEBUG   | Flow run 'powerful-kakapo' - Changing working directory to '\\\\junto.corp\\dfs\\QR_Deployments\\QRDeployments\\prod\\data_research\\juntodata'
16:20:33.741 | DEBUG   | Flow run 'powerful-kakapo' - Importing flow code from 'flows\DataLoading\webscrape\some_data_load.py:some_flow'
16:20:36.438 | DEBUG   | prefect.utilities.services.critical_service_loop - Starting run of 'get_and_submit_flow_runs'
16:20:36.438 | DEBUG   | prefect.workers.process.processworker 6a716f79-bcc0-43cc-8471-81673871b6c2 - Querying for flow runs scheduled before 2025-03-24 20:20:46.438218+00:00
16:20:36.532 | DEBUG   | prefect.workers.process.processworker 6a716f79-bcc0-43cc-8471-81673871b6c2 - Discovered 0 scheduled_flow_runs
Traceback (most recent call last):
  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\site-packages\prefect\workers\process.py"", line 193, in start
    printer(f""Worker {worker.name!r} started!"")
  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\site-packages\anyio\_backends\_asyncio.py"", line 767, in __aexit__
    raise exc_val
  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\site-packages\anyio\_backends\_asyncio.py"", line 741, in __aexit__
    await _wait(self._tasks)
  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\site-packages\anyio\_backends\_asyncio.py"", line 706, in _wait
    await waiter
asyncio.exceptions.CancelledError: Cancelled by cancel scope 1bb3dba7580

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\contextlib.py"", line 634, in __aexit__
    cb_suppress = await cb(*exc_details)
  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\site-packages\prefect\runner\runner.py"", line 1688, in __aexit__
    await self._runs_task_group.__aexit__(*exc_info)
  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\site-packages\anyio\_backends\_asyncio.py"", line 763, in __aexit__
    raise BaseExceptionGroup(
exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\site-packages\prefect\cli\_utilities.py"", line 44, in wrapper
    return fn(*args, **kwargs)
  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\site-packages\prefect\cli\_types.py"", line 155, in sync_fn
    return asyncio.run(async_fn(*args, **kwargs))
  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\asyncio\runners.py"", line 44, in run
    return loop.run_until_complete(main)
  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\asyncio\base_events.py"", line 642, in run_until_complete
    return future.result()
  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\site-packages\prefect\cli\worker.py"", line 169, in start
    await worker.start(
  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\site-packages\prefect\workers\process.py"", line 193, in start
    printer(f""Worker {worker.name!r} started!"")
  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\site-packages\prefect\workers\process.py"", line 242, in __aexit__
    await super().__aexit__(*exc_info)
  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\site-packages\prefect\workers\base.py"", line 1344, in __aexit__
    await self.teardown(*exc_info)
  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\site-packages\prefect\workers\base.py"", line 726, in teardown
    await self._exit_stack.__aexit__(*exc_info)
  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\contextlib.py"", line 651, in __aexit__
    raise exc_details[1]
  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\contextlib.py"", line 634, in __aexit__
    cb_suppress = await cb(*exc_details)
  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\site-packages\anyio\_backends\_asyncio.py"", line 763, in __aexit__
    raise BaseExceptionGroup(
exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)

An exception occurred.
Exception in thread Tornado selector:
Traceback (most recent call last):
  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\threading.py"", line 954, in _bootstrap_inner
    self.run()
  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\threading.py"", line 892, in run
    self._target(*self._args, **self._kwargs)
  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\site-packages\tornado\platform\asyncio.py"", line 573, in _run_select
    self._real_loop.call_soon_threadsafe(self._handle_select, rs, ws)
  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\asyncio\base_events.py"", line 791, in call_soon_threadsafe
    self._check_closed()
  File ""C:\Users\svc_user123\.conda\envs\junto_prod_prefect3\lib\asyncio\base_events.py"", line 510, in _check_closed
    raise RuntimeError('Event loop is closed')
RuntimeError: Event loop is closed

```

</details>

### Version info

```Text
Version:             3.2.14
API version:         0.8.4
Python version:      3.9.4
Git commit:          efcde6dc
Built:               Fri, Mar 21, 2025 5:28 PM
OS/Arch:             win32/AMD64
Profile:             ephemeral
Server type:         cloud
Pydantic version:    2.9.2
Integrations:
  prefect-dask:      0.3.3
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17585/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17585
17579,Prefect seems to require typing_extensions version at least 4.10.0,closed,completed,2025-03-24T15:02:25Z,2025-03-24T15:34:22Z,2025-03-24T15:34:21Z,1,['bug'],mch-sb,,NONE,"### Bug summary

Prefect does not seem to work with `typing_extensions` (https://github.com/python/typing_extensions) less than `4.10.0`, as `prefect` seems to need `TypeIs` (https://github.com/PrefectHQ/prefect/blob/9a6cd2af582a2e846ad3058fd87c01cac2572795/src/prefect/tasks.py#L30). 
This should be reflected in the `pyproject.toml`-file, https://github.com/PrefectHQ/prefect/blob/9a6cd2af582a2e846ad3058fd87c01cac2572795/pyproject.toml#L79 ?

### Version info

```Text
Version:             3.2.14
API version:         0.8.4
Python version:      3.11.9
Git commit:          efcde6dc
Built:               Fri, Mar 21, 2025 5:28 PM
OS/Arch:             linux/x86_64
Profile:             ephemeral
Server type:         ephemeral
Pydantic version:    2.10.6
Server:
  Database:          sqlite
  SQLite version:    3.37.2
Integrations:
  prefect-shell:     0.3.1
  prefect-dbt:       0.6.6
  prefect-docker:    0.6.2
```

### Additional context

_No response_",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17579/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17579
17578,Cannot find prefect.yaml,closed,completed,2025-03-24T14:09:25Z,2025-03-24T15:58:28Z,2025-03-24T15:58:27Z,3,['bug'],lisc67,,NONE,"### Bug summary

Hi all,

I am new to Prefect. I am trying to create a deployment using the **prefect init** command but it fails as the system cannot find the templates / recipes folder. The system search the folder:

/usr/local/lib/python3.11/site-packages/prefect/deployments/templates

While the correct path on the system seems to be

/usr/local/lib/python3.11/site-packages/prefect/deployments/recipes

I there any env variable I can set to change this search path? Is this a bug?

Thank you!

### Version info

```Text
Version:             3.2.11
API version:         0.8.4
Python version:      3.11.11
Git commit:          9481694f
Built:               Thu, Mar 6, 2025 3:27 AM
OS/Arch:             linux/x86_64
Profile:             ephemeral
Server type:         server
Pydantic version:    2.10.6
Integrations:
  prefect-redis:     0.2.2
  prefect-kubernetes: 0.5.8
```

### Additional context

_No response_",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17578/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17578
17576,Add a possibility to guarantee local execution of flows when directly calling Python functions is not an option,open,,2025-03-24T09:58:43Z,2025-03-24T16:38:38Z,,4,['enhancement'],NicholasPini,,NONE,"### Describe the current behavior

As far as I've understood, at the moment flows can be served or deployed locally, which is fine. The problem is that my monorepo has a bunch of separated Python projects, each of which is a different Prefect flow. The only way to test these flows locally is to rely on Prefect and use `run_deployment`, because I cannot import one project into another (it would mess up dependencies and defeat the whole purpose of keeping these projects separated). 

I don't mind this, but the problem is that when I run a local worker (either from serving a flow, or for a process workpool), this worker can be used by anyone. This means that if me and another person are testing the same flow locally, and run a worker each for the same served flow, I cannot guarantee that my flow is run on my machine. This can be problematic if me and the other person are running different version of the source code, causing problems. 

### Describe the proposed behavior

It would be nice to have some way to guarantee this behavior: if I run `run_deployment` for a flow, which is deployed locally or served, I would like to have an option to make sure it only runs on a worker executing on my local machine. Not sure if it already possible, or if it possible to implement it. 

The only work around I've found is to create a different process work pool, one for each person working on the project, which is a bit annoying and unwieldy.

### Example Use

_No response_

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17576/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17576
17575,How to cancel late runs that are late beyond a threshold,closed,completed,2025-03-24T07:51:36Z,2025-03-31T11:56:37Z,2025-03-31T11:56:36Z,2,['enhancement'],satwikkansal,,NONE,"### Describe the current behavior

I'm not sure how to achieve this currently, maybe write a client side job like this? https://docs.prefect.io/v3/develop/interact-with-api#reschedule-late-flow-runs 

### Describe the proposed behavior

It'd be nice to have a way to skip the late runs if they get late beyond a threshold, and set this threshold in the configuration.

### Example Use

_No response_

### Additional context

_No response_",satwikkansal,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17575/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17575
17574,Error while using PostgreSQL for prefect,open,,2025-03-24T06:57:16Z,2025-03-31T10:45:36Z,,4,['bug'],satwikkansal,,NONE,"### Bug summary

I'm not able to spin up prefect server. Here's the stack trace

```
git:(sync-positions-prefect) âœ— prefect server start

 ___ ___ ___ ___ ___ ___ _____
| _ \ _ \ __| __| __/ __|_   _|
|  _/   / _|| _|| _| (__  | |
|_| |_|_\___|_| |___\___| |_|

Configure Prefect to communicate with the server with:

    prefect config set PREFECT_API_URL=http://127.0.0.1:4200/api

View the API reference documentation at http://127.0.0.1:4200/docs

Check out the dashboard at http://127.0.0.1:4200




ERROR:    Traceback (most recent call last):
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py"", line 545, in _prepare_and_execute
    self._rows = deque(await prepared_stmt.fetch(*parameters))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/asyncpg/prepared_stmt.py"", line 176, in fetch
    data = await self.__bind_execute(args, 0, timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/asyncpg/prepared_stmt.py"", line 267, in __bind_execute
    data, status, _ = await self.__do_execute(
                      ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/asyncpg/prepared_stmt.py"", line 256, in __do_execute
    return await executor(protocol)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""asyncpg/protocol/protocol.pyx"", line 206, in bind_execute
asyncpg.exceptions.DuplicateTableError: relation ""trgm_ix_flow_name"" already exists

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py"", line 1964, in _exec_single_context
    self.dialect.do_execute(
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/default.py"", line 942, in do_execute
    cursor.execute(statement, parameters)
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py"", line 580, in execute
    self._adapt_connection.await_(
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py"", line 132, in await_only
    return current.parent.switch(awaitable)  # type: ignore[no-any-return,attr-defined] # noqa: E501
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py"", line 196, in greenlet_spawn
    value = await result
            ^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py"", line 558, in _prepare_and_execute
    self._handle_exception(error)
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py"", line 508, in _handle_exception
    self._adapt_connection._handle_exception(error)
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py"", line 792, in _handle_exception
    raise translated_error from error
sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_dbapi.ProgrammingError: <class 'asyncpg.exceptions.DuplicateTableError'>: relation ""trgm_ix_flow_name"" already exists

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/starlette/routing.py"", line 692, in lifespan
    async with self.lifespan_context(app) as maybe_state:
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py"", line 210, in __aenter__
    return await anext(self.gen)
           ^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/prefect/server/api/server.py"", line 616, in lifespan
    await run_migrations()
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/prefect/server/api/server.py"", line 596, in run_migrations
    await db.create_db()
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/prefect/server/database/interface.py"", line 77, in create_db
    await self.run_migrations_upgrade()
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/prefect/server/database/interface.py"", line 85, in run_migrations_upgrade
    await run_sync_in_worker_thread(alembic_upgrade)
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/prefect/utilities/asyncutils.py"", line 233, in run_sync_in_worker_thread
    result = await anyio.to_thread.run_sync(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/anyio/to_thread.py"", line 56, in run_sync
    return await get_async_backend().run_sync_in_worker_thread(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/anyio/_backends/_asyncio.py"", line 2461, in run_sync_in_worker_thread
    return await future
           ^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/anyio/_backends/_asyncio.py"", line 962, in run
    result = context.run(func, *args)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/prefect/utilities/asyncutils.py"", line 243, in call_with_mark
    return call()
           ^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/prefect/server/database/alembic_commands.py"", line 36, in wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/prefect/server/database/alembic_commands.py"", line 72, in alembic_upgrade
    alembic.command.upgrade(alembic_config(), revision, sql=dry_run)
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/alembic/command.py"", line 406, in upgrade
    script.run_env()
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/alembic/script/base.py"", line 586, in run_env
    util.load_python_file(self.dir, ""env.py"")
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/alembic/util/pyfiles.py"", line 95, in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/alembic/util/pyfiles.py"", line 113, in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""<frozen importlib._bootstrap_external>"", line 999, in exec_module
  File ""<frozen importlib._bootstrap>"", line 488, in _call_with_frames_removed
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/prefect/server/database/_migrations/env.py"", line 201, in <module>
    run_async_from_worker_thread(apply_migrations)
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/prefect/utilities/asyncutils.py"", line 254, in run_async_from_worker_thread
    return anyio.from_thread.run(call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/anyio/from_thread.py"", line 59, in run
    return async_backend.run_async_from_thread(func, args, token=token)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/anyio/_backends/_asyncio.py"", line 2501, in run_async_from_thread
    return f.result()
           ^^^^^^^^^^
  File ""/usr/local/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py"", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py"", line 401, in __get_result
    raise self._exception
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/anyio/_backends/_asyncio.py"", line 2488, in task_wrapper
    return await func(*args)
           ^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/prefect/server/database/_migrations/env.py"", line 190, in apply_migrations
    await connection.run_sync(do_run_migrations)
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/ext/asyncio/engine.py"", line 887, in run_sync
    return await greenlet_spawn(
           ^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py"", line 201, in greenlet_spawn
    result = context.throw(*sys.exc_info())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/prefect/server/database/_migrations/env.py"", line 159, in do_run_migrations
    context.run_migrations()
  File ""<string>"", line 8, in run_migrations
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/alembic/runtime/environment.py"", line 946, in run_migrations
    self.get_context().run_migrations(**kw)
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/alembic/runtime/migration.py"", line 623, in run_migrations
    step.migration_fn(**kw)
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/prefect/server/database/_migrations/versions/postgresql/2022_06_04_133535_d60c18774a5d_add_indexes_for_partial_name_matches.py"", line 23, in upgrade
    op.execute(
  File ""<string>"", line 8, in execute
  File ""<string>"", line 3, in execute
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/alembic/operations/ops.py"", line 2551, in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/alembic/operations/base.py"", line 442, in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/alembic/operations/toimpl.py"", line 236, in execute_sql
    operations.migration_context.impl.execute(
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/alembic/ddl/impl.py"", line 254, in execute
    self._exec(sql, execution_options)
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/alembic/ddl/impl.py"", line 247, in _exec
    return conn.execute(construct, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py"", line 1416, in execute
    return meth(
           ^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/sql/elements.py"", line 516, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py"", line 1638, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py"", line 1843, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py"", line 1983, in _exec_single_context
    self._handle_dbapi_exception(
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py"", line 2352, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py"", line 1964, in _exec_single_context
    self.dialect.do_execute(
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/default.py"", line 942, in do_execute
    cursor.execute(statement, parameters)
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py"", line 580, in execute
    self._adapt_connection.await_(
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py"", line 132, in await_only
    return current.parent.switch(awaitable)  # type: ignore[no-any-return,attr-defined] # noqa: E501
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py"", line 196, in greenlet_spawn
    value = await result
            ^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py"", line 558, in _prepare_and_execute
    self._handle_exception(error)
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py"", line 508, in _handle_exception
    self._adapt_connection._handle_exception(error)
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py"", line 792, in _handle_exception
    raise translated_error from error
sqlalchemy.exc.ProgrammingError: (sqlalchemy.dialects.postgresql.asyncpg.ProgrammingError) <class 'asyncpg.exceptions.DuplicateTableError'>: relation ""trgm_ix_flow_name"" already exists
[SQL: 
            CREATE INDEX CONCURRENTLY 
            trgm_ix_flow_name 
            ON flow USING gin (name gin_trgm_ops);
            ]
(Background on this error at: https://sqlalche.me/e/20/f405)

ERROR:    Application startup failed. Exiting.
```

### Version info

```Text
Version:             3.2.12
API version:         0.8.4
Python version:      3.12.9
Git commit:          826eb1a7
Built:               Mon, Mar 10, 2025 4:36 PM
OS/Arch:             darwin/x86_64
Profile:             local
Server type:         server
Pydantic version:    2.10.6
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17574/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17574
17563,"Flow Run Stuck in Cancelling Status, not transit to Cancelled",closed,completed,2025-03-21T19:13:08Z,2025-03-25T17:17:19Z,2025-03-25T17:16:48Z,4,['bug'],yesheneve,,NONE,"### Bug summary

1. Set the deployment concurrency_limit as 1.
2. Click Cancel button on UI for an ongoing run.
3. Check the status of that run after a while. Flow Run Stuck in Cancelling Status, not transit to Cancelled. Here is the log for that run at the end from ECS task 
```
| INFO | prefect.runner - Found 1 flow runs awaiting cancellation.
| ERROR | Task run 'generation_task-29c' - Crash detected! Execution was aborted by a termination signal.
| ERROR | Task run 'generation_task-29c' - Finished in state Crashed('Execution was aborted by a termination signal.')
| INFO | prefect.flow_runs.runner - Process for flow run 'sturdy-leech' exited with status code: -15; This indicates that the process exited due to a SIGTERM signal. Typically, this is caused by manual cancellation.
```
3. Check the Concurrency, that run will still occupy one Active Slots. It does not release the active slot.


### Version info

```Text
Version:             3.2.12
API version:         0.8.4
Python version:      3.11.11
Git commit:          826eb1a7
Built:               Mon, Mar 10, 2025 4:36 PM
OS/Arch:             linux/x86_64
Profile:             ephemeral
Server type:         ephemeral
Pydantic version:    2.10.6
Server:
  Database:          AWS RDS Postgres
  Postgres version:  16.4
Integrations:
  prefect-aws:       0.5.5
```

### Additional context

Found those https://github.com/PrefectHQ/prefect/issues/16001 and https://github.com/PrefectHQ/prefect/pull/14611.
We check the ECS console and saw this
```
Command
[""prefect"",""flow-run"",""execute""]
```
Also, we could confirm that the command field on our work pool's base job template is empty.",yesheneve,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17563/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17563
17562,Prefect OS UI Bugged when two flow parameters are dataclasses with same interfac,open,,2025-03-21T19:11:05Z,2025-03-22T16:04:40Z,,0,"['bug', 'ui']",jonahduffin,,NONE,"### Bug summary

If you deploy a flow that accepts a parameter that can be one of two or more types, the Prefect UI allows you to select which type you'd like to provide when executing the deployment.

This UI is bugged if you provide two dataclasses that are different classes with different names, but have the same or similar attributes. In the MRE below, DataclassOne is selected by default, and if you try to select DataclassTwo in the UI, it will appear selected but will immediately switch back to DataclassOne if you type in any of the form fields for DataclassTwo. In short, you can't use DataclassTwo at all via the deployment UI if it has the same properties as DataclassOne.

MRE:
```
from dataclasses import dataclass

from prefect import flow


@dataclass(frozen=True)
class DataclassOne:
    name: str
    dir: str
    flag1: bool
    dict1: dict[str, str] | None = None
    str_path_1: str | None = None
    str_path_2: str | None = None
    str_path_3: str | None = None

    @property
    def value(self) -> str:
        return f'DATACLASS_ONE_{self.name}'


@dataclass(frozen=True)
class DataclassTwo:
    name: str
    dir: str
    flag1: bool
    dict1: dict[str, str] | None = None
    str_path_1: str | None = None
    str_path_2: str | None = None
    str_path_3: str | None = None

    @property
    def value(self) -> str:
        return f'DATACLASS_TWO_{self.name}'


ValidType = DataclassOne | DataclassTwo


@flow
def prefect_ui_mre(valid_type: ValidType):
    print(valid_type)


if __name__ == ""__main__"":
    prefect_ui_mre.serve()
```
If you change the name of a single attribute in DataclassTwo, then you can squirm your way into filling in the form fields, but it's still pretty buggy. You have to click the ""DataclassTwo"" type multiple times until it really switches over. 

### Version info

```Text
Version:             3.2.12.dev4
API version:         0.8.4
Python version:      3.10.16
Git commit:          733a6c28
Built:               Sun, Mar 9, 2025 8:08 AM
OS/Arch:             darwin/arm64
Profile:             ephemeral
Server type:         server
Pydantic version:    2.11.0b1
Integrations:
  prefect-aws:       0.5.5
```

### Additional context

When two dataclasses with the same attributes are used as alternative type options, you can at first select the second dataclass:

![Image](https://github.com/user-attachments/assets/31682292-ea59-4e3a-86f3-c8d7a9accf2b)

But typing in any form field will immediately switch back to the first dataclass, rendering the second unusable.

![Image](https://github.com/user-attachments/assets/37b22f32-328d-43c3-9436-e48b3a0b2dd7)

Lots of other buggy UI stuff happens in this scenario but this seems to be the primary issue.",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17562/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17562
17557,Result Persistence Doesn't Work With `run_deployment` Submitted Async,open,,2025-03-21T14:48:52Z,2025-03-21T16:04:35Z,,2,['bug'],kr-hansen,,NONE,"### Bug summary

When I try using result persistence for submitting flows in parallel using `run_deployment`, I cannot get the results back from those deployment using the `result_persistence` and `result_storage` parameters.  I only get back `coroutines` without being able to get the results.

If I run/submit the same flows to `run_deployment` not in an async fashion, I can get the results back just fine.  It is just a function of how the async functionality works in the flow.

## Minimum Reproducible Example
```
import asyncio
from typing import List

from prefect import flow, task
from prefect.client.schemas import FlowRun
from prefect.deployments import run_deployment
from prefect_gcp import GcsBucket
from prefect_ray import RayTaskRunner

result_storage = GcsBucket(
    bucket=""my-bucket"",
    bucket_folder=""Prefect3Test"",
)
result_storage.save(name=""prefect3test-results"", overwrite=True, _sync=True)

@flow(
    log_prints=True,
    result_storage=result_storage,
    persist_result=True,
    retries=1,
    name=""persist_test"",
    task_runner=RayTaskRunner,
)
def persist_test(some_param: int):
    success_task = passing_task(some_param = some_param)
    return success_task

@task
def passing_task(some_param: int = 42, parent_run_id=None):
    print(""This task should be skipped on retry"")
    return some_param

@flow(log_prints=True, task_runner=RayTaskRunner)
async def parent_flow():
    # run the run_deployment_of_child_flow task via the ThreadPoolTaskRunner and wait for the
    #  result and return the result

    runs: List[FlowRun] = await asyncio.gather(
        *[
            run_deployment(
                name=""persist_test/persist_test"",
                parameters={""some_param"": val},
            ) 
            for val in range(2)
        ]
    )

    print([run.state.result(fetch=True) for run in runs])

if __name__ == ""__main__"":
    asyncio.run(parent_flow(), debug=True)
```

What I get in the final print statement is `[<coroutine object sync_compatible.<locals>.coroutine_wrapper.<locals>.ctx_call at 0x11f2cbb40>, <coroutine object sync_compatible.<locals>.coroutine_wrapper.<locals>.ctx_call at 0x128325b40>]`.

If I drop the `await asyncio.gather` and just get a list of flow runs, then I get back `[0, 1]` as I'd expect.

Is there a better way to submit deployments in parallel instead of in series than using `asyncio.gather`?  Or is there a way to make it so I can get results back from these deployments in an async manner?

### Version info

```Text
Version:             3.2.13
API version:         0.8.4
Python version:      3.11.6
Git commit:          12800297
Built:               Fri, Mar 14, 2025 8:37 PM
OS/Arch:             darwin/arm64
Profile:             local
Server type:         server
Pydantic version:    2.10.6
Integrations:
  prefect-gcp:       0.6.4
  prefect-ray:       0.4.3
```

### Additional context

I wanted to confirm `prefect-ray` wasn't the main cause here, and I'm pretty sure it isn't.  I kept it in the example, but it could be dropped for reproducing the problem most likely.",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17557/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17557
17555,Incorrect dbt profiles dir setting resolution logic in `PrefectDbtSettings`,open,,2025-03-21T12:43:38Z,2025-03-28T10:24:58Z,,12,['bug'],trymzet,,CONTRIBUTOR,"### Bug summary

`dbt` looks in 3 places to decide the profiles directory, in this order:
 - `DBT_PROFILES_DIR` env var
- `<project_dir>/.dbt`
- `~/.dbt`

However, `PrefectDbtSettings` only looks at env vars and uses `Path.home() / "".dbt""` as the default. This is incorrect, as CWD's `.dbt` directory should take precedence over home directory's one.

In other words, this leads to the problem where dbt projects with `profiles.yml` file located in the project don't work with `PrefectDbtRunner`.

What I don't understand is, why is Prefect managing dbt settings [here](https://github.com/PrefectHQ/prefect/blob/cf27aaebfd27dac7eeef5054dcc6ace47e6e1a7a/src/integrations/prefect-dbt/prefect_dbt/core/settings.py#L15-L16) instead of letting dbt (`dbtRunner`) handle them, simply passing over what the user specified?

### Additional context

Possibly related problem - getting ""path `<home>/.dbt` not found despite passing both `project_dir` and `profiles_dir` to `PrefectDbtSettings`:

```python
Traceback (most recent call last):
  File ""/usr/local/lib/python3.12/site-packages/prefect/task_engine.py"", line 805, in run_context
    yield self
  File ""/usr/local/lib/python3.12/site-packages/prefect/task_engine.py"", line 1387, in run_task_sync
    engine.call_task_fn(txn)
  File ""/usr/local/lib/python3.12/site-packages/prefect/task_engine.py"", line 828, in call_task_fn
    result = call_with_parameters(self.task.fn, parameters)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/prefect/utilities/callables.py"", line 208, in call_with_parameters
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File ""/opt/prefect/src/edp_flows/flows/transform.py"", line 20, in dbt_run
    return dbt(
           ^^^^
  File ""/opt/prefect/src/edp_flows/flows/utils.py"", line 182, in dbt_prefect
    return dbt_runner.invoke(args)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/prefect_dbt/core/runner.py"", line 423, in invoke
    self.parse()
  File ""/usr/local/lib/python3.12/site-packages/prefect_dbt/core/runner.py"", line 326, in parse
    raise ValueError(f""Failed to load manifest: {res.exception}"")
ValueError: Failed to load manifest: Path '/.dbt' does not exist.
```

I'm not sure where Prefect is getting the `/.dbt` path from - probably somehow the default value of `PrefectDbtSettings.profiles_dir` is used despite me passing `profiles_dir` to the constructor explicitly.",,1,https://api.github.com/repos/PrefectHQ/prefect/issues/17555/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17555
17553,"Prefect Docker Worker, increase client timeout",closed,completed,2025-03-21T09:59:29Z,2025-03-21T16:42:37Z,2025-03-21T16:42:37Z,0,['enhancement'],jbw-vtl,,CONTRIBUTOR,"### Describe the current behavior

We have been running Prefect at a growing scale on Linux, starting to run into timeouts when prefect tries to create many containers via a docker worker at once.

We could not find any configuration options of changing the timeout used within the prefect docker client and it does not adhere to the `DOCKER_CLIENT_TIMEOUT` variables.

### Describe the proposed behavior

Proposing a small enhancement to have the docker client used within the docker worker adhere to `DOCKER_CLIENT_TIMEOUT`.
This would allow controlling the timeout via the environment variables set on the agent.

Attaching a small PR with proposed integration.

As a follow up larger PR, it could also make sense to fully expose the client kwargs as a field in the docker worker configuration, similar to what was done with for the DockerHost block.
That however seems a bit more involved

### Example Use

We are using prefect within docker compose, looking to leverage configuration such as below to tweak the timeout

```yaml
agent:
    image: ...
    restart: always
    entrypoint: [""/opt/prefect/entrypoint.sh"", ""prefect"", ""worker"", ""start"", ""--pool"", ""docker-pool"", ""--work-queue"", ""default"", ""--type"", ""docker""]
    environment:
      - PREFECT_API_URL=http://server:4200/api
      - DOCKER_CLIENT_TIMEOUT=120
      - DD_AGENT_HOST=host.docker.internal
```

### Additional context

_No response_",desertaxle,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17553/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17553
17550,Scheduled runs for overlapping schedules on the same deployment only trigger once,closed,completed,2025-03-20T21:22:51Z,2025-03-26T16:16:31Z,2025-03-26T16:16:30Z,3,['bug'],masonmenges,cicdw,CONTRIBUTOR,"### Bug summary

If multiple schedules are defined with overlapping schedules but different parameters for the same deployment only one run of the deployment is triggered when a scheduled start time passes for the deployment instead of one run for each schedule.

```
  - name: ""schedule_param_testing""
    version: ""{{ $VERSION }}""
    tags: []
    description: null
    entrypoint: flows/demo.py:demo_flow
    schedules:
      - cron: ""50 11 * * 2-5""
        timezone: ""America/Denver""
        active: true
        parameters:
          date: ""03/19/2025""
          configs: {""name"": ""prefect2""}
      - cron: ""50 11 * * 2-5""
        timezone: ""America/Denver""
        active: true
        parameters:
          date: ""03/14/2025""
          configs: {""name"": ""prefect2""}
    work_pool:
    name: k8s-minikube-test
    work_queue_name: null
    build: null
```

### Version info

```Text
Version:             3.2.12
API version:         0.8.4
Python version:      3.12.4
Git commit:          826eb1a7
Built:               Mon, Mar 10, 2025 4:36 PM
OS/Arch:             darwin/arm64
Profile:             masonsandbox
Server type:         cloud
Pydantic version:    2.10.6
Integrations:
  prefect-dask:      0.3.2
  prefect-snowflake: 0.28.0
  prefect-slack:     0.3.0
  prefect-gcp:       0.6.2
  prefect-aws:       0.5.0
  prefect-gitlab:    0.3.1
  prefect-dbt:       0.6.4
  prefect-kubernetes: 0.5.8
  prefect-docker:    0.6.1
  prefect-sqlalchemy: 0.5.1
  prefect-shell:     0.3.1
```

### Additional context

_No response_",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17550/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17550
17547,Task caching doesn't work when using default policy if an input is a result from another task that is a pandas dataframe,closed,completed,2025-03-20T20:17:28Z,2025-03-27T18:01:57Z,2025-03-27T18:01:57Z,6,['bug'],jbnitorum,,NONE,"### Bug summary

I have noticed when retrying failed flows runs that many of the tasks in the flow are rerunning despite having completely successfully and have a persisted result.  Looking into it further it appears the issue is when the one or more of the inputs for one task is the result of another task and that result is a pandas dataframe.  We recently migrated from Prefect 2 to Prefect 3 and this was never an issue previously so let me know if I am missing a behavior change.  I am able to see the resulting dataframe result on S3.  I suspect this must be some issues related to serialization.

We have the following settings:
```
PREFECT_RESULTS_PERSIST_BY_DEFAULT=true
PREFECT_DEFAULT_RESULT_STORAGE_BLOCK='s3-bucket/my-bucket-block'
```

Here is an example.  We are running this on AWS ECS Fargate and using Prefect Cloud.  There should be cache hits on tasks 7, 8, and 9 on an initial run.  If you retry the flow you should have cache hits on all tasks.  What I'm seeing is only cache hits on 7 and 9 on an initial run and hits on 1, 4, 5 , 6, 7 and 9.  Missing on 2, 3, and 8.

```python
from prefect import flow, task, get_run_logger
import pandas as pd
import boto3
import requests
import io

@task(name=""Getting data"")
def extract(return_df=True):
    if return_df:
        url = 'https://www.federalreserve.gov/datadownload/Output.aspx?rel=H8&series=dd48166f12d986aede821fb86d9185d7&lastobs=&from=&to=&filetype=csv&label=include&layout=seriescolumn&type=package'
        r = requests.get(url)
        df = pd.read_csv(io.StringIO(r.content.decode('utf-8')))
        return df
    else:
        return 'this is a string'

@task(name=""Doing something with data"")
def transform(df_or_string):
    if isinstance(df_or_string, str):
        print('this is a string')
        the_string = df_or_string +' more string'
        return the_string
    else:
        df = df_or_string
        df['new_col'] = 'Add this constant'
        return df

@task(name=""Log output of transform"")
def load(df):
    logger = get_run_logger()
    logger.info(df)
    
@flow(name=""Retry Test"")
def main_flow():
    data_frame = extract(return_df = True)  ### caches on retry
    df_transformed = transform(data_frame) ### DOES NOT CACHE ON RETRY BECAUSE IT HAS AN INPUT THAT IS A DATAFRAME TYPE CACHED TASK RESULT
    _ = load(df_transformed) ### DOES NOT CACHE ON RETRY BECAUSE IT HAS AN INPUT THAT IS A DATAFRAME TYPE CACHED TASK RESULT

    string_text = extract(return_df = False) ### caches on retry
    longer_string = transform(string_text) ### caches on retry
    _ = load(longer_string) ### caches on retry

    data_frame2 = extract(return_df = True)  ### this caches on initial run and on caches on retry
    df_transformed2 = transform(data_frame2) ### DOES NOT CACHE ON INTITIAL RUN OR RETRY BECAUSE IT HAS AN INPUT THAT IS A DATAFRAME TYPE CACHED TASK RESULT
    _ = load(df_transformed2) ### THIS CACHES ON INTIIAL RUN AND ON RETRY..... not sure why this is different than the line above...???????

if __name__ == ""__main__"":
    main_flow()
```

### Version info

```Text
Version:             3.2.7
API version:         0.8.4
Python version:      3.10.16
Git commit:          d4d9001e
Built:               Fri, Feb 21, 2025 7:41 PM
OS/Arch:             linux/x86_64
Profile:             ephemeral
Server type:         ephemeral
Pydantic version:    2.10.6
Server:
  Database:          sqlite
  SQLite version:    3.40.1
Integrations:
  prefect-aws:       0.5.5
  prefect-dask:      0.3.3
  prefect-dbt:       0.7.0rc1
  prefect-shell:     0.3.1
  prefect-snowflake: 0.28.2
  prefect-redis:     0.2.2
```

### Additional context

_No response_",cicdw,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17547/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17547
17546,Out of process task runner does not correctly load result storage,closed,completed,2025-03-20T18:47:55Z,2025-03-21T14:59:09Z,2025-03-21T14:59:09Z,6,['bug'],bnaul,,CONTRIBUTOR,"### Bug summary

I am using the DaskTaskRunner but I reproduced the same behavior with RayTaskRunner:
```
from prefect import task, flow
from prefect_dask import DaskTaskRunner

@task(result_storage_key=""{task_run.id}.prefect_result"")
def speak():
    return ""hey""

@flow(task_runner=DaskTaskRunner(cluster_kwargs={""env"": dict(PREFECT_RESULTS_DEFAULT_STORAGE_BLOCK=""gcs-bucket/model-prefect-tmp"")}))
def hello():
    return speak.submit()

if __name__ == '__main__':
    hello()
```
gives
```
14:42:56.383 | ERROR   | Task run 'speak-8f8' - An error was encountered while committing transaction '0dfe47d2-d785-4302-8350-05ad385e9db2.prefect_result'
Traceback (most recent call last):
  File ""/Users/brett/model/.venv/lib/python3.10/site-packages/prefect/transactions.py"", line 312, in commit
    self.store.persist_result_record(
  File ""/Users/brett/model/.venv/lib/python3.10/site-packages/prefect/results.py"", line 828, in persist_result_record
    return self._persist_result_record(
  File ""/Users/brett/model/.venv/lib/python3.10/site-packages/prefect/utilities/asyncutils.py"", line 347, in coroutine_wrapper
    return run_coro_as_sync(ctx_call())
  File ""/Users/brett/model/.venv/lib/python3.10/site-packages/prefect/utilities/asyncutils.py"", line 207, in run_coro_as_sync
    return call.result()
  File ""/Users/brett/model/.venv/lib/python3.10/site-packages/prefect/_internal/concurrency/calls.py"", line 329, in result
    return self.future.result(timeout=timeout)
  File ""/Users/brett/model/.venv/lib/python3.10/site-packages/prefect/_internal/concurrency/calls.py"", line 192, in result
    return self.__get_result()
  File ""/opt/homebrew/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py"", line 403, in __get_result
    raise self._exception
  File ""/Users/brett/model/.venv/lib/python3.10/site-packages/prefect/_internal/concurrency/calls.py"", line 402, in _run_async
    result = await coro
  File ""/Users/brett/model/.venv/lib/python3.10/site-packages/prefect/utilities/asyncutils.py"", line 188, in coroutine_wrapper
    return await task
  File ""/Users/brett/model/.venv/lib/python3.10/site-packages/prefect/utilities/asyncutils.py"", line 341, in ctx_call
    result = await async_fn(*args, **kwargs)
  File ""/Users/brett/model/.venv/lib/python3.10/site-packages/prefect/results.py"", line 776, in _persist_result_record
    base_key = str(Path(key).relative_to(basepath))
  File ""/opt/homebrew/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/pathlib.py"", line 809, in relative_to
    to_drv, to_root, to_parts = self._parse_args(other)
  File ""/opt/homebrew/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/pathlib.py"", line 578, in _parse_args
    a = os.fspath(a)
TypeError: expected str, bytes or os.PathLike object, not NoneType
14:42:56.388 | INFO    | Task run 'speak-8f8' - Finished in state Completed()
```
If I explicitly pass the `result_storage=""gcs-bucket/model-prefect-tmp""` to the `@task` decorator, the result does get persisted correctly. So it seems to have something to do with creating the storage block from an environment variable, but only with an external task runner as far as I can tell (just setting the default storage block in my local settings persists to GCS correctly).

I did not try to reproduce this with e.g. S3 storage, but from glancing at the `GcsBucket` logic which is quite simple it seems like the issue has to be deeper in the `Block` class itself.

### Version info

```Text
Version:             3.2.13
API version:         0.8.4
Python version:      3.10.16
Git commit:          12800297
Built:               Fri, Mar 14, 2025 8:37 PM
OS/Arch:             darwin/arm64
Profile:             default
Server type:         cloud
Pydantic version:    2.9.2
Integrations:
  prefect-gcp:       0.6.2
  prefect-dask:      0.3.3
  prefect-ray:       0.4.3
  prefect-kubernetes: 0.5.3
```

### Additional context

_No response_",cicdw,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17546/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17546
17542,ACI worker doesn't add non-`ACRManagedIdentity` image registry credentials to `arm_template`,closed,completed,2025-03-20T14:53:15Z,2025-03-20T20:02:01Z,2025-03-20T20:02:00Z,0,['bug'],kevingrismore,,CONTRIBUTOR,"### Bug summary

The [`DockerRegistry` type alias](https://github.com/PrefectHQ/prefect/blob/main/src/integrations/prefect-azure/prefect_azure/workers/container_instance.py#L126) allows for any data to be supplied, but only constructs a model with attributes for data matching the shape of [`ACRManagedIdentity`](https://github.com/PrefectHQ/prefect/blob/main/src/integrations/prefect-azure/prefect_azure/container_instance.py#L103).

If data in the format of standard Docker registry credentials is supplied as the default for `image_registry` is included as described in the default base job template,
```json
""image_registry"": {
        ""anyOf"": [
          {
            ""$ref"": ""#/definitions/DockerRegistry""
          },
          {
            ""$ref"": ""#/definitions/ACRManagedIdentity""
          }
        ],

...

    ""definitions"": {
      ""DockerRegistry"": {
        ""type"": ""object"",
        ""title"": ""DockerRegistry"",
        ""required"": [
          ""username"",
          ""password"",
          ""registry_url""
        ],
        ""properties"": {
          ""reauth"": {
            ""type"": ""boolean"",
            ""title"": ""Reauth"",
            ""default"": true,
            ""description"": ""Whether or not to reauthenticate on each interaction.""
          },
          ""password"": {
            ""type"": ""string"",
            ""title"": ""Password"",
            ""format"": ""password"",
            ""writeOnly"": true,
            ""description"": ""The password to log into the registry with.""
          },
          ""username"": {
            ""type"": ""string"",
            ""title"": ""Username"",
            ""description"": ""The username to log into the registry with.""
          },
          ""registry_url"": {
            ""type"": ""string"",
            ""title"": ""Registry Url"",
            ""description"": ""The URL to the registry. Generally, \""http\"" or \""https\"" can be omitted.""
          }
        },
        ""description"": ""Connects to a Docker registry.\n\nRequires a Docker Engine to be connectable."",
        ""secret_fields"": [
          ""password""
        ],
        ""block_type_slug"": ""docker-registry"",
        ""block_schema_references"": {}
      }
```
such as
```json
        ""default"": {
          ""username"": ""test"",
          ""password"": ""test"",
          ""registry_url"": ""test""
        },
```
or
```json
        ""default"": {
          ""$ref"": {
             ""block_document_id"": ""<some-docker-registry-credentials-block-id>""
        },
```
then the created object is a dictionary like
```python
{""username"": ""test"", ""password"": ""test"", ""registry_url"": ""test""}
```
which fails [the `hasattr()` checks in `_add_image_registry_credentials()`](https://github.com/PrefectHQ/prefect/blob/main/src/integrations/prefect-azure/prefect_azure/workers/container_instance.py#L313), causing no `imageRegistryCredentials` to be added to the template and the eventual failure of the container instance to pull an image.

### Version info

```Text
Version:             3.2.13
API version:         0.8.4
Python version:      3.11.5
Git commit:          12800297
Built:               Fri, Mar 14, 2025 8:37 PM
OS/Arch:             darwin/arm64
Profile:             default
Server type:         cloud
Pydantic version:    2.10.3
Integrations:
  prefect-azure:     0.4.2
```

### Additional context

_No response_",kevingrismore,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17542/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17542
17538,Duplicate runs when redeploying frequently-scheduled deployments,open,,2025-03-20T13:05:17Z,2025-03-21T16:14:52Z,,3,['bug'],evan-enspired,,NONE,"### Bug summary

We have a number of deployments which are deployed using the same process, however one of these deployments doesn't seem to have the existing scheduled runs deleted whenever we do a redeployment (resulting in duplicate runs).

All of the deployments are deployed using the same process, with the only difference being that the 'problematic' deployment is scheduled to run every minute rather than once a day.

If it helps, here is the basic logic behind how the deployments are handled:

Deployments are created from the flows as follows:

```
deployment = flow.to_deployment(
        name=f""{config.stage.value}:{config.name}"",
        work_queue_name=config.work_queue.value,
        schedules=config.schedules,
        job_variables={
            ""image_pull_policy"": ""Never"",
            **(config.job_variables or {}),
        },
    )
```

The deployments are deployed (where `deployments` is a list of individual deployments): 

`deploy(*deployments, work_pool_name=work_pool_name, image=image, push=False)`

Each of these are using the same docker image etc. 
The only difference between deployments is that one uses a Cron schedule of `""* * * * *""` while the other use schedules similar to `""0 5 1 * *""`. Each run typically takes somewhere on the order of 30 seconds, so the run which is scheduled for every minute will will be running about half of the time.

I suspect that the frequency of runs (maybe that it is generally running while prefect redeploys?) leads to prefect not deleting the old scheduled runs when creating new ones. The result is that for each minute, there will be TWO scheduled runs, instead of ONE.

Our solution thus far has been to first delete this deployment and then quickly redeploy, which then results in correctly scheduled runs.

### Version info

```Text
Version:             3.2.12
API version:         0.8.4
Python version:      3.12.7
Git commit:          826eb1a7
Built:               Mon, Mar 10, 2025 4:36 PM
OS/Arch:             linux/x86_64
Profile:             local
Server type:         server
Pydantic version:    2.9.2
Integrations:
  prefect-aws:       0.5.0
  prefect-docker:    0.6.1
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17538/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17538
17536,Cancelling flow run crashes due to lacking of `flow_run.state`,closed,completed,2025-03-20T10:01:49Z,2025-03-20T17:04:36Z,2025-03-20T16:50:22Z,1,['bug'],lelouvincx,,CONTRIBUTOR,"### Bug summary

When workers try to submit a scheduled flow run if its corresponding deployment somehow got deleted, workers will mark the flow run as cancelled.

However, the current implementation is getting an error leading to failure in marking the flow run as canceled. This then leads to to crashed worker in an infinite-loop.

Error log:
```
Traceback (most recent call last):
File ""/opt/prefect/current/.venv/lib/python3.11/site-packages/prefect/workers/base.py"", line 1004, in _submit_run
	await self._mark_flow_run_as_cancelled(
File ""/opt/prefect/current/.venv/lib/python3.11/site-packages/prefect/workers/base.py"", line 1255, in _mark_flow_run_as_cancelled
	state = flow_run.state.model_copy(update=state_updates)
            ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'model_copy'
```

For details, here's the present implementation:

```diff
async def _submit_run(self, flow_run: ""FlowRun"") -> None:
    """"""
    Submits a given flow run for execution by the worker.
    """"""
    run_logger = self.get_flow_run_logger(flow_run)

    try:
        await self.client.read_deployment(getattr(flow_run, ""deployment_id""))
+   except (ObjectNotFound, AttributeError):
        self._logger.exception(
            f""Deployment {flow_run.deployment_id} no longer exists. ""
            f""Flow run {flow_run.id} will not be submitted for""
            "" execution""
        )
        self._submitting_flow_run_ids.remove(flow_run.id)
+       await self._mark_flow_run_as_cancelled(
+           flow_run,
+           state_updates=dict(
+               message=f""Deployment {flow_run.deployment_id} no longer exists, cancelled run.""
+           ),
+       )
        return
```

The bug continues in function `_mark_flow_run_as_cancelled`:

```diff
    async def _mark_flow_run_as_cancelled(
        self, flow_run: ""FlowRun"", state_updates: dict[str, Any] | None = None
    ) -> None:
        state_updates = state_updates or {}
        state_updates.setdefault(""name"", ""Cancelled"")
        state_updates.setdefault(""type"", StateType.CANCELLED)
        if TYPE_CHECKING:
            assert flow_run.state
-       state = flow_run.state.model_copy(update=state_updates)

        await self.client.set_flow_run_state(flow_run.id, state, force=True)

        # Do not remove the flow run from the cancelling set immediately because
        # the API caches responses for the `read_flow_runs` and we do not want to
        # duplicate cancellations.
        await self._schedule_task(
            60 * 10, self._cancelling_flow_run_ids.remove, flow_run.id
        )
```

`NoneType` here means `flow_run.state` is None. Because the above constant `TYPE_CHECKING` is currently false, imported from `typing`.

### Version info

```Text
âžœ uv run prefect version
Version:             3.2.13
API version:         0.8.4
Python version:      3.11.10
Git commit:          12800297
Built:               Fri, Mar 14, 2025 8:37 PM
OS/Arch:             darwin/arm64
Profile:             local
Server type:         server
Pydantic version:    2.10.6
Integrations:
  prefect-dbt:       0.7.0rc1
  prefect-gcp:       0.6.4
  prefect-shell:     0.3.1
```

### Additional context

Workers keep restarting preventing other flow runs to be summited:

![Image](https://github.com/user-attachments/assets/1b5b3908-e9e6-4a12-8292-540ec9a2cb11)",desertaxle,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17536/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17536
17534,Flow Deploy not recognize build context,closed,completed,2025-03-20T02:42:39Z,2025-03-21T04:08:46Z,2025-03-20T14:31:34Z,0,['bug'],thdtt,,CONTRIBUTOR,"### Bug summary

My code:
```python
if __name__ == '__main__':
    my_flow.deploy(
        name=""test"",
        work_pool_name=""my-docker-pool"",
        image=DockerImage(
            name=""test"",
            tag=""latest"",
            context=get_project_path()        # it should use the path I've set
        ),
        push=True,
        cron=""0 * * * *"",
    )
```
When set context on DockerImage, prefect not recognize context path, but always use directory where the file exist so that many modules cannot be recognized

### Version info

```Text
Version:             3.2.13
API version:         0.8.4
Python version:      3.12.0
Git commit:          12800297
Built:               Fri, Mar 14, 2025 8:37 PM
OS/Arch:             darwin/arm64
Profile:             ephemeral
Server type:         server
Pydantic version:    2.10.6
```

### Additional context

_No response_",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17534/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17534
17531,(2.x)Tasks run outside of a flow using the Prefect Test Harness fail with a 500 internal server error,open,,2025-03-19T21:18:18Z,2025-03-20T23:50:48Z,,0,"['bug', '2.x']",masonmenges,,CONTRIBUTOR,"### Bug summary

Utilizing the prefect_test_harness with a task run outside of a flow run context results in a 500 internal server error this only occurs when running on prefect 2, prefect 3 seems to handle this particular case without issue, the task itself also runs fine outside of the test harness and tests using this seem to ""work"" as well but the test output is polluted with these error making it more difficult to parse.

```python
from prefect import flow, task
from prefect.testing.utilities import prefect_test_harness
@task
def my_task():
    return 42


with prefect_test_harness():
    assert my_task() == 42
```

### Version info

```Text
Version:             2.20.16
API version:         0.8.4
Python version:      3.12.0
Git commit:          b5047953
Built:               Thu, Dec 19, 2024 10:55 AM
OS/Arch:             darwin/arm64
Profile:             masonsandbox
Server type:         cloud
```

### Additional context

stack trace:

```
15:17:45.313 | INFO    | prefect.engine - Created task run 'my_task-78429a92' for task 'my_task'
15:17:45.409 | INFO    | Task run 'my_task-78429a92' - Finished in state Completed()
15:17:45.523 | ERROR   | prefect.server - Encountered exception in request:
Traceback (most recent call last):
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/prefect/_vendor/starlette/middleware/errors.py"", line 168, in __call__
    await self.app(scope, receive, _send)
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/prefect/_vendor/starlette/middleware/gzip.py"", line 24, in __call__
    await responder(scope, receive, send)
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/prefect/_vendor/starlette/middleware/gzip.py"", line 44, in __call__
    await self.app(scope, receive, self.send_with_gzip)
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/prefect/_vendor/starlette/middleware/exceptions.py"", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/prefect/_vendor/starlette/_exception_handler.py"", line 62, in wrapped_app
    raise exc
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/prefect/_vendor/starlette/_exception_handler.py"", line 51, in wrapped_app
    await app(scope, receive, sender)
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/prefect/_vendor/fastapi/middleware/asyncexitstack.py"", line 20, in __call__
    raise e
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/prefect/_vendor/fastapi/middleware/asyncexitstack.py"", line 17, in __call__
    await self.app(scope, receive, send)
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/prefect/_vendor/starlette/routing.py"", line 760, in __call__
    await self.middleware_stack(scope, receive, send)
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/prefect/_vendor/starlette/routing.py"", line 780, in app
    await route.handle(scope, receive, send)
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/prefect/_vendor/starlette/routing.py"", line 302, in handle
    await self.app(scope, receive, send)
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/prefect/_vendor/starlette/routing.py"", line 81, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/prefect/_vendor/starlette/_exception_handler.py"", line 62, in wrapped_app
    raise exc
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/prefect/_vendor/starlette/_exception_handler.py"", line 51, in wrapped_app
    await app(scope, receive, sender)
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/prefect/_vendor/starlette/routing.py"", line 76, in app
    response = await func(request)
               ^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/prefect/server/utilities/server.py"", line 104, in handle_response_scoped_depends
    response = await default_handler(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/prefect/_vendor/fastapi/routing.py"", line 251, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/prefect/_vendor/fastapi/routing.py"", line 177, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/prefect/server/api/logs.py"", line 27, in create_logs
    await models.logs.create_logs(session=session, logs=batch)
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/prefect/server/database/dependencies.py"", line 125, in async_wrapper
    return await fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/prefect/server/models/logs.py"", line 45, in create_logs
    await session.execute(db.insert(db.Log).values())
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/sqlalchemy/ext/asyncio/session.py"", line 461, in execute
    result = await greenlet_spawn(
             ^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py"", line 201, in greenlet_spawn
    result = context.throw(*sys.exc_info())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/sqlalchemy/orm/session.py"", line 2362, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/sqlalchemy/orm/session.py"", line 2237, in _execute_internal
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/sqlalchemy/orm/session.py"", line 2106, in _connection_for_bind
    return trans._connection_for_bind(engine, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""<string>"", line 2, in _connection_for_bind
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py"", line 139, in _go
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/sqlalchemy/orm/session.py"", line 1189, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/sqlalchemy/engine/base.py"", line 3278, in connect
    return self._connection_cls(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/sqlalchemy/engine/base.py"", line 146, in __init__
    self._dbapi_connection = engine.raw_connection()
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/sqlalchemy/engine/base.py"", line 3302, in raw_connection
    return self.pool.connect()
           ^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/sqlalchemy/pool/base.py"", line 449, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/sqlalchemy/pool/base.py"", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/sqlalchemy/pool/base.py"", line 712, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/sqlalchemy/pool/impl.py"", line 308, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/sqlalchemy/pool/base.py"", line 390, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/sqlalchemy/pool/base.py"", line 674, in __init__
    self.__connect()
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/sqlalchemy/pool/base.py"", line 900, in __connect
    with util.safe_reraise():
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py"", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/sqlalchemy/pool/base.py"", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/sqlalchemy/engine/create.py"", line 643, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/sqlalchemy/engine/default.py"", line 621, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/sqlalchemy/dialects/sqlite/aiosqlite.py"", line 352, in connect
    await_only(connection),
    ^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py"", line 132, in await_only
    return current.parent.switch(awaitable)  # type: ignore # noqa: E501
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py"", line 196, in greenlet_spawn
    value = await result
            ^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/site-packages/aiosqlite/core.py"", line 139, in __await__
    self.start()
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_2.x_test/lib/python3.12/threading.py"", line 971, in start
    _start_new_thread(self._bootstrap, ())
RuntimeError: can't create new thread at interpreter shutdown
--- Error logging to API ---
Server error '500 Internal Server Error' for url 'http://ephemeral-prefect/api/logs/'
Response: {'exception_message': 'Internal Server Error'}
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/500%  
```",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17531/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17531
17529,Custom Block metadata settings not applied if attributes are typed,open,,2025-03-19T20:00:37Z,2025-03-21T23:52:46Z,,4,"['bug', 'upstream dependency']",jlwhelan28,,NONE,"### Bug summary

When creating a custom Block schema, metadata attributes to control the object's display won't be set if they are typed. If this is intended behavior, an example and note in the documentation here [blocks#customize-a-block](https://docs.prefect.io/v3/develop/blocks#customize-a-block%E2%80%99s-display) would be helpful.

```python
from prefect.blocks.core import Block

# This does not work, resulting block slug is 'myblock'
class MyBlock(Block):
    value: str
    _block_type_name: str = ""My Custom Block""
    _block_type_slug: str = ""my-block""

MyBlock('hello')._block_type_slug
# returns None

# This works, resulting block slug is 'my-block'
class MyBlock(Block):
    value: str
    _block_type_name = ""My Custom Block""
    _block_type_slug = ""my-block""

MyBlock('hello')._block_type_slug
# returns ""my-block""
```

### Version info

```Text
Version:             3.2.9
API version:         0.8.4
Python version:      3.12.9
Git commit:          27eb408c
Built:               Fri, Feb 28, 2025 8:12 PM
OS/Arch:             linux/x86_64
Profile:             ephemeral
Server type:         server
Pydantic version:    2.10.6
Integrations:
  prefect-aws:       0.5.5
  prefect-docker:    0.6.2
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17529/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17529
17525,"Request for Comprehensive Documentation on Memory Consumption in Tasks, Generators, and Flows",open,,2025-03-18T22:47:36Z,2025-03-19T00:11:28Z,,2,"['enhancement', 'great writeup', 'documentation']",maitlandmarshall,,CONTRIBUTOR,"
Iâ€™m reaching out to request explicit and comprehensive documentation on how memory consumption works across different task and flow configurations in Prefect. While the current documentation (e.g., [Write and Run Tasks](https://docs.prefect.io/v3/develop/write-tasks)) provides some insights into task execution and generator handling, thereâ€™s ambiguity around memory usage, especially with generators, task results, and flows. This makes it challenging to predict and optimize memory behavior in production workflows, particularly for memory-intensive data pipelines.

Here are the specific areas where clearer documentation would be valuable:

1. **Task Variants and Memory Consumption**:
   - How does memory usage differ between standard tasks (returning a single value), tasks returning generator objects, and tasks that are generator functions (using `yield` directly)?
   - When are task results held in memory, and when (if ever) are they released automatically during a flow run?

2. **Generators in Tasks**:
   - For a task returning a generator (e.g., `@task def f(): return gen()`), itâ€™s noted that Prefect consumes the generator into a list. Can this be clarified with examples showing memory implications?
   - For a generator task (e.g., `@task def f(): yield 1; yield 2`), does it stream values or materialize them? How does iteration in a flow affect memory (e.g., `for x in f()`)?
   - Are there differences in memory behavior when consuming these generators in flows vs. mapping over them (e.g., `f.map()`)?

3. **Flows and Generator Interactions**:
   - How do flows handle generators passed between tasks? Are there scenarios where intermediate results are fully loaded into memory versus streamed?
   - Does the task runner (e.g., Sequential, Concurrent, Dask) impact how generators or task results are stored in memory?

4. **Result Release and Memory Management**:
   - When are task results released from memory during or after a flow run? For example, after a task completes and its result is passed downstream, is it garbage-collected, or does Prefect retain it?
   - How does result persistence (e.g., to disk or remote storage) affect in-memory retention? Is there a way to opt out of keeping results in memory entirely?
   - Are there known memory growth issues (e.g., as seen in #14329) still relevant, and how can users mitigate them?

5. **Practical Examples**:
   - Could the documentation include examples showing memory usage for common patterns (e.g., a task yielding a large dataset, a flow mapping over a generator, a task with caching enabled)? Ideally, these could contrast streaming vs. materialization scenarios.

#### Current Behavior
From experimenting and reading issues like #2023 (task mapping on generators), #13820 (generator task support), and #14329 (linear memory growth), it seems:
- Tasks returning generators are consumed into lists, increasing memory usage.
- Generator tasks (with `yield`) can stream if iterated over, but this isnâ€™t explicitly guaranteed.
- Memory might not release during a flow run unless explicitly managed (e.g., avoiding `list()` calls), but the conditions for this are unclear.

However, without clear documentation, users must infer these behaviors through trial and error or community discussions, which can lead to inefficient workflows or unexpected memory issues in production.

#### Desired Outcome
A dedicated documentation section (e.g., â€œMemory Management in Prefectâ€) that:
- Explains memory consumption for each task type and generator scenario.
- Clarifies when results are held or released, with guidance on minimizing memory footprints.
- Provides actionable examples and best practices for memory-efficient workflows.

This would empower users to design workflows confidently, especially for large-scale data processing where memory optimization is critical.

#### Additional Context
Iâ€™ve been exploring this due to uncertainty around whether a generator task streams or materializes in a flow (e.g., `@task def test(): yield ""a""; yield ""b""` consumed with `for x in test()`). Community answers vary, and while the behavior seems to lean toward streaming, explicit confirmation and broader memory details would be hugely beneficial.

Thanks for considering this! Prefectâ€™s flexibility is fantastic, and clearer memory documentation would make it even more approachable for production use cases.",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17525/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17525
17520,Flows annotations in python 3.9,closed,completed,2025-03-18T17:34:48Z,2025-04-18T01:31:52Z,2025-04-18T01:31:51Z,4,"['bug', 'upstream dependency']",pietrodantuono,,NONE,"### Bug summary

When annotating a flow in Python 3.9 I would expect that, if importing `annotations` from `__future__`, I would be able to use the pipe instead of `typing.Union`, instead an error is thrown.

> [!NOTE]
> No issues in `prefect.task` instead.

See this example:

```python
from __future__ import annotations
from prefect import task, flow

@task
def convert_to_int(var: int | float | str) -> int:  # pipe annotations in tasks work as expected
    """"""Convert a variable to integer based on its type.""""""
    if isinstance(var, (int, float)):
        return int(var)
    elif isinstance(var, str):
        try:
            if var.startswith('0x'):
                return int(var, 16)
            else:
                return int(var)
        except ValueError:
            # Convert string to its ASCII/Unicode values and sum them
            return sum(ord(c) for c in var)
    else:
        raise TypeError(""Input must be numeric or string"")

@task
def calculate_hex_sum(val1: int, val2: int) -> str:
    """"""Calculate the sum of two integers and return as hex without '0x' prefix.""""""
    return hex(val1 + val2)[2:]  # Remove '0x' prefix

@flow(name=""Hex Sum Flow"")
def hex_sum(var1: int | float | str, var2: int | float | str) -> str:  # works with typing.Union[int, float, str], raises with int | float | str
    """"""
    Convert two variables to hexadecimal and return their sum in hex format.
    
    Args:
        var1: First variable (string or numeric)
        var2: Second variable (string or numeric)
    
    Returns:
        String: Hexadecimal sum without '0x' prefix
    """"""
    val1 = convert_to_int(var1)
    val2 = convert_to_int(var2)
    return calculate_hex_sum(val1, val2)

# Example usage
if __name__ == ""__main__"":
    print(""Sum of 10 and 20:"", hex_sum(10, 20))
    print(""Sum of 'abc' and 123:"", hex_sum('abc', 123))
    print(""Sum of '0x1a' and 10:"", hex_sum('0x1a', 10))
    print(""Sum of 'hello' and 'world':"", hex_sum('hello', 'world'))
```

Error message

```python
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In[1], line 27
     23     """"""Calculate the sum of two integers and return as hex without '0x' prefix.""""""
     24     return hex(val1 + val2)[2:]  # Remove '0x' prefix
     26 @flow(name=""Hex Sum Flow"")
---> 27 def hex_sum(var1: int | float | str, var2: int | float | str) -> str:
     28     """"""
     29     Convert two variables to hexadecimal and return their sum in hex format.
     30     
   (...)
     36         String: Hexadecimal sum without '0x' prefix
     37     """"""
     38     val1 = convert_to_int(var1)

File ~/example/.venv/lib/python3.9/site-packages/prefect/flows.py:1904, in FlowDecorator.__call__(self, _FlowDecorator__fn, name, version, flow_run_name, retries, retry_delay_seconds, task_runner, description, timeout_seconds, validate_parameters, persist_result, result_storage, result_serializer, cache_result_in_memory, log_prints, on_completion, on_failure, on_cancellation, on_crashed, on_running)
   1900         method_decorator = type(__fn).__name__
   1901         raise TypeError(
   1902             f""@{method_decorator} should be applied on top of @flow""
   1903         )
-> 1904     return Flow(
   1905         fn=__fn,
   1906         name=name,
   1907         version=version,
   1908         flow_run_name=flow_run_name,
   1909         task_runner=task_runner,
   1910         description=description,
   1911         timeout_seconds=timeout_seconds,
   1912         validate_parameters=validate_parameters,
   1913         retries=retries,
   1914         retry_delay_seconds=retry_delay_seconds,
   1915         persist_result=persist_result,
   1916         result_storage=result_storage,
   1917         result_serializer=result_serializer,
   1918         cache_result_in_memory=cache_result_in_memory,
   1919         log_prints=log_prints,
   1920         on_completion=on_completion,
   1921         on_failure=on_failure,
   1922         on_cancellation=on_cancellation,
   1923         on_crashed=on_crashed,
   1924         on_running=on_running,
   1925     )
   1926 else:
   1927     return cast(
   1928         Callable[[Callable[P, R]], Flow[P, R]],
   1929         partial(
   (...)
   1950         ),
   1951     )

File ~/example/.venv/lib/python3.9/site-packages/prefect/flows.py:356, in Flow.__init__(self, fn, name, version, flow_run_name, retries, retry_delay_seconds, task_runner, description, timeout_seconds, validate_parameters, persist_result, result_storage, result_serializer, cache_result_in_memory, log_prints, on_completion, on_failure, on_cancellation, on_crashed, on_running)
    350 if self.should_validate_parameters:
    351     # Try to create the validated function now so that incompatibility can be
    352     # raised at declaration time rather than at runtime
    353     # We cannot, however, store the validated function on the flow because it
    354     # is not picklable in some environments
    355     try:
--> 356         ValidatedFunction(self.fn, config={""arbitrary_types_allowed"": True})
    357     except ConfigError as exc:
    358         raise ValueError(
    359             ""Flow function is not compatible with `validate_parameters`. ""
    360             ""Disable validation or change the argument names.""
    361         ) from exc

File ~/example/.venv/lib/python3.9/site-packages/pydantic/v1/decorator.py:78, in ValidatedFunction.__init__(self, function, config)
     75 self.v_args_name = 'args'
     76 self.v_kwargs_name = 'kwargs'
---> 78 type_hints = get_all_type_hints(function)
     79 takes_args = False
     80 takes_kwargs = False

File ~/example/.venv/lib/python3.9/site-packages/pydantic/v1/typing.py:80, in get_all_type_hints(obj, globalns, localns)
     79 def get_all_type_hints(obj: Any, globalns: Any = None, localns: Any = None) -> Any:
---> 80     return get_type_hints(obj, globalns, localns, include_extras=True)

File ~/.local/share/uv/python/cpython-3.9.21-linux-x86_64-gnu/lib/python3.9/typing.py:1497, in get_type_hints(obj, globalns, localns, include_extras)
   1489 if isinstance(value, str):
   1490     # class-level forward refs were handled above, this must be either
   1491     # a module-level annotation or a function argument annotation
   1492     value = ForwardRef(
   1493         value,
   1494         is_argument=not isinstance(obj, types.ModuleType),
   1495         is_class=False,
   1496     )
-> 1497 value = _eval_type(value, globalns, localns)
   1498 if name in defaults and defaults[name] is None:
   1499     value = Optional[value]

File ~/.local/share/uv/python/cpython-3.9.21-linux-x86_64-gnu/lib/python3.9/typing.py:292, in _eval_type(t, globalns, localns, recursive_guard)
    286 """"""Evaluate all forward references in the given type t.
    287 For use of globalns and localns see the docstring for get_type_hints().
    288 recursive_guard is used to prevent infinite recursion with a recursive
    289 ForwardRef.
    290 """"""
    291 if isinstance(t, ForwardRef):
--> 292     return t._evaluate(globalns, localns, recursive_guard)
    293 if isinstance(t, (_GenericAlias, GenericAlias)):
    294     ev_args = tuple(_eval_type(a, globalns, localns, recursive_guard) for a in t.__args__)

File ~/.local/share/uv/python/cpython-3.9.21-linux-x86_64-gnu/lib/python3.9/typing.py:554, in ForwardRef._evaluate(self, globalns, localns, recursive_guard)
    549 if self.__forward_module__ is not None:
    550     globalns = getattr(
    551         sys.modules.get(self.__forward_module__, None), '__dict__', globalns
    552     )
    553 type_ = _type_check(
--> 554     eval(self.__forward_code__, globalns, localns),
    555     ""Forward references must evaluate to types."",
    556     is_argument=self.__forward_is_argument__,
    557     allow_special_forms=self.__forward_is_class__,
    558 )
    559 self.__forward_value__ = _eval_type(
    560     type_, globalns, localns, recursive_guard | {self.__forward_arg__}
    561 )
    562 self.__forward_evaluated__ = True

File <string>:1

TypeError: unsupported operand type(s) for |: 'type' and 'type'
```

### Version info

```Text
Version:             3.2.11
API version:         0.8.4
Python version:      3.9.21
Git commit:          9481694f
Built:               Wed, Mar 5, 2025 10:00 PM
OS/Arch:             linux/x86_64
Profile:             local
Server type:         ephemeral
Pydantic version:    2.10.6
Server:
  Database:          sqlite
  SQLite version:    3.47.1
```

### Additional context

_No response_",aaazzam,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17520/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17520
17518,Select a different default log-level for the UI,open,,2025-03-18T14:22:01Z,2025-03-18T14:22:01Z,,0,['enhancement'],cBournhonesque,,NONE,"### Describe the current behavior

In the UI, the logs for a task are shown with a default log level of ERROR by default.
You can click on the dropdown to modify that, but it's annoying if I want the dropdown to be set to INFO by default.

### Describe the proposed behavior

Expose some option to control the default log-level shown for a flow-run/task-run in the UI

### Example Use

_No response_

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17518/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17518
17517,"DaskTaskRunner issues unexpected ""a future was garbage collected"" warning",closed,completed,2025-03-18T12:04:09Z,2025-05-01T15:13:54Z,2025-05-01T15:13:54Z,4,['bug'],athrpf,,NONE,"### Bug summary

When submitting multiple dependent tasks in a for loop and only keeping the reference to the last one, I get a warning

```
""A future was garbage collected before it resolved. Please call `.wait()` or `.result()` on futures to ensure they resolve."" 
```

Here is an example to reproduce, which follows the test that tests for this warning introduced in #14148.

```
from prefect import task, flow
from prefect_dask import DaskTaskRunner
from prefect.cache_policies import NO_CACHE
from prefect.futures import wait

task_runner = DaskTaskRunner(cluster_kwargs={""n_workers"": 1})


@task()
def task1():
    return 42


@task()
def task2(test):
    return test * 2


@flow(task_runner=task_runner)
def test_flow():
    results = []
    n = 10
    for _ in range(n):
        result1 = task1.submit()
        result2 = task2.submit(result1)
        results.append(result2)
    wait(results)


if __name__ == ""__main__"":
    test_flow()
```

- The warning gets issued `n-1` times, when each of the first `n-1` instances of `result1` go out of scope`
- My expectation would be that the instances of `task2` hold references to the futures, and therefore `__del__` would not be called
- I get the same behaviour with the `RayTaskRunner`
- The `ConcurrentTaskRunner` does not have this issue


### Version info

```Text
$ prefect version
Version:             3.2.9
API version:         0.8.4
Python version:      3.11.9
Git commit:          27eb408c
Built:               Fri, Feb 28, 2025 8:12 PM
OS/Arch:             linux/x86_64
Profile:             prefect3
Server type:         server
Pydantic version:    2.9.2
Integrations:
  prefect-dask:      0.3.3
  prefect-ray:       0.4.3
```

### Additional context

_No response_",cicdw,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17517/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17517
17513,Add PREFECT_API_URL config setup step before the work pool creation for self hosted,open,,2025-03-17T18:01:52Z,2025-03-17T18:01:52Z,,0,['enhancement'],octonawish-akcodes,,NONE,"### Describe the current behavior

Current behavior is when a new user jumps on `self-hosted` [documentation](https://docs.prefect.io/v3/tutorials/schedule) if the user run ` prefect worker start --pool my-work-pool` they will get the error of:

```
:~/prefect/prefect$ prefect worker start --pool my-work-pool
Traceback (most recent call last):
  File ""/home/abhi/.local/lib/python3.9/site-packages/prefect/cli/_utilities.py"", line 44, in wrapper
    return fn(*args, **kwargs)
  File ""/home/abhi/.local/lib/python3.9/site-packages/prefect/cli/_types.py"", line 155, in sync_fn
    return asyncio.run(async_fn(*args, **kwargs))
  File ""/usr/lib/python3.9/asyncio/runners.py"", line 44, in run
    return loop.run_until_complete(main)
  File ""/usr/lib/python3.9/asyncio/base_events.py"", line 647, in run_until_complete
    return future.result()
  File ""/home/abhi/.local/lib/python3.9/site-packages/prefect/cli/worker.py"", line 126, in start
    is_queues_paused = await _check_work_queues_paused(
  File ""/home/abhi/.local/lib/python3.9/site-packages/prefect/cli/worker.py"", line 208, in _check_work_queues_paused
    wqs = await client.read_work_queues(
  File ""/home/abhi/.local/lib/python3.9/site-packages/prefect/client/orchestration/__init__.py"", line 1141, in read_work_queues
    response = await self._client.post(
  File ""/home/abhi/.local/lib/python3.9/site-packages/httpx/_client.py"", line 1859, in post
    return await self.request(
  File ""/home/abhi/.local/lib/python3.9/site-packages/httpx/_client.py"", line 1540, in request
    return await self.send(request, auth=auth, follow_redirects=follow_redirects)
  File ""/home/abhi/.local/lib/python3.9/site-packages/prefect/client/base.py"", line 354, in send
    response.raise_for_status()
  File ""/home/abhi/.local/lib/python3.9/site-packages/prefect/client/base.py"", line 162, in raise_for_status
    raise PrefectHTTPStatusError.from_httpx_error(exc) from exc.__cause__
prefect.exceptions.PrefectHTTPStatusError: Client error '403 Forbidden' for url 'https://github.com/prefecthq/demos.git/work_pools/my-work-pool/queues/filter'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
An exception occurred.
```

which states that the `PREFECT_API_URL` is not setup as its not written on documentation.

### Describe the proposed behavior

`PREFECT_API_URL` config setup step before the creation of work pool for the self hosted.

Something like this:

```bash
:~/prefect/prefect$ prefect config set PREFECT_API_URL=""http://127.0.0.1:4200/api""
Set 'PREFECT_API_URL' to 'http://127.0.0.1:4200/api'.
Updated profile 'local'.
```

This will solve the issue

### Example Use

_No response_

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17513/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17513
17511,[prefect-gcp] Increase timeout for Cloud Run Jobs worker,closed,completed,2025-03-17T17:25:10Z,2025-03-20T14:38:44Z,2025-03-20T14:38:44Z,1,['enhancement'],jeremy-thomas-roc,,CONTRIBUTOR,"### Describe the current behavior

The current documented limit is 1 day; however, 7 day timeouts are now in preview, as per [this link](https://cloud.google.com/run/quotas#cloud_run_limits). There is a validator in the Cloud Run Job worker that prohibits us from setting a timeout greater than a day.

### Describe the proposed behavior

Either increase the limit or remove the validator for this field. I understand the philosophy of catching errors before they are sent to the API, but this could be something that changes again, and removing the validation would allow it to pass through, regardless of the changes on the GCP side. The obvious downside is letting the API throw the error and having to propagate it, but I think either solution is valid.

### Example Use

_No response_

### Additional context

This is one of the major limitations we have with Cloud Run Jobs, we have to use entirely different workers for long running jobs currently. This is a pretty low hanging fix (I am willing to PR it myself, if it would help) and would be very beneficial to our team.",desertaxle,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17511/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17511
17508,Double/Duplicate Scheduled Runs After Prefect Updates,closed,duplicate,2025-03-17T15:58:23Z,2025-03-17T19:12:54Z,2025-03-17T19:12:54Z,1,['bug'],yang-gene,,NONE,"### Bug summary

Similar to #8880 (seems to be inactive despite being open) and #3629

My team self-hosts Prefect using Red Hat's OKD (Openshift Kubernetes Distribution).

After upgrading from Prefect 3.1.1 to 3.2.2. We found that most of our nightly cron-scheduled deployments are run twice. Only one flow run is scheduled; however, two flow runs are created and run at the **exact same time**.  Oddly, only our frequently run deployments (e.g. every 15 minutes) do not suffer from these double runs.

We found that in v 3.2.2, double runs could be fixed by toggling off and on every single deployment in the UI.

After we upgraded from v 3.2.2 to 3.2.9, we encountered the exact same issue. We ended up programatically deleting all of our deployments and re-registering our deployment using the API (which is non-ideal).

### Reproducing the Issue

We have no definite way of reproducing this issue; however, it _may_ be possible to recreate it by registering a nightly cron-scheduled deployment in prefect 3.1.1 and then upgrading to 3.2.2. A successful reproduction of the issue would be that this deployment creates two flow runs (with differing ids) when a single flow run was scheduled.

### Version info

```Text
$ prefect version
Version:             3.2.9
API version:         0.8.4
Python version:      3.11.11
Git commit:          27eb408c
Built:               Fri, Feb 28, 2025 8:15 PM
OS/Arch:             linux/x86_64
Profile:             ephemeral
Server type:         server
Pydantic version:    2.10.6
Integrations:
  prefect-gitlab:    0.3.1
  prefect-kubernetes: 0.5.7
  prefect-redis:     0.2.2
```

### Additional context

_No response_",cicdw,1,https://api.github.com/repos/PrefectHQ/prefect/issues/17508/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17508
17504,Integrations install doesn't succeed after prompt,open,,2025-03-17T15:09:50Z,2025-03-17T15:09:50Z,,0,['bug'],znicholasbrown,,CONTRIBUTOR,"### Bug summary

When attempting to start a worker via the CLI, e.g. with `prefect worker start --pool ""k8s-local""`, the CLI provides the following prompt:
<img width=""1091"" alt=""Image"" src=""https://github.com/user-attachments/assets/4dcbb224-d101-4362-9e04-f29ecbbbf543"" />

This is great! However the command ultimately fails with the following message:
```
Unable to start worker. Please ensure you have the necessary dependencies installed to run your desired worker type.
```

It does look to have installed the integration correctly as running the command a second time succeeds as expected.

### Version info

```Text
Version:             3.2.12.dev1+9.g8b0d207f11
API version:         0.8.4
Python version:      3.11.7
Git commit:          8b0d207f
Built:               Thu, Mar 6, 2025 10:38 PM
OS/Arch:             darwin/arm64
Profile:             stg
Server type:         cloud
Pydantic version:    2.10.5
Integrations:
  prefect-kubernetes: 0.5.8
  prefect-dask:      0.3.1
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17504/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17504
17503,Add example of creating a deployment with `prefect deployment schedule create` CLI command to the scheduling docs,open,,2025-03-17T14:05:17Z,2025-03-17T14:05:59Z,,0,['docs'],discdiver,,CONTRIBUTOR,"### Describe the current behavior

Only the interactive `prefect deploy` option is mentioned.
https://docs.prefect.io/v3/automate/add-schedules#create-schedules-with-the-cli

### Describe the proposed behavior

Add example.

### Example Use

_No response_

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17503/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17503
17494,Multiple schedules with the same cron expression are not properly executed,closed,completed,2025-03-16T07:35:35Z,2025-03-19T17:46:14Z,2025-03-19T17:46:12Z,1,['bug'],yajatvishwak,,NONE,"### Bug summary

In Prefect Cloud, when I schedule multiple flows with the same cron expression, the scheduled flow runs do not appear in the ""Upcoming Runs"" section and the flow does not run at the cron time. However, if I delete one of the schedules, the other scheduled runs become visible.

I am scheduling flows using the UI

Issue video : https://youtu.be/_iWbddgb4jM


### Version info

```Text
Version:             3.2.2
API version:         0.8.4
Python version:      3.12.7
Git commit:          d982c69a
Built:               Thu, Feb 13, 2025 10:53 AM
OS/Arch:             darwin/arm64
Profile:             local
Server type:         cloud
Pydantic version:    2.10.6
```

### Additional context

_No response_",zzstoatzz,1,https://api.github.com/repos/PrefectHQ/prefect/issues/17494/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17494
17492,Option to deserialize a Secret Block's value to JSON,closed,completed,2025-03-16T03:27:49Z,2025-03-22T11:13:43Z,2025-03-22T11:13:43Z,0,['enhancement'],lelouvincx,,CONTRIBUTOR,"### Describe the current behavior

I am configuring the new Prefect to run dbt models using the module `prefect-dbt`. Following the [docs](https://docs.prefect.io/integrations/prefect-dbt/index#profiles-yml-templating), I use Prefect's YAML templating to inject secrets into the dbt profile.

```python
from prefect_dbt import PrefectDbtSettings

dbt_settings = PrefectDbtSettings(
        profiles_dir=Constants.dbt_PROFILES_DIR,
        project_dir=Constants.dbt_PROJECT_DIR,
    )
```

The `profiles.yml` looks like this:
```yaml
my-bigquery:
  target: ""{{ prefect.variables.target }}""
  outputs:
    dev:
      type: bigquery
      method: service-account-json
      project: my-project-123456
      dataset: dev
      threads: 4
      priority: interactive
      keyfile_json:
        type: ""{{ prefect.blocks.secret.gcp-cred.type }}""
        project_id: ""{{ prefect.blocks.secret.gcp-cred.project_id }}""
        private_key_id: ""{{ prefect.blocks.secret.gcp-cred.private_key_id }}""
        private_key: ""{{ prefect.blocks.secret.gcp-cred.private_key }}""
        client_email: ""{{ prefect.blocks.secret.gcp-cred.client_email }}""
        client_id: ""{{ prefect.blocks.secret.gcp-cred.client_id }}""
        auth_uri: ""{{ prefect.blocks.secret.gcp-cred.auth_uri }}""
        token_uri: ""{{ prefect.blocks.secret.gcp-cred.token_uri }}""
        auth_provider_x509_cert_url: ""{{ prefect.blocks.secret.gcp-cred.auth_provider_x509_cert_url }}""
        client_x509_cert_url: ""{{ prefect.blocks.secret.gcp-cred.client_x509_cert_url }}""
```

However, I encounter errors when Prefect tries to resolve templated blocks for block `prefect.blocks.secret.gcp-cred`. I did paste the whole GCP Credentials JSON keyfile into it, and it is serialized as string.

![Image](https://github.com/user-attachments/assets/35b6825e-1865-4001-9eec-f96fd18261e2)

The secret block:

![Image](https://github.com/user-attachments/assets/ea047fcf-baad-4195-889b-0a24646e3360)

Here's the error log when trying to run `dbt debug`:
<details><summary>Detail error log</summary>
<p>

```
Engine execution exited with unexpected exception
Traceback (most recent call last):
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/flow_engine.py"", line 1530, in run_flow
    ret_val = run_flow_sync(**kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/flow_engine.py"", line 1375, in run_flow_sync
    return engine.state if return_type == ""state"" else engine.result()
                                                       ^^^^^^^^^^^^^^^
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/flow_engine.py"", line 350, in result
    raise self._raised
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/flow_engine.py"", line 765, in run_context
    yield self
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/flow_engine.py"", line 1373, in run_flow_sync
    engine.call_flow_fn()
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/flow_engine.py"", line 785, in call_flow_fn
    result = call_with_parameters(self.flow.fn, self.parameters)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/utilities/callables.py"", line 208, in call_with_parameters
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File ""/opt/prefect/etl/flows/transform_dbt.py"", line 39, in dbt_flow
    run_dbt_command.with_options(name=f""{flow_name} - {' '.join(cmd[:2])}"")(cmd)
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/tasks.py"", line 1033, in __call__
    return run_task(
           ^^^^^^^^^
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/task_engine.py"", line 1576, in run_task
    return run_task_sync(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/task_engine.py"", line 1389, in run_task_sync
    return engine.state if return_type == ""state"" else engine.result()
                                                       ^^^^^^^^^^^^^^^
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/task_engine.py"", line 482, in result
    raise self._raised
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/task_engine.py"", line 805, in run_context
    yield self
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/task_engine.py"", line 1387, in run_task_sync
    engine.call_task_fn(txn)
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/task_engine.py"", line 828, in call_task_fn
    result = call_with_parameters(self.task.fn, parameters)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/utilities/callables.py"", line 208, in call_with_parameters
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File ""/opt/prefect/etl/lib/connectors/dbt.py"", line 27, in run_dbt_command
    dbt_runner.invoke([""deps""])
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect_dbt/core/runner.py"", line 418, in invoke
    with resolve_profiles_yml(invoke_kwargs[""profiles_dir""]) as profiles_dir:
  File ""/home/lelouvincx/.local/share/uv/python/cpython-3.11.10-linux-x86_64-gnu/lib/python3.11/contextlib.py"", line 137, in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect_dbt/core/profiles.py"", line 145, in resolve_profiles_yml
    profiles_yml = run_coro_as_sync(
                   ^^^^^^^^^^^^^^^^^
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/utilities/asyncutils.py"", line 207, in run_coro_as_sync
    return call.result()
           ^^^^^^^^^^^^^
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py"", line 329, in result
    return self.future.result(timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py"", line 192, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File ""/home/lelouvincx/.local/share/uv/python/cpython-3.11.10-linux-x86_64-gnu/lib/python3.11/concurrent/futures/_base.py"", line 401, in __get_result
    raise self._exception
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py"", line 402, in _run_async
    result = await coro
             ^^^^^^^^^^
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/utilities/asyncutils.py"", line 188, in coroutine_wrapper
    return await task
           ^^^^^^^^^^
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/client/utilities.py"", line 99, in with_injected_client
    return await fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/utilities/templating.py"", line 318, in resolve_block_document_references
    updated_value = await resolve_block_document_references(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/client/utilities.py"", line 99, in with_injected_client
    return await fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/utilities/templating.py"", line 318, in resolve_block_document_references
    updated_value = await resolve_block_document_references(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/client/utilities.py"", line 99, in with_injected_client
    return await fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/utilities/templating.py"", line 318, in resolve_block_document_references
    updated_value = await resolve_block_document_references(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/client/utilities.py"", line 99, in with_injected_client
    return await fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/utilities/templating.py"", line 318, in resolve_block_document_references
    updated_value = await resolve_block_document_references(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/client/utilities.py"", line 99, in with_injected_client
    return await fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/utilities/templating.py"", line 318, in resolve_block_document_references
    updated_value = await resolve_block_document_references(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/client/utilities.py"", line 99, in with_injected_client
    return await fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/prefect/.venv/lib/python3.11/site-packages/prefect/utilities/templating.py"", line 367, in resolve_block_document_references
    raise ValueError(
ValueError: Invalid template: '{{ prefect.blocks.secret.gcp-cred.type }}'. Could not resolve the keypath in the block document data.
with value_keypath: ['type']
with from_dict: <class 'prefect.utilities.annotations.NotSet'>
data type: <class 'str'>
template: {{ prefect.blocks.secret.gcp-cred.type }}
```

</p>
</details> 

So that you can see the extracted variable `data` [implemented here](https://github.com/PrefectHQ/prefect/blob/4e56e18ade9f18409c20a5e82b505aedcdd463a2/src/prefect/utilities/templating.py#L352-L359) is deserialized as string, but expected to be dictionary.

```diff
  File ""/opt/holistics/prefect/.venv/lib/python3.11/site-packages/prefect/utilities/templating.py"", line 367, in resolve_block_document_references
    raise ValueError(
ValueError: Invalid template: '{{ prefect.blocks.secret.gcp-cred.type }}'. Could not resolve the keypath in the block document data.
with value_keypath: ['type']
with from_dict: <class 'prefect.utilities.annotations.NotSet'>
-data type: <class 'str'>
template: {{ prefect.blocks.secret.gcp-cred.type }}
```

Because the variable `data` has type str, I cannot execute the function `get_from_dict` to extract keys, such as `type`, `project_id`, `private_key_id`, etc those I want them to be extracted.

### Describe the proposed behavior

My current workaround for this is to add a new line to deserialize it as JSON.

```diff
# resolving keypath/block attributes
if value_keypath:
+   data = json.loads(data) # add this single line to deserialize it as dictionary
    from_dict: Any = get_from_dict(data, value_keypath[0], default=NotSet)
    if from_dict is NotSet:
        raise ValueError(
            f""Invalid template: {template!r}. Could not resolve the""
            "" keypath in the block document data.""
        )
    value = from_dict
```

Everything works well after adding this line.

### Example Use

1. Spawn up Prefect
2. Add a new block with type Secret and content like a GCP Credential keyfile (JSON)
Example
```json
{
  ""type"": ""service_account"",
  ""project_id"": ""my-project-123456"",
  ""private_key_id"": ""abcabcabcabcabcabcabcabcabcabcabcabc"",
  ""private_key"": ""-----BEGIN PRIVATE KEY-----ddafldskjf;lasjfasfsdafjpowroashfls;akfjas;oldfpoaqihjosadkhjoasvjiaspodfijaslfkhjaso9fhsaoifhslakbgvhasokhpaoifhjwpofhsaldfhaspofdsa\n-----END PRIVATE KEY-----\n"",
  ""client_email"": ""client@email.iam.gserviceaccount.com"",
  ""client_id"": ""12345678912314"",
  ""auth_uri"": ""https://accounts.google.com/o/oauth2/auth"",
  ""token_uri"": ""https://oauth2.googleapis.com/token"",
  ""auth_provider_x509_cert_url"": ""https://www.googleapis.com/oauth2/v1/certs"",
  ""client_x509_cert_url"": ""https://www.googleapis.com/robot/v1/metadata/x509/client@email.iam.gserviceaccount.com""
}
```
3. Create a profile directory for dbt profiles with a `profiles.yml`
```yaml
my-bigquery:
  target: ""{{ prefect.variables.target }}""
  outputs:
    dev:
      type: bigquery
      method: service-account-json
      project: my-project-123456
      dataset: dev
      threads: 4
      priority: interactive
      keyfile_json:
        type: ""{{ prefect.blocks.secret.gcp-cred.type }}""
        project_id: ""{{ prefect.blocks.secret.gcp-cred.project_id }}""
        private_key_id: ""{{ prefect.blocks.secret.gcp-cred.private_key_id }}""
        private_key: ""{{ prefect.blocks.secret.gcp-cred.private_key }}""
        client_email: ""{{ prefect.blocks.secret.gcp-cred.client_email }}""
        client_id: ""{{ prefect.blocks.secret.gcp-cred.client_id }}""
        auth_uri: ""{{ prefect.blocks.secret.gcp-cred.auth_uri }}""
        token_uri: ""{{ prefect.blocks.secret.gcp-cred.token_uri }}""
        auth_provider_x509_cert_url: ""{{ prefect.blocks.secret.gcp-cred.auth_provider_x509_cert_url }}""
        client_x509_cert_url: ""{{ prefect.blocks.secret.gcp-cred.client_x509_cert_url }}""
```
4. Create a flow to run `dbt debug` and create deployment for it
```python
@task(name=""[dbt] Get dbt settings"")
def get_dbt_settings() -> PrefectDbtSettings:
    logger = get_run_logger()
    logger.info(""Getting dbt settings"")

    dbt_settings = PrefectDbtSettings(
        profiles_dir=Constants.dbt_PROFILES_DIR,
        project_dir=Constants.dbt_PROJECT_DIR,
    )

    return dbt_settings


@flow
def run_dbt_command(commands: list[str], raise_on_failure: bool = True):
    logger = get_run_logger()

    dbt_runner = PrefectDbtRunner(settings=get_dbt_settings(), raise_on_failure=raise_on_failure)

    logger.info(""Running dbt deps to ensure dependencies are up to date"")
    dbt_runner.invoke([""deps""])

    logger.info(f""Running dbt with command: {' '.join(commands)}"")
    dbt_runner.invoke(commands)

if __name__ == '__main__':
    run_dbt_command(['debug']).serve()
```

### Additional context

Versions:
- `prefect`: v3.2.9
- `prefect-dbt[bigquery]`: v0.7.0rc1
- `dbt-core`: v1.9.3
- `pyyaml`: v6.0.2

Using docker/K8S/Serverless? No, using as normal.",lelouvincx,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17492/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17492
17489,High database transactions rollback ratio,open,,2025-03-15T03:32:37Z,2025-03-24T20:48:20Z,,0,"['bug', 'Database']",FHU-yezi,,NONE,"### Bug summary

I am using [NetData](https://github.com/netdata/netdata) as a server monitor, and an alert shows that Prefect is making a lot of rollbacked transactions.

![](https://github.com/user-attachments/assets/b64b3260-ec34-47d5-a044-4100b433f4a1)

Currently it is not affect my server's performance, but is this normal or not?

### Version info

```Text
Version:             3.2.11
API version:         0.8.4
Python version:      3.12.9
Git commit:          9481694f
Built:               Wed, Mar 5, 2025 10:04 PM
OS/Arch:             linux/x86_64
Profile:             ephemeral
Server type:         server
Pydantic version:    2.10.6
Integrations:
  prefect-redis:     0.2.2
```

### Additional context

This is the most frequently executed SQL statment in my server:

```sql
INSERT INTO flow_run (deployment_id, deployment_version, parameters, idempotency_key, context, empirical_policy, tags, job_variables, auto_scheduled, flow_id, name, state_type, state_name, run_count, expected_start_time, next_scheduled_start_time, total_run_time, id, created, updated) VALUES ($1::UUID, $2::VARCHAR, $3::JSONB, $4::VARCHAR, $5::JSONB, $6, $7::JSONB, $8::JSONB, $9::BOOLEAN, $10::UUID, $11::VARCHAR, $12::state_type, $13::VARCHAR, $14::INTEGER, $15::TIMESTAMP WITH TIME ZONE, $16::TIMESTAMP WITH TIME ZONE, $17::INTERVAL, $18::UUID, $19::TIMESTAMP WITH TIME ZONE, $20::TIMESTAMP WITH TIME ZONE) ON CONFLICT (flow_id, idempotency_key) DO NOTHING
```",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17489/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17489
17484,Unable to retry flow using UI on push pool,open,,2025-03-14T22:24:57Z,2025-03-17T22:25:30Z,,0,"['bug', 'cloud']",ir3456,,NONE,"### Bug summary

We have a specific flow that we are unable to retry from the app.prefect.cloud UI. After clicking retry on the flow run page when the flow is in either a `Crashed` or `Failed` state, the flow shows up in the `Awaiting Retry` state and hangs there indefinitely. The flow runs on a Cloud Run V2 push pool. 

Being sufficiently complex, we rely on retries and caching behavior to allow us to retry the flow so that it effectively picks up where it left off because it does not need to rerun any tasks that had already succeeded. 

After contacting support, they suggested trying to use the API to directly set the state of the flow to `Scheduled`. When we tried this, it worked as expected, showing up as `Awaiting Retry` for ~30s before changing to a `Pending` state and shortly thereafter `Running`. 

We have consistently and repeatedly noticed this behavior with only a specific flow (relatively complex and described below). It works as expected with our other flows when retrying from the UI. While using the API to directly set the state to `Scheduled` works, this is certainly a workaround and not a fix.

### Version info

```Text
The issue here appears to be a bug in the Push Pool code when a flow is retried using the `Retry` button on the app.prefect.cloud UI. 

The main orchestration flow and all tasks it calls that run existing deployments are deployed using prefect 3.0.8.
```

### Additional context

Because we only notice this behavior with a single flow and that flow is sufficiently more complex than our other flows that we are able to retry, I will describe the structure of the flow, its tasks, and caching as they might be relevant to the problem. 

The flow in question is used exclusively to orchestrate multiple deployments. Each deployment that gets orchestrated has a corresponding task, each with its own retries and caching. In the flow, each task is submitted to the `ConcurrentTaskRunner`, some of which have upstream dependencies specified using the `wait_for` parameter. All task futures are collected into a `PrefectFutureList` and then `.result()` is called on the list of prefect futures to ensure that all tasks terminate, whether that be completed, crashed, failed, or have upstream dependencies that crashed or failed.

Assuming that there was a data issue, causing `task_3` to fail, once the issue is resolved, the simplest next step is to retry the flow, which would immediately identify `task_1` and `task_2` as `Completed` because they were cached and pick up where it left off, running `task_3`. Without being able to retry, we must either run the orchestration flow from the beginning which requires rerunning `task_1` and `task_2` or we can manually run `task_3` some other way, however, we lose the orchestration context. In this example `task_3` has no downstream dependencies, but our actual orchestration flow has 50+ tasks with far more complex dependencies which make manually running all tasks/deployments sufficiently difficult.

```
from prefect import task, flow
from prefect.deployments import run_deployment
from prefect.futures import PrefectFutureList
from prefect.tasks import exponential_backoff
from prefect_gcp.cloud_storage import GcsBucket

GCS_TASK_CACHING_BLOCK = GcsBucket.load(""gcs-task-caching"")

INCOMPLETE_RUN_STATES = [
    StateType.FAILED,
    StateType.CRASHED,
    StateType.CANCELLED,
    StateType.CANCELLING,
]


class PrefectPipelineTaskRunError(Exception):
    """"""Error to be raised when a task fails.""""""
    ...


def run_prefect_deployment_check_successful(
    deployment_name: str, params: dict[str, Any] | None = None
):
    """"""Runs a deployment and waits for completion, erroring if not successful.""""""
    if params:
        flow_run_result = run_deployment(deployment_name, parameters=params)
    else:
        flow_run_result = run_deployment(deployment_name)

    if flow_run_result.state_type in INCOMPLETE_RUN_STATES:
        raise PrefectPipelineTaskRunError(
            f""The pipeline task for running {deployment_name} failed ""
            f""with status {flow_run_result.state_type.value.upper()}.""
        )


@task(
    name=""task-1"",
    tags=[""pipelines""],
    version=get_version(),
    retries=2,
    retry_delay_seconds=exponential_backoff(backoff_factor=30),
    retry_jitter_factor=0.5,
    on_failure=[alert_slack_on_task_failure],
    result_storage=GCS_TASK_CACHING_BLOCK,
)
def task_1() -> None:
    deployment_name = ""flow-1/flow-1-deployment""

    run_prefect_deployment_check_successful(deployment_name=deployment_name)


@task(
    name=""task-2"",
    tags=[""pipelines""],
    version=get_version(),
    retries=2,
    retry_delay_seconds=exponential_backoff(backoff_factor=30),
    retry_jitter_factor=0.5,
    on_failure=[alert_slack_on_task_failure],
    result_storage=GCS_TASK_CACHING_BLOCK,
)
def task_2() -> None:
    deployment_name = ""flow-2/flow-2-deployment""

    run_prefect_deployment_check_successful(deployment_name=deployment_name)


@task(
    name=""task-3"",
    tags=[""pipelines""],
    version=get_version(),
    retries=2,
    retry_delay_seconds=exponential_backoff(backoff_factor=30),
    retry_jitter_factor=0.5,
    on_failure=[alert_slack_on_task_failure],
    result_storage=GCS_TASK_CACHING_BLOCK,
)
def task_3() -> None:
    deployment_name = ""flow-3/flow-3-deployment""

    run_prefect_deployment_check_successful(deployment_name=deployment_name)


@flow(name=""orchestration-flow"", retries=1)
def orchestration_flow():
    """"""Orchestrates jobs and declares dependencies between them.""""""
    task_futures = PrefectFutureList()

    task_1_future = task_1.submit()
    task_futures.append(task_1_future)
    task_2_future = task_2.submit()
    task_futures.append(task_2_future)
    task_3_future = task_3.submit(wait_for=[task_1_future, task_2_future])
    task_futures.append(task_3_future)

    task_futures.result()
```",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17484/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17484
17482,Flow Run continues to run after cancelled,open,,2025-03-14T21:18:13Z,2025-04-08T02:25:42Z,,2,['bug'],gscholtes-relativity,,NONE,"### Bug summary

A Flow Run in the running state can be cancelled (via API call to Prefect) and the Flow Run will continue to run, including new Tasks which start after the cancellation time.

Similar issues:
 - #16939 this issues mentions something about failing tasks (details unclear but in our case no failed tasks). In their case the flow run is cancelled via UI, so possibly a similar root cause?
 - #16001 this is for runs stuck in the Cancelling state. In contrast, we saw a run successfully enter the Cancelled state but then continue to run.

### Version info

```Text
Version:             3.1.3
API version:         0.8.4
Python version:      3.10.12
Git commit:          39b6028c
Built:               Tue, Nov 19, 2024 3:25 PM
OS/Arch:             linux/x86_64
Profile:             ephemeral
Server type:         cloud
Pydantic version:    2.9.2
Integrations:
  prefect-azure:     0.4.2
```

### Additional context

Some additional details: 

- In the Prefect UI and logs, we can see a `prefect.flow-run.Cancelled` log at the correct time
- The Start and End time in the UI show the true start of the run and the End time is the cancellation time. Duration is based on start to cancel time.
- New tasks Start and End after the cancellation time. Visible in logs and in UI

I will provide screenshots as possible (all from the same Flow Run):

Full run time visualized:
![Image](https://github.com/user-attachments/assets/8ac0cfd2-611b-4ca3-bbd2-29f253ea852c)

Start and End agree with cancelled log but not above screenshot:
![Image](https://github.com/user-attachments/assets/6c390dd6-43e6-4400-9e52-4c431135ed18)
![Image](https://github.com/user-attachments/assets/3041ddfe-a7e2-42a6-a710-a7c151d4b662)
![Image](https://github.com/user-attachments/assets/462cda83-6935-42ce-aa23-67201325ecc9)

The logs for the final Tasks of this Flow Run, which were scheduled to start, started, and ended after the cancel time and entered a completed state:
![Image](https://github.com/user-attachments/assets/1dcff986-44e4-4dda-a58a-5ce3ea27f924)

#### Reproduction steps

I have not identified a reliable way to reproduce this. Any insight appreciated.",,1,https://api.github.com/repos/PrefectHQ/prefect/issues/17482/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17482
17481,Flow Run time is displaying (1m 60s) instead of (2m 00s),closed,duplicate,2025-03-14T20:10:38Z,2025-03-14T20:16:31Z,2025-03-14T20:16:29Z,1,['bug'],matthewkrausse,,NONE,"### Bug summary

In the flow run, I am getting 1 minute and 60 seconds instead of 2 minutes. Small thing but figured I should share. 

### Version info

```Text
Version:             3.2.12
API version:         0.8.4
Python version:      3.12.3
Git commit:          826eb1a7
Built:               Mon, Mar 10, 2025 4:36 PM
OS/Arch:             darwin/arm64
Profile:             default
Server type:         cloud
Pydantic version:    2.10.6
Integrations:
  prefect-gcp:       0.6.4
```

### Additional context

_No response_",cicdw,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17481/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17481
17473,Getting repeated sqlite errors in Prefect server,closed,duplicate,2025-03-13T12:02:04Z,2025-03-13T14:45:22Z,2025-03-13T14:45:21Z,1,['bug'],satwikkansal,,NONE,"### Bug summary

Command run `prefect server start`

Sample stack trace

```sh
17:28:04.113 | ERROR   | prefect.server - Encountered error during state validation
Traceback (most recent call last):
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py"", line 1964, in _exec_single_context
    self.dialect.do_execute(
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/default.py"", line 942, in do_execute
    cursor.execute(statement, parameters)
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/dialects/sqlite/aiosqlite.py"", line 172, in execute
    self._adapt_connection._handle_exception(error)
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/dialects/sqlite/aiosqlite.py"", line 323, in _handle_exception
    raise error
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/dialects/sqlite/aiosqlite.py"", line 154, in execute
    self.await_(_cursor.execute(operation, parameters))
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py"", line 132, in await_only
    return current.parent.switch(awaitable)  # type: ignore[no-any-return,attr-defined] # noqa: E501
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py"", line 196, in greenlet_spawn
    value = await result
            ^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/aiosqlite/cursor.py"", line 40, in execute
    await self._execute(self._cursor.execute, sql, parameters)
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/aiosqlite/cursor.py"", line 32, in _execute
    return await self._conn._execute(fn, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/aiosqlite/core.py"", line 122, in _execute
    return await future
           ^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/aiosqlite/core.py"", line 105, in run
    result = function()
             ^^^^^^^^^^
sqlite3.OperationalError: database is locked

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/prefect/server/orchestration/rules.py"", line 274, in validate_proposed_state
    await self._validate_proposed_state()
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/prefect/server/orchestration/rules.py"", line 329, in _validate_proposed_state
    await self.session.flush()
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/ext/asyncio/session.py"", line 802, in flush
    await greenlet_spawn(self.sync_session.flush, objects=objects)
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py"", line 203, in greenlet_spawn
    result = context.switch(value)
             ^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/orm/session.py"", line 4353, in flush
    self._flush(objects)
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/orm/session.py"", line 4488, in _flush
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py"", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/orm/session.py"", line 4449, in _flush
    flush_context.execute()
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py"", line 463, in execute
    n.execute_aggregate(self, set_)
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py"", line 759, in execute_aggregate
    persistence.save_obj(
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py"", line 93, in save_obj
    _emit_insert_statements(
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py"", line 1233, in _emit_insert_statements
    result = connection.execute(
             ^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py"", line 1416, in execute
    return meth(
           ^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/sql/elements.py"", line 516, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py"", line 1638, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py"", line 1843, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py"", line 1983, in _exec_single_context
    self._handle_dbapi_exception(
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py"", line 2352, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py"", line 1964, in _exec_single_context
    self.dialect.do_execute(
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/default.py"", line 942, in do_execute
    cursor.execute(statement, parameters)
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/dialects/sqlite/aiosqlite.py"", line 172, in execute
    self._adapt_connection._handle_exception(error)
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/dialects/sqlite/aiosqlite.py"", line 323, in _handle_exception
    raise error
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/dialects/sqlite/aiosqlite.py"", line 154, in execute
    self.await_(_cursor.execute(operation, parameters))
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py"", line 132, in await_only
    return current.parent.switch(awaitable)  # type: ignore[no-any-return,attr-defined] # noqa: E501
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py"", line 196, in greenlet_spawn
    value = await result
            ^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/aiosqlite/cursor.py"", line 40, in execute
    await self._execute(self._cursor.execute, sql, parameters)
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/aiosqlite/cursor.py"", line 32, in _execute
    return await self._conn._execute(fn, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/aiosqlite/core.py"", line 122, in _execute
    return await future
           ^^^^^^^^^^^^
  File ""/Users/satwik/Library/Caches/pypoetry/virtualenvs/frdb-oc8f_yQV-py3.12/lib/python3.12/site-packages/aiosqlite/core.py"", line 105, in run
    result = function()
             ^^^^^^^^^^
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) database is locked
[SQL: INSERT INTO flow_run_state (flow_run_id, type, timestamp, name, message, state_details, data, result_artifact_id, id, created, updated) VALUES (:flow_run_id, :type, :timestamp, :name, :message, :state_details, :data, :result_artifact_id, :id, :created, :updated)]
[parameters: {'flow_run_id': '0260e2a4-f03e-47e1-ae48-bc7475218f2d', 'type': 'SCHEDULED', 'timestamp': '2025-03-13 11:58:01.815277', 'name': 'Late', 'message': None, 'state_details': '{""flow_run_id"": ""0260e2a4-f03e-47e1-ae48-bc7475218f2d"", ""task_run_id"": null, ""child_flow_run_id"": null, ""scheduled_time"": ""2025-03-13T09:30:00Z"", ""ca ... (149 characters truncated) ... y"": null, ""run_input_keyset"": null, ""refresh_cache"": null, ""retriable"": null, ""transition_id"": null, ""task_parameters_id"": null, ""traceparent"": null}', 'data': None, 'result_artifact_id': None, 'id': 'bc91a2dd-c801-4c3f-b786-1c26e48f4457', 'created': '2025-03-13 11:58:04.041787', 'updated': '2025-03-13 11:58:04.041847'}]
```

### Version info

```Text
frdb-py3.12âžœ  frdb_v2 git:(sync-positions-prefect) âœ— prefect version
Version:             3.2.12
API version:         0.8.4
Python version:      3.12.9
Git commit:          826eb1a7
Built:               Mon, Mar 10, 2025 4:36 PM
OS/Arch:             darwin/x86_64
Profile:             local
Server type:         server
Pydantic version:    2.10.6
```

### Additional context

_No response_",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17473/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17473
17456,confusing api url showing after `prefect server start`,open,,2025-03-12T18:55:22Z,2025-03-24T17:16:17Z,,3,['bug'],zzstoatzz,,COLLABORATOR,"### Bug summary

always shows 127.0.0.1

perhaps caused by (or not fixed by) https://github.com/PrefectHQ/prefect/pull/17386

### Version info

```Text
main
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17456/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17456
17452,Tasks stuck in AwaitingConcurrencySlot: Server returned a non-pending state 'SCHEDULED',closed,completed,2025-03-12T15:53:58Z,2025-03-24T16:55:21Z,2025-03-24T16:55:20Z,5,['bug'],Pballer,,NONE,"### Bug summary

We have tasks stuck and wont submit.   The UI ""Runs"" tab says the state is ""AwaitingConcurrencySlot"".  In the task logs it says the state is ""SCHEDULED"".


```
Worker 'ECSWorker 02ef6ae9-f573-411f-afdc-9fc0018a236f' submitting flow run '435b76c3-c610-4146-8aeb-cfeca5fea262'
Aborted submission of flow run '435b76c3-c610-4146-8aeb-cfeca5fea262': Server returned a non-pending state 'SCHEDULED'
```

I am able to reproduce it by:

1) Deploy a new flow with concurrency limit 1 with job_variables=None. 

2) Start the flow with job_variables=None. 
Worker template will use the default task definition we provide ""PrefectDefaultFlow"".  
This completes successfully. 
Logs:
```
Retrieving most recent active revision from ECS task family 'PrefectDefaultFlow'...
Using ECS task definition 'arn:aws:ecs:us-east-2:<our_account>:task-definition/PrefectDefaultFlow:7'...
```
3) Start the flow with job_variables:  
```
""cpu"": 1024,
""memory"": 4096,
""image"": ""<our_account>.dkr.ecr.us-east-2.amazonaws.com/prefect-ecr-flow:latest"",
""family"": ""<our_account>-us-east-2-prefect-ecr-flow-latest""
```
This also completes successfully. 

Logs:
```
Worker 'ECSWorker 02ef6ae9-f573-411f-afdc-9fc0018a236f' submitting flow run '539e8aa8-2693-40b6-8d14-2c277c991334'
Retrieving ECS task definition 'arn:aws:ecs:us-east-2:<our_account>:task-definition/PrefectDefaultFlow:7'...
Retrieving most recent active revision from ECS task family '<our_account>-us-east-2-prefect-ecr-flow-latest'...
Using ECS task definition 'arn:aws:ecs:us-east-2:<our_account>:task-definition/<our_account>-us-east-2-prefect-ecr-flow-latest:2'...
Creating ECS task run...
```

4) If I rerun step 3.  It gets stuck in AwaitingConcurrencySlot/SCHEDULED.
Logs:
```
Worker 'ECSWorker 02ef6ae9-f573-411f-afdc-9fc0018a236f' submitting flow run '435b76c3-c610-4146-8aeb-cfeca5fea262'
Aborted submission of flow run '435b76c3-c610-4146-8aeb-cfeca5fea262': Server returned a non-pending state 'SCHEDULED'
```

Based on my tests, it only happens when I change job_variables.



### Version info

```Text
Version:             3.2.12
API version:         0.8.4
Python version:      3.11.11
Git commit:          826eb1a7
Built:               Mon, Mar 10, 2025 4:36 PM
OS/Arch:             linux/x86_64
Profile:             ephemeral
Server type:         ephemeral
Pydantic version:    2.10.6
Server:
  Database:          AWS RDS Postgres
  Postgres version:  16.4
Integrations:
  prefect-aws:       0.5.5
```

### Additional context

_No response_",cicdw,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17452/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17452
17451,AttributeError: 'PrefectRouter' object has no attribute 'routes',closed,completed,2025-03-12T12:50:01Z,2025-03-13T15:12:21Z,2025-03-13T14:46:14Z,8,['bug'],Vict0r7,desertaxle,NONE,"### Bug summary

Hello,

Iâ€™m encountering an issue with the Prefect server that started after updating to the latest version. I have several automations configured, but they are now broken. Specifically, the ""custom webhook notification"" action appears to be malfunctioning, and also the ""resume suspended flow run"".

Error logs:
```
12:16:41.389 | ERROR   | prefect.server.utilities.messaging.memory - Failed in consume_loop
Traceback (most recent call last):
  File ""/usr/local/lib/python3.12/site-packages/prefect/server/utilities/messaging/memory.py"", line 356, in _consume_loop
    await handler(message)
  File ""/usr/local/lib/python3.12/site-packages/prefect/server/events/actions.py"", line 1731, in message_handler
    await action.act(triggered_action)
  File ""/usr/local/lib/python3.12/site-packages/prefect/server/events/actions.py"", line 1291, in act
    block = await self._get_notification_block(triggered_action=triggered_action)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/prefect/server/events/actions.py"", line 1258, in _get_notification_block
    async with await self.orchestration_client(triggered_action) as orion:
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/prefect/server/events/actions.py"", line 300, in orchestration_client
    return OrchestrationClient(
           ^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/prefect/server/api/clients.py"", line 40, in __init__
    api_app = create_app()
              ^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/prefect/server/api/server.py"", line 646, in create_app
    api_app = create_api_app(
              ^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/site-packages/prefect/server/api/server.py"", line 336, in create_api_app
    api_app.include_router(router, dependencies=dependencies)
  File ""/usr/local/lib/python3.12/site-packages/fastapi/applications.py"", line 1447, in include_router
    self.router.include_router(
  File ""/usr/local/lib/python3.12/site-packages/fastapi/routing.py"", line 1263, in include_router
    for r in router.routes:
             ^^^^^^^^^^^^^
AttributeError: 'PrefectRouter' object has no attribute 'routes'. Did you mean: 'route'?
```

### Version info

```Text
Prefect server v3.2.12
```

### Additional context

Custom webhook block document:

```json
{
  ""id"": ""9b983cf5-07ea-4721-9a0d-225bd8dd2d5b"",
  ""created"": ""2025-03-12T12:32:43.492129Z"",
  ""updated"": ""2025-03-12T12:32:43.492140Z"",
  ""name"": ""api-notification"",
  ""data"": {
    ""cookies"": null,
    ""form_data"": null,
    ""headers"": {
      ""x-token"": ""{{token}}""
    },
    ""json_data"": {
      ""payload"": ""{{body}}""
    },
    ""method"": ""POST"",
    ""name"": ""api-notification"",
    ""params"": null,
    ""secrets"": {
      ""token"": ""********""
    },
    ""timeout"": 10,
    ""url"": ""https://********/internal/prefect/flow-notification""
  },
  ""block_schema_id"": ""1a4bf7c9-d053-416e-b38a-6c1770cf1143"",
  [...]
}
```",desertaxle,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17451/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17451
17449,multiprocessing library inconsistencies on Deployment Flow runs,closed,not_planned,2025-03-11T19:23:30Z,2025-04-18T20:45:33Z,2025-04-10T21:00:42Z,3,"['bug', 'Stretch goal']",masonmenges,,CONTRIBUTOR,"### Bug summary

Utilizing the Multiprocessing library within a prefect flow run seems to work locally but causes failures or remains stuck indefinitely when triggering deployed runs with the same code. The following code executes successfully when run locally but when triggered as part of a deployment the run appears to be stuck indefinitely, only observed from a Kubernetes deployment, or fails with a pickling error seemingly from the multiprocessing library when run using .serve()


```python
from prefect import flow, task
from multiprocessing import Process
# from prefect.runner.storage import GitRepository


def print_func(continent='Asia'):
    print('The name of continent is : ', continent)

@task(log_prints=True)
def run_print_func():
    print(""This task is to print out given continents."")
    names = ['America', 'Europe', 'Africa']
    procs = []
    proc = Process(target=print_func)  # instantiating without any argument
    procs.append(proc)
    proc.start()

    # instantiating process with arguments
    for name in names:
        # print(name)
        proc = Process(target=print_func, args=(name,))
        procs.append(proc)
        proc.start()
    # complete the processes
    for proc in procs:
        proc.join()

@flow(name=""test-multiprocessing"")
def test_multiprocessing_flow():
    run_print_func()
    print(""Multiprocessing works!"")



if __name__ == ""__main__"":
    test_multiprocessing_flow.serve()
```

### Version info

```Text
Version:             3.2.11
API version:         0.8.4
Python version:      3.12.0
Git commit:          9481694f
Built:               Wed, Mar 5, 2025 10:00 PM
OS/Arch:             darwin/arm64
Profile:             masonsandbox
Server type:         cloud
Pydantic version:    2.10.6
```

### Additional context

Traceback from a served flow

```
13:16:42.878 | ERROR   | prefect.engine - Execution of flow run '3f700320-83c2-404f-a4eb-d8865d587fa1' exited with unexpected exception
Traceback (most recent call last):
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/site-packages/prefect/engine.py"", line 57, in handle_engine_signals
    yield
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/site-packages/prefect/engine.py"", line 124, in <module>
    run_flow(flow, flow_run=flow_run, error_logger=run_logger)
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/site-packages/prefect/flow_engine.py"", line 1530, in run_flow
    ret_val = run_flow_sync(**kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/site-packages/prefect/flow_engine.py"", line 1375, in run_flow_sync
    return engine.state if return_type == ""state"" else engine.result()
                                                       ^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/site-packages/prefect/flow_engine.py"", line 350, in result
    raise self._raised
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/site-packages/prefect/flow_engine.py"", line 765, in run_context
    yield self
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/site-packages/prefect/flow_engine.py"", line 1373, in run_flow_sync
    engine.call_flow_fn()
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/site-packages/prefect/flow_engine.py"", line 785, in call_flow_fn
    result = call_with_parameters(self.flow.fn, self.parameters)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/site-packages/prefect/utilities/callables.py"", line 208, in call_with_parameters
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File ""/Users/masonmenges/Repos/git_hub_repos/mm2-sanbox/flows/multiprocessing_test2.py"", line 32, in test_multiprocessing_flow
    run_print_func()
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/site-packages/prefect/tasks.py"", line 1033, in __call__
    return run_task(
           ^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/site-packages/prefect/task_engine.py"", line 1576, in run_task
    return run_task_sync(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/site-packages/prefect/task_engine.py"", line 1389, in run_task_sync
    return engine.state if return_type == ""state"" else engine.result()
                                                       ^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/site-packages/prefect/task_engine.py"", line 482, in result
    raise self._raised
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/site-packages/prefect/task_engine.py"", line 805, in run_context
    yield self
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/site-packages/prefect/task_engine.py"", line 1387, in run_task_sync
    engine.call_task_fn(txn)
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/site-packages/prefect/task_engine.py"", line 828, in call_task_fn
    result = call_with_parameters(self.task.fn, parameters)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/site-packages/prefect/utilities/callables.py"", line 208, in call_with_parameters
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File ""/Users/masonmenges/Repos/git_hub_repos/mm2-sanbox/flows/multiprocessing_test2.py"", line 16, in run_print_func
    proc.start()
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/multiprocessing/process.py"", line 121, in start
    self._popen = self._Popen(self)
                  ^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/multiprocessing/context.py"", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/multiprocessing/context.py"", line 289, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/multiprocessing/popen_spawn_posix.py"", line 32, in __init__
    super().__init__(process_obj)
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/multiprocessing/popen_fork.py"", line 19, in __init__
    self._launch(process_obj)
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/multiprocessing/popen_spawn_posix.py"", line 47, in _launch
    reduction.dump(process_obj, fp)
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/prefect_cloud/lib/python3.12/multiprocessing/reduction.py"", line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
_pickle.PicklingError: Can't pickle <function print_func at 0x112eb8fe0>: import of module '__prefect_loader_4615899616__' failed
13:16:43.467 | WARNING | EventsWorker - Still processing items: 3 items remaining...
13:16:45.970 | ERROR   | prefect.flow_runs.runner - Process for flow run 'spiffy-gecko' exited with status code: 1
```",linear[bot],0,https://api.github.com/repos/PrefectHQ/prefect/issues/17449/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17449
17446,Deployment name gets truncated,closed,completed,2025-03-11T14:55:59Z,2025-03-11T17:07:50Z,2025-03-11T17:07:50Z,0,['bug'],nnmm,,NONE,"### Bug summary

The `Flow.serve()` method seems to strip everything after and including the last dot in the name attribute. E.g. `etl-0.0.5` becomes `etl-0.0`.

To reproduce:

* `uv init prefect_deploy_bug --package`
* cd prefect_deploy_bug
* uv add prefect>=2.0
* Edit the code in `src/prefect_deploy_bug/__init__.py` to have this content:

```python
from prefect import flow
from prefect.logging import get_run_logger

@flow
def etl_flow() -> None:
    logger = get_run_logger()
    logger.info(""kthxbye"")

etl_flow.serve(
    name=""etl-0.0.5"",
    cron=""0 4 * * *"",  # Run every day at 4 AM
)
```

* In one terminal run `uv run prefect server start`
* In another, run `PREFECT_API_URL=http://127.0.0.1:4200/api uv run src/prefect_deploy_bug/__init__.py`
* Observe that the name for the deployment printed to the console and shown in the UI is `'etl-flow/etl-0.0`.

### Version info

```Text
Version:             3.2.12
API version:         0.8.4
Python version:      3.12.7
Git commit:          826eb1a7
Built:               Mon, Mar 10, 2025 4:36 PM
OS/Arch:             linux/x86_64
Profile:             local
Server type:         ephemeral
Pydantic version:    2.10.6
Server:
  Database:          sqlite
  SQLite version:    3.46.0
```

### Additional context

_No response_",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17446/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17446
17444,Show task logs when clicking on task node in UI,open,,2025-03-11T14:50:56Z,2025-03-11T16:26:13Z,,0,"['enhancement', 'ui']",cBournhonesque,,NONE,"### Describe the current behavior

In the UI, currently if you click on a task node, the log window still only shows the flow run logs.


### Describe the proposed behavior

It would be convenient if the log window would show the logs for the task

### Example Use

_No response_

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17444/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17444
17442,Logs still appear after disable_run_logger(),closed,completed,2025-03-11T13:40:56Z,2025-03-11T14:27:52Z,2025-03-11T14:27:52Z,0,['bug'],bnaul,desertaxle,CONTRIBUTOR,"### Bug summary

Noticed this because I was seeing logs from `prefect_gcp`'s `GcsBucket` that are inside a `disable_run_logger()` block.
```
from prefect import flow
from prefect.logging import disable_run_logger, get_run_logger, get_logger

@flow
def hello_flow():
    get_run_logger().info(""Should appear"")
    with disable_run_logger():
        flow_run_logger = get_logger(""prefect.flow_run"")
        task_run_logger = get_logger(""prefect.task_run"")
        print(f""{flow_run_logger.disabled=}"")
        print(f""{task_run_logger.disabled=}"")
        get_run_logger().info(""Should not appear"")

if __name__ == ""__main__"":
    hello_flow()
```
Gives
```
09:38:49.293 | INFO    | Flow run 'glittering-earwig' - Beginning flow run 'glittering-earwig' for flow 'hello-flow'
09:38:49.297 | INFO    | Flow run 'glittering-earwig' - View at https://app.prefect.cloud/account/1e4d7e04-0fb7-4aa3-8ef5-746e9f404f4f/workspace/849a6829-4afb-48c3-9cc2-2dc6b262fd9c/runs/flow-run/056c47b6-8f81-4dc0-ad43-c76d9cb09014
09:38:49.298 | INFO    | Flow run 'glittering-earwig' - Should appear
flow_run_logger.disabled=True
task_run_logger.disabled=True
09:38:49.299 | INFO    | Flow run 'glittering-earwig' - Should not appear
09:38:49.398 | INFO    | Flow run 'glittering-earwig' - Finished in state Completed()
```
Tried the same thing with `disable_run_logger()` outside the flow with the same result.

It seems like https://github.com/PrefectHQ/prefect/blob/main/tests/test_logging.py#L1731-L1750 is testing the case where we just call a task function directly w/ no flow context, so maybe something different is happening in the flow case?

### Version info

```Text
Version:             3.2.11
API version:         0.8.4
Python version:      3.10.16
Git commit:          9481694f
Built:               Wed, Mar 5, 2025 10:00 PM
OS/Arch:             darwin/arm64
Profile:             default
Server type:         cloud
Pydantic version:    2.9.2
Integrations:
  prefect-gcp:       0.6.2.dev1002+gbe1ba636e4.d20250311
  prefect-dask:      0.3.3
  prefect-kubernetes: 0.5.3
```

### Additional context

_No response_",desertaxle,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17442/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17442
17437,Unexpected CLI prompt to save deployment configuration part 2,closed,completed,2025-03-10T17:20:40Z,2025-04-10T02:09:38Z,2025-04-10T02:09:38Z,4,['bug'],ddeepwell,,NONE,"### Bug summary

Unfortunately, #17410 which was meant to fix #17409 did not remove the prompt since `should_prompt_for_save` still returns True. `should_prompt_for_save` is an alias for [`app.console.is_interactive`](https://github.com/PrefectHQ/prefect/blob/main/src/prefect/cli/root.py#L38) where `console` is a [Rich](https://pypi.org/project/rich/) Console which returns true for the `is_interactive` property (as seen [here](https://github.com/Textualize/rich/blob/master/rich/console.py#L740)) when executing the command `prefect deploy`.

### Version info

```Text
Version:             3.2.12
API version:         0.8.4
Python version:      3.13.2
Git commit:          826eb1a7
Built:               Mon, Mar 10, 2025 4:36 PM
OS/Arch:             darwin/arm64
Profile:             local
Server type:         server
Pydantic version:    2.10.6
```

### Additional context

_No response_",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17437/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17437
17434,Cannot deploy flow from within a flow,closed,completed,2025-03-10T14:11:01Z,2025-03-11T14:34:41Z,2025-03-10T16:03:41Z,4,['bug'],bnaul,,CONTRIBUTOR,"### Bug summary

Related to / manifestation of #15008:
```
from prefect import flow
from util.prefect import hello_flow  # just some flow

@flow
def deploy():
    hello_flow.deploy(
        name=""my-deployment"",
        work_pool_name=""data-default"",
        build=False,
        _sync=True,
    )

if __name__ == ""__main__"":
    deploy()
```
fails with
```
File ~/model/.venv/lib/python3.10/site-packages/prefect/flows.py:1496, in Flow.deploy(self, name, work_pool_name, image, build, push, work_queue_name, job_variables, interval, cron, rrule, paused, schedule, schedules, concurrency_limit, triggers, parameters, description, tags, version, enforce_parameter_schema, entrypoint_type, print_next_steps, ignore_warnings, _sla)
   1493 if TYPE_CHECKING:
   1494     assert inspect.isawaitable(to_deployment_coro)
-> 1496 deployment = await to_deployment_coro
   1498 from prefect.deployments.runner import deploy
   1500 deploy_coro = deploy(
   1501     deployment,
   1502     work_pool_name=work_pool_name,
   (...)
   1507     ignore_warnings=ignore_warnings,
   1508 )

TypeError: object RunnerDeployment can't be used in 'await' expression
```

### Version info

```Text
Version:             3.2.11
API version:         0.8.4
Python version:      3.10.16
Git commit:          9481694f
Built:               Wed, Mar 5, 2025 10:00 PM
OS/Arch:             darwin/arm64
Profile:             default
Server type:         cloud
Pydantic version:    2.10.6
Integrations:
  prefect-gcp:       0.6.2
  prefect-dask:      0.3.3
  prefect-kubernetes: 0.5.3
```

### Additional context

_No response_",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17434/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17434
17433,"Work queues status ""Not Ready"" but Worker is ""online""",closed,completed,2025-03-10T13:49:41Z,2025-03-11T14:16:34Z,2025-03-11T14:16:32Z,3,['bug'],Pballer,,NONE,"### Bug summary

When I upgraded self-hosted Prefect from 3.0.2 to 3.2.5 the Work Queues status is stuck in ""Not Ready"". 

The Worker is online and submitting jobs as expected.  

### Version info

```Text
Version:             3.2.5
API version:         0.8.4
Python version:      3.9.20
Git commit:          168280f7
Built:               Wed, Feb 19, 2025 3:25 AM
OS/Arch:             linux/aarch64
Profile:             ephemeral
Server type:         ephemeral
Pydantic version:    2.10.6
Server:
  Database:          AWS RDS Postgres 
  Postgres version:  16.4
Integrations:
  prefect-aws:       0.5.5
```

### Additional context

For an additional test, I deleted and recreated the work pool.  The worker started as normal and was able to submit jobs successfully. But the queues are still in Not Ready state.",Pballer,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17433/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17433
17432,Secrets used in deployment visible in UI,open,,2025-03-10T13:42:01Z,2025-03-12T09:15:22Z,,6,['bug'],9cpluss,,NONE,"### Bug summary

Hi,
I am using the Secret blocks to store passwords that are used in deployments to pass them into the flow run environment. But when I check the deployment in the UI via Deployments > <name of deployment> > Configuration I can see all passwords in clear text under Job Variables.

Here is an example deployment file:

```python
from prefect import flow, task
from prefect.blocks.system import Secret
from prefect.variables import Variable


@task
def hello_world():
    print(""Hello, world!"")


@flow(log_prints=True)
def my_flow():
    hello_world()


if __name__ == ""__main__"":
    db_password = Secret.load(""db-password"")

    my_flow.deploy(
        name=""hello-world"",
        work_pool_name=""docker"",
        job_variables={
            ""env"": {
                ""DB_USER"": Variable.get(""db"")[""user""],
                ""DB_PASS"": db_password.get(),
            },
        },
        image=""python:3.9"",
        build=False,
        push=False,
    )
```

### Version info

```Text
Version:             3.1.4
API version:         0.8.4
Python version:      3.10.12
Git commit:          
Built:               Wed, Nov 20, 2024 7:37 PM
OS/Arch:             linux/x86_64
Profile:             local
Server type:         server
Pydantic version:    2.10.2
Integrations:
  prefect-docker:    0.6.2
```

### Additional context

Here is a screenshot of me setting the Secret:

![Image](https://github.com/user-attachments/assets/e862ca63-4aac-4910-b277-fa1ae2d774ef)


And here is what it looks like in the UI after the deployment was created:

![Image](https://github.com/user-attachments/assets/dc4b8cfc-1fba-4fb7-95aa-c59dd4ddcb49)

As you can see the password is not obfuscated.

Maybe I am using it wrong but I would expect the password to be obfuscated.",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17432/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17432
17431,prefect-gcp 0.6.3 does not define extras,closed,completed,2025-03-10T12:43:58Z,2025-03-10T14:31:07Z,2025-03-10T14:24:27Z,2,['bug'],neurolabs,desertaxle,NONE,"### Bug summary

```bash
pip install prefect-gcp[all_extras]
```
prints `WARNING: prefect-gcp 0.6.3 does not provide the extra 'all-extras'` and using any extras fails.

Flows then fail with `ImportError(""To use prefect_gcp.bigquery, install prefect-gcp with the 'bigquery' extra: \`pip install 'prefect_gcp[bigquery]'\`"") `

It all works with

```bash
pip install prefect-gcp[all_extras]==0.6.2
```



### Version info

```Text
Version:             3.2.11
API version:         0.8.4
Python version:      3.12.9
Git commit:          9481694f
Built:               Wed, Mar 5, 2025 10:00 PM
OS/Arch:             linux/x86_64
Profile:             ephemeral
Server type:         server
Pydantic version:    2.10.6
Integrations:
  prefect-gcp:       0.6.3
```

### Additional context

_No response_",desertaxle,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17431/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17431
17427,Missing environment variable in self hosted worker guide,closed,completed,2025-03-08T14:11:21Z,2025-03-16T15:17:30Z,2025-03-16T15:17:29Z,3,['bug'],happysalada,,CONTRIBUTOR,"### Bug summary

When running the self hosted workflow guide, I managed to deploy the server successfully, however when deploying a worker pool, there seems to be missing environment variables, because I see many errors.

Here is a list of problem.
- first warning is ""UserWarning: Failed to create the Prefect home directory at /.prefect""
I am passing ""              ""PREFECT_HOME=%S/prefect-worker-${poolName}"" to the systemd service though, which is started with the following command
            ExecStart = ''
              ${pkgs.prefect}/bin/prefect worker start \
                --pool ${poolName} \
                --type process \
                --install-policy ${poolCfg.installPolicy}
            '';
The environment variable seems to be ignored for the worker, not sure why.
- Second problem is that a temporary server is being started
-  GLOBAL_SETTINGS_CONTEXT: SettingsContext = root_settings_context()
 14:02:19.479 | INFO    | prefect - Starting temporary server on http://
I am passing 
              ""PREFECT_API_URL=${cfg.baseUrl}/api""
I am not sure why this variable is being ignored. Is there another environment variable that I should be passing ? Why is this starting a temporary server ? Do I need a temporary server to run the worker pool, can I not connect to my already running server ?



### Version info

```Text
version 3.2.7
python version 3.12.9
```

### Additional context

I'm currently packaging prefect for nixos to have a seemless experience upon startup.
If you give me more details, I'm happy to test things and make a PR to contribute to the docs for prefect.
Thank you for making prefect!",happysalada,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17427/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17427
17416,[UI] Tag filter selection not saved in session for UI when navigating between left-side menu items,closed,completed,2025-03-07T18:04:01Z,2025-04-25T16:01:06Z,2025-04-25T16:01:06Z,1,['bug'],robfreedy,,CONTRIBUTOR,"### Bug summary

In Prefect Cloud, the tag selection is not saved in session when navigating back and forth between left-side navigation tabs. 

Steps to reproduce: 

1. Select a tag filter on the ""Flows"" page 

<img width=""1200"" alt=""Image"" src=""https://github.com/user-attachments/assets/dcefe1f5-83af-4481-9d1e-3fc7cd5ec24e"" />

2. Navigate to another left side menu item (i.e. ""Runs"", for example) 

3. Navigate back to the ""Flows"" page where the tag filter has been cleared

<img width=""1200"" alt=""Image"" src=""https://github.com/user-attachments/assets/90e7d130-cb34-4512-a3fc-4c8f33bff3be"" />

One thing to note is that these tag filter selections are saved on page refresh. 

### Version info

```Text
N/A
```

### Additional context

Recreated in Prefect Cloud (not tested in Prefect server) ",linear[bot],0,https://api.github.com/repos/PrefectHQ/prefect/issues/17416/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17416
17415,Prevent Orphaned Slots in Concurrency Limits,open,,2025-03-07T17:29:43Z,2025-03-07T17:29:43Z,,0,['enhancement'],aaazzam,,COLLABORATOR,"### Describe the current behavior

Currently, Prefect implements global concurrency limits that allow tasks to acquire locks on a number of slots from a shared pool. These limits can optionally be configured with a ""leaky bucket"" algorithm that gradually returns slots to the pool over time, effectively functioning as a rate limit.

When the slot decay is not configured (standard concurrency limit), there are scenarios where tasks can indefinitely hold onto concurrency slots:

1. If the container running a task dies unexpectedly
2. In some instances when a parent flow is canceled
3. When a task fails in a way that prevents proper cleanup

These orphaned concurrency slots become unavailable to other tasks, gradually depleting the pool. This situation is particularly difficult to debug as there's no clear indication of which tasks are holding onto slots or when they were acquired, leading to mysterious ""concurrency limit reached"" errors that require manual intervention to resolve.



### Describe the proposed behavior

To address these issues, we propose implementing a ""leased lock"" paradigm, common in distributed concurrency systems:

1. Each concurrency limit would enforce a lease duration for acquired slots
2. Tasks that acquire slots would need to periodically renew their lease while they're still running
3. If a task fails to renew its lease within the specified timeframe, the slots would be automatically released back to the pool

This approach provides several benefits:

- **Self-healing:** Orphaned slots automatically return to the pool after the lease expires
- **Visibility:** The renewal pattern provides a heartbeat mechanism that can be monitored
- **Configurable safety:** Lease durations can be tuned based on workload patterns
- **Compatibility:** Can work alongside existing slot decay configurations

## Implementation Details

The leased lock system would include:

- A configurable `lease_duration` parameter for concurrency limits (defaulting to a reasonable value like 5 minutes)
- A background renewal process that automatically extends leases for running tasks
- A cleanup mechanism that scans for expired leases and returns slots to the pool
- Logging and observability improvements to track lease acquisitions and releases

Users would be able to:
- Specify different lease durations for different concurrency limits
- Monitor lease status through the Prefect UI
- Configure alert policies for frequently expired leases (which might indicate infrastructure issues)

## Migration Path

This change would be backward compatible with existing concurrency limit configurations. By default, the lease duration would be set sufficiently high to prevent unexpected slot releases for most workloads, but low enough to recover from common failure scenarios.

For users experiencing frequent orphaned slots, enabling shorter lease durations would provide immediate relief without requiring changes to their task code.

### Example Use

_No response_

### Additional context

_No response_",,6,https://api.github.com/repos/PrefectHQ/prefect/issues/17415/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17415
17414,DaskTaskRunner does not properly wait for mapped futures,closed,completed,2025-03-07T17:24:28Z,2025-03-07T21:43:23Z,2025-03-07T21:42:41Z,5,"['bug', 'integrations']",bnaul,,CONTRIBUTOR,"### Bug summary

When passing a list of mapped futures to a downstream task via `wait_for`, the downstream tasks runs immediately and does not wait:
(EDIT: fixed typo)
```python
from prefect import task, flow
from prefect_dask import DaskTaskRunner
from time import sleep

@task
def list_nums():
    return [1, 5, 10]

@task(log_prints=True)
def wait(n: int):
    print(f""Sleeping for {n=}"")
    sleep(n)
    return n

@task(log_prints=True)
def should_wait():
    return ""I'm running!""


@flow(task_runner=DaskTaskRunner(address=""localhost:8786""))
def my_flow():
    nums = list_nums.submit()
    futures = wait.map(nums)                                       # does not wait
    # futures = [wait.submit(1), wait.submit(5), wait.submit(10)]  # waits as expected
    result = should_wait.submit(wait_for=futures)
    return result


if __name__ == ""__main__"":
    my_flow()
```
output:
```
12:22:51.375 | INFO    | Task run 'wait-dee' - Sleeping for n=1
12:22:51.408 | INFO    | Task run 'wait-1e1' - Sleeping for n=10
12:22:51.409 | INFO    | Task run 'wait-737' - Sleeping for n=5
12:22:51.409 | INFO    | Task run 'block-48b' - Finished in state Completed()
12:22:52.382 | INFO    | Task run 'wait-dee' - Finished in state Completed()
12:22:56.412 | INFO    | Task run 'wait-737' - Finished in state Completed()
12:23:01.435 | INFO    | Task run 'wait-1e1' - Finished in state Completed()
```

When passing a list of `.submit` futures, the downstream task does wait as expected. Removing the `DaskTaskRunner` also fixes the issue for both `[.submit()]` and `.map`

### Version info

```Text
Version:             3.2.11
API version:         0.8.4
Python version:      3.10.16
Git commit:          9481694f
Built:               Wed, Mar 5, 2025 10:00 PM
OS/Arch:             darwin/arm64
Profile:             default
Server type:         cloud
Pydantic version:    2.9.2
Integrations:
  prefect-gcp:       0.6.2
  prefect-dask:      0.3.3
  prefect-kubernetes: 0.5.3
```

### Additional context

_No response_",bnaul,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17414/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17414
17409,Unexpected CLI prompt to save deployment configuration,closed,completed,2025-03-06T23:10:54Z,2025-03-07T17:20:30Z,2025-03-07T17:20:30Z,1,['bug'],ddeepwell,,NONE,"### Bug summary

When creating a deployment via the CLI, a prompt to save the configuration occurs when an environment variable is set, but no prompt occurs when the variable is not set.

When no environment variable is set, prefect does throw a warning, but continues without prompting to save.

When the environment variable is set, prefect prompts to save and deploys the configuration as expected. I do not expect (nor want) the prompt since the file should be configured correctly.

Here is a minimum working example.

```yaml
#prefect.yaml
name: Env-var-bug
prefect-version:

build:
push:

pull:
  - prefect.deployments.steps.set_working_directory:
      directory: ""{{ $WORKING_DIRECTORY }}""

deployments:
  - name: bugged-deployment
    version:
    tags: []
    concurrency_limit:
    description:
    entrypoint: flow.py:my_flow
    parameters:
      settings_file: ""{{ $SETTINGS_FILE }}""
    work_pool:
      name: work-pool
      work_queue_name:
      job_variables: {}
    schedules: []
```

```python
#flow.py

from pathlib import Path
from prefect import flow


@flow(log_prints=True)
def my_flow(settings_file: Path):
    print(f""Running my scheduled flow with file {settings_file}..."")
```

Case 1: Unset environment variable - does not prompt (as expected)

```bash
prefect deploy --name bugged-deployment
```

Case 2: Set environment variable - does prompt (unexpected)

```bash
export SETTINGS_FILE=prefect.yaml 
prefect deploy --name bugged-deployment
```

The prompt is: ""Would you like to save configuration for this deployment for faster deployments in the future? [y/n]:""

Case 3: No environment variable - does not prompt (as expected)

Replace `""{{ $SETTINGS_FILE }}""` with `prefect.yaml` and execute:

```bash
prefect deploy --name bugged-deployment
```


### Version info

```Text
Version:             3.2.11
API version:         0.8.4
Python version:      3.13.2
Git commit:          9481694f
Built:               Wed, Mar 5, 2025 10:00 PM
OS/Arch:             darwin/arm64
Profile:             local
Server type:         server
Pydantic version:    2.10.6
```

### Additional context

_No response_",cicdw,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17409/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17409
17406,Deployment env vars in the k8s list format aren't merged with work pool env vars,closed,completed,2025-03-06T21:55:45Z,2025-03-21T15:01:46Z,2025-03-21T15:01:46Z,0,['bug'],masonmenges,zzstoatzz,CONTRIBUTOR,"### Bug summary

Kubernetes work pools allow users to supply env vars as a dictionary of kv pairs or as a list of k8s-style `{NAME: <name>, VALUE: <value>}` pairs (see https://github.com/PrefectHQ/prefect/blob/main/src/integrations/prefect-kubernetes/prefect_kubernetes/worker.py#L345). The base case of a standard dictionary is eventually converted into the k8s style on the k8s worker. When env vars are in kv dict form, the pairs supplied on the work pool and on the deployment are merged by the `BaseWorker` (see https://github.com/PrefectHQ/prefect/blob/main/src/prefect/workers/base.py#L150).

Env vars set on a Kubernetes work pool that are supplied as a list are currently not merged with env vars in a deployment, with the deployment env vars taking precedence. A list of env vars in k8s format should be subject to the same behavior as env vars supplied as a dict.

Work pool Environment variables:
```
[
  {
    ""name"":""SUPER_SECRET"", 
    ""valueFrom"": {
      ""secretKeyRef"": {
        ""key"": ""super-secret"",
        ""name"": ""some-new-secret-test""
      }
    }
  },
  {
    ""name"": ""some workpool variable"",
    ""value"": ""SUPER WORKPOOL VARIABLE""
  }
]
```

Deployment Environment Variables:
```
[{""name"": ""env_var_job_var_new"", ""value"": ""job_var1""}]
```

Environment Variables from the pod:
```
        - name: PREFECT_DEBUG_MODE
          value: 'False'
        - name: PREFECT_API_URL
          value: 
        - name: PREFECT_API_KEY
          value: 
        - name: PREFECT_API_ENABLE_HTTP2
          value: 'True'
        - name: PREFECT_LOGGING_LEVEL
          value: DEBUG
        - name: PREFECT_SERVER_EPHEMERAL_ENABLED
          value: 'True'
        - name: PREFECT_WORKER_QUERY_SECONDS
          value: '5.0'
        - name: PREFECT_WORKER_PREFETCH_SECONDS
          value: '10.0'
        - name: PREFECT__FLOW_RUN_ID
          value: 324db939-06c6-45be-9b86-cdcd4919fe2c
        - name: env_var_job_var_new
          value: job_var1
```

### Version info

```Text
Version:             3.2.11
API version:         0.8.4
Python version:      3.12.4
Git commit:          9481694f
Built:               Wed, Mar 5, 2025 10:00 PM
OS/Arch:             darwin/arm64
Profile:             masonsandbox
Server type:         cloud
Pydantic version:    2.10.6
Integrations:
  prefect-dask:      0.3.2
  prefect-snowflake: 0.28.0
  prefect-slack:     0.3.0
  prefect-gcp:       0.6.2
  prefect-aws:       0.5.0
  prefect-gitlab:    0.3.1
  prefect-dbt:       0.6.4
  prefect-kubernetes: 0.5.8
  prefect-docker:    0.6.1
  prefect-sqlalchemy: 0.5.1
  prefect-shell:     0.3.1
```

### Additional context

_No response_",zzstoatzz,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17406/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17406
17398,UI Variable updates don't work correctly when adding prefixed text,closed,completed,2025-03-06T15:36:06Z,2025-04-09T15:20:12Z,2025-04-09T15:20:12Z,2,"['bug', 'ui']",joshcaskie,,NONE,"### Bug summary

Hello! I would like to report a bug with updating Variables defined in the Cloud UI. Whenever I update a variable and prepend a word to a plain string `""""`, any change with a space character is not saved correctly.

I'll go through an example:
1. Created a new variable with the text `""hello there""`.
2. Edit the variable to change the text to `""hi hello there""`. 
3. Save the changes.
4. Observe the new state of the variable is `""hihello there""`.

I'll share screenshots below.

Thank you!

### Version info

```Text
n/a (Cloud Only)
Google Chrome Version 133.0.6943.142 (Official Build) (arm64)
```

### Additional context

![Image](https://github.com/user-attachments/assets/ccf6c333-78bb-465c-aac4-e69a7ddea939)

![Image](https://github.com/user-attachments/assets/0b3045e2-8bb8-4555-8da9-50d16c6a4f47)

![Image](https://github.com/user-attachments/assets/5913ef7a-e905-49e2-ba04-347826e060b0)

![Image](https://github.com/user-attachments/assets/887b0c62-e7ed-4922-9150-237f808bb40d)",znicholasbrown,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17398/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17398
17397,"pull steps in configuraion is not updated, when update GitLabCredentials info for an existing deployment,",closed,completed,2025-03-06T09:59:34Z,2025-03-06T19:51:40Z,2025-03-06T19:51:38Z,1,['bug'],zhulinJulia24,,NONE,"### Bug summary

1. run deployment like this

```
from prefect import flow
from prefect.blocks.system import Secret
from prefect.runner.storage import GitRepository
from prefect_gitlab import GitLabCredentials

if __name__ == ""__main__"":
    gitlab_repo = GitRepository(
        url=""https://xxxx"",
        credentials=GitLabCredentials.load(""my-gitlab-credentials-block""),
        branch=""dev"",
        pull_interval=60,
    )

    flow.from_source(
        source=gitlab_repo,
        entrypoint=""src/xx.py:run_standard_preprocessing_flow"",
    ).deploy(
        name=""standard_preprocessing_daily"",
        work_pool_name=""cpu"",
    )

```

2. then update GitLabCredentials, and rerun it. 

```
from prefect import flow
from prefect.blocks.system import Secret
from prefect.runner.storage import GitRepository
from prefect_gitlab import GitLabCredentials

if __name__ == ""__main__"":
    gitlab_repo = GitRepository(
        url=""https://xxxx"",
        credentials=GitLabCredentials.load(""compass-flow-project-access-token""),
        branch=""dev"",
        pull_interval=60,
    )

    flow.from_source(
        source=gitlab_repo,
        entrypoint=""src/xx.py:run_standard_preprocessing_flow"",
    ).deploy(
        name=""standard_preprocessing_daily"",
        work_pool_name=""cpu"",
    )

```
pull steps in configuraion is not updated. 


![Image](https://github.com/user-attachments/assets/c932e6dc-e299-4314-b331-1edbbf58b30b)



### Version info

```Text
Version:             3.2.0
API version:         0.8.4
Python version:      3.10.16
Git commit:          c8986ede
Built:               Fri, Feb 7, 2025 6:02 PM
OS/Arch:             linux/x86_64
Profile:             local
Server type:         server
Pydantic version:    2.10.6
Integrations:
  prefect-gitlab:    0.3.1
  prefect-dask:      0.3.3
```

### Additional context

_No response_",cicdw,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17397/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17397
17391,`from prefect.deployments import run_deployment` fails on 3.2.10,closed,completed,2025-03-05T21:11:29Z,2025-03-05T22:12:40Z,2025-03-05T21:55:12Z,2,['bug'],abefrandsen,,NONE,"### Bug summary

In the latest release of prefect (3.2.10), I get the following result:
```python
from prefect.deployments import run_deployment
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/abe/.pyenv/versions/3.10.16/lib/python3.10/site-packages/prefect/deployments/__init__.py"", line 32, in __getattr__
    module = import_module(module_name, package=package)
  File ""/home/abe/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""/home/abe/.pyenv/versions/3.10.16/lib/python3.10/site-packages/prefect/deployments/flow_runs.py"", line 7, in <module>
    from opentelemetry.instrumentation.utils import is_instrumentation_enabled
ModuleNotFoundError: No module named 'opentelemetry.instrumentation'
```

If I revert to 3.2.8, the same command succeeds. The error message calls out line 7 of `flow_runs.py` as the culprit, and indeed that line was only added on this most recent release of prefect. 

### Version info

```Text
Version:             3.2.10+3.g459cb4722d
API version:         0.8.4
Python version:      3.10.16
Git commit:          459cb472
Built:               Wed, Mar 5, 2025 9:07 PM
OS/Arch:             linux/x86_64
Profile:             ephemeral
Server type:         ephemeral
Pydantic version:    2.10.6
Server:
  Database:          sqlite
  SQLite version:    3.45.1
```

### Additional context

_No response_",desertaxle,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17391/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17391
17388,create explicit methods for ambiguously typed `Task` kwargs,open,,2025-03-05T18:36:24Z,2025-03-05T18:40:35Z,,0,"['enhancement', 'development']",zzstoatzz,,COLLABORATOR,"### Describe the current behavior

## Problem
There are many ways to use the task decorator, whether on functions or instance methods,  which today we try to handle all this with overloads.

In particular, using keyword arguments like `return_state` and `wait_for` in task calls makes proper type checking (nearly, if not) impossible. These kwargs modify the return type of a task (e.g., changing from `R` to `State[R]` when `return_state=True`), which breaks static type checking in `mypy` and `pyright`. This creates frustrating developer experiences and makes it difficult to rely on type checkers for preventing bugs.

```python
state = my_task(arg1, return_state=True)  # we can't quite handle all cases with overloads
```

### Describe the proposed behavior

Create explicit methods on `Task` objects that clearly indicate their return type, e.g.
- `call_and_return_state`
- `submit_and_return_state`
- existing `__call__`
- existing `submit`

### Example Use

```python
# Use explicit methods that return exactly what they say
state = my_task.call_and_return_state(...)
state = my_task.submit_and_return_state(...)
```

### Additional context

We'll want to re-use some interface so we don't have to maintain even more methods in different places

related to #17379 ",,2,https://api.github.com/repos/PrefectHQ/prefect/issues/17388/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17388
17384,DaskTaskRunner does not handle Dask exceptions,open,,2025-03-05T15:26:03Z,2025-03-05T15:26:42Z,,0,['bug'],bnaul,,CONTRIBUTOR,"### Bug summary

In `PrefectDaskFuture.wait`, it's assumed (per [this comment](https://github.com/PrefectHQ/prefect/blob/eb9d51f7c507adeed73a460c234594a815c9b4c0/src/integrations/prefect-dask/prefect_dask/task_runners.py#L120)) that either `future.result()` returns a `State` or times out.  But there are other possible failure states described [here](https://distributed.dask.org/en/stable/killed.html) that are not handled, and lead to a fairly cryptic failure message:
```
File ~/model/.venv/lib/python3.10/site-packages/prefect/states.py:509, in get_state_exception(state)
    507     default_message = ""Run cancelled.""
    508 else:
--> 509     raise ValueError(f""Expected failed or crashed state got {state!r}."")
    511 if isinstance(state.data, ResultRecord):
    512     result = state.data.result

ValueError: Expected failed or crashed state got Running(message='', type=RUNNING, result=None).
```

To reproduce, I am running a simple flow like below on a local dask cluster:
```
from time import sleep
from prefect import flow, task
from prefect_dask import DaskTaskRunner

@flow(task_runner=DaskTaskRunner(address=""localhost:8786""))
def wait_flow():
    @task
    def wait():
        sleep(30)
        return True
    result = wait.submit()
    return result

if __name__ == ""__main__"":
    wait_flow()
```
and killing the dask worker until the scheduler declares the task suspicious and gives up:
```
distributed.scheduler.KilledWorker: Attempted to run task slow_task-a25511e480b7951003007c0155e3f56c on 1 different workers, but all those workers died while running it. The last worker that attempt to run the task was tcp://127.0.0.1:60949. Inspecting worker logs is often a good next step to diagnose what went wrong. For more information see https://distributed.dask.org/en/stable/killed.html.
```
Because of the `except: return` block linked above, we end up not returning any kind of State, leading to the `Expected failed or crashed state got Running` failure.

Not super familiar with the new State ontology yet but it seems like `KilledWorker` or `CommError` should probably result in a `Crashed` state?

cc Coiled folks @mrocklin @ntabris @jrbourbeau in case anyone has a stronger and better informed opinion than I on the proper behavior here ðŸ™‚ .

### Version info

```Text
Version:             3.2.7
API version:         0.8.4
Python version:      3.10.16
Git commit:          d4d9001e
Built:               Fri, Feb 21, 2025 7:39 PM
OS/Arch:             darwin/arm64
Profile:             default
Server type:         cloud
Pydantic version:    2.9.2
Integrations:
  prefect-dask:      0.3.2.dev1046+gbe1ba636e4.d20250305
  prefect-gcp:       0.6.2
  prefect-kubernetes: 0.5.3
```

### Additional context

_No response_",,0,https://api.github.com/repos/PrefectHQ/prefect/issues/17384/timeline,0,0,0,https://github.com/PrefectHQ/prefect/issues/17384
